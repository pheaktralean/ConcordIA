{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "23a96bffc608491a87fd6040f23187e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_350dc801fc14458c8e3f3455419a7c01",
              "IPY_MODEL_cf7b0e7f345d4c0db42b00cd4d332a80",
              "IPY_MODEL_ab7e612845bc4e9b88d4fab7484a23e3"
            ],
            "layout": "IPY_MODEL_71d235da785a4d41967f73dd5fe2a292"
          }
        },
        "350dc801fc14458c8e3f3455419a7c01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52228a45231341cfbfb9689628a09ec0",
            "placeholder": "​",
            "style": "IPY_MODEL_188a8e1a90a549d6a9e0d58e28880efe",
            "value": "Best trial: 49. Best value: 1.3296: 100%"
          }
        },
        "cf7b0e7f345d4c0db42b00cd4d332a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab9c59cae1f6461f9a343e00c9fef147",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_861b6640e8f2447fbfbb20451cebdef5",
            "value": 50
          }
        },
        "ab7e612845bc4e9b88d4fab7484a23e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da8f578892b44949b0ccad33b5330174",
            "placeholder": "​",
            "style": "IPY_MODEL_18f8d5d18eab44b3abce0b099f05eba0",
            "value": " 50/50 [2:04:49&lt;00:00, 149.68s/it]"
          }
        },
        "71d235da785a4d41967f73dd5fe2a292": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52228a45231341cfbfb9689628a09ec0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "188a8e1a90a549d6a9e0d58e28880efe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab9c59cae1f6461f9a343e00c9fef147": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "861b6640e8f2447fbfbb20451cebdef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da8f578892b44949b0ccad33b5330174": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18f8d5d18eab44b3abce0b099f05eba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7ccecf24ff64cb5b891bbe4874daa51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d911652fbad9462ab760d989d32bb915",
              "IPY_MODEL_7d94338dad64445eb4f1ca3872eea94b",
              "IPY_MODEL_ed4be3caa8784b518feeb2eb0e6454c7"
            ],
            "layout": "IPY_MODEL_d79270511abc469aa830cbba2c4d0647"
          }
        },
        "d911652fbad9462ab760d989d32bb915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec4dd3b15a46492abfa81a7a0cbe284c",
            "placeholder": "​",
            "style": "IPY_MODEL_387be86393df471692dd60547d6ba6bc",
            "value": "Epoch 79: "
          }
        },
        "7d94338dad64445eb4f1ca3872eea94b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57290ea481db4c3181e4b2d10314fbf6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce404a0a8f4645ac9e4bdb485212cc62",
            "value": 1
          }
        },
        "ed4be3caa8784b518feeb2eb0e6454c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f3af15c1739400091c502fc1b8bf9e8",
            "placeholder": "​",
            "style": "IPY_MODEL_1e7d0f12f3fb4bd2b7e6d20585222a32",
            "value": " 40/? [00:02&lt;00:00, 14.90it/s, v_num=50]"
          }
        },
        "d79270511abc469aa830cbba2c4d0647": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "ec4dd3b15a46492abfa81a7a0cbe284c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "387be86393df471692dd60547d6ba6bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57290ea481db4c3181e4b2d10314fbf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce404a0a8f4645ac9e4bdb485212cc62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f3af15c1739400091c502fc1b8bf9e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e7d0f12f3fb4bd2b7e6d20585222a32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e73176ce01ac4125bcb343d805a3f635": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21af3e6689724fe0a879f93e4d87149a",
              "IPY_MODEL_b62668626a794e6bb7643735915590bd",
              "IPY_MODEL_b35e1b0cf66542178de28b1624a32709"
            ],
            "layout": "IPY_MODEL_5607248d22314e7bb44c8ffef7f3694a"
          }
        },
        "21af3e6689724fe0a879f93e4d87149a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60897c92ed1548e2b44404a2aabe156c",
            "placeholder": "​",
            "style": "IPY_MODEL_ed02181408aa48608e259fa27a24c6a4",
            "value": "Epoch 79: "
          }
        },
        "b62668626a794e6bb7643735915590bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_284447e0a0044dd8a7ddd4d7229fd3b5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8de39a548b1844d7aef7dd9b1b4c9959",
            "value": 1
          }
        },
        "b35e1b0cf66542178de28b1624a32709": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_297b870284a1478894b1256ac5e0c43f",
            "placeholder": "​",
            "style": "IPY_MODEL_281fefcde61c47cf857e346f43e4035c",
            "value": " 40/? [00:02&lt;00:00, 18.44it/s, v_num=52]"
          }
        },
        "5607248d22314e7bb44c8ffef7f3694a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "60897c92ed1548e2b44404a2aabe156c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed02181408aa48608e259fa27a24c6a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "284447e0a0044dd8a7ddd4d7229fd3b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8de39a548b1844d7aef7dd9b1b4c9959": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "297b870284a1478894b1256ac5e0c43f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "281fefcde61c47cf857e346f43e4035c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        " #Run this cell FIRST and ONLY ONCE\n",
        "\n",
        "# 1. Downgrade numpy to fix the \"dtype size changed\" error\n",
        "!pip install \"numpy<2.0\" --force-reinstall\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "MIvC_ZrIHiDd",
        "outputId": "b6fda7b7-ff92-4086-c9d6-0fa62848c784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy<2.0\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/18.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/18.0 MB\u001b[0m \u001b[31m157.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m15.1/18.0 MB\u001b[0m \u001b[31m250.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m17.9/18.0 MB\u001b[0m \u001b[31m307.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m137.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "509e973448c3499baf4dc425ee28aee7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Install GluonTS and other dependencies\n",
        "!pip install gluonts torch pandas matplotlib seaborn --quiet\n",
        "\n",
        "# 3. Clone and install Lag-Llama\n",
        "import os\n",
        "if not os.path.exists(\"lag-llama\"):\n",
        "    !git clone https://github.com/time-series-foundation-models/lag-llama/\n",
        "\n",
        "%cd lag-llama\n",
        "!pip install -r requirements.txt --quiet\n",
        "\n",
        "print(\"\\n✓ Setup complete! Now run Cell 2.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kv52b5ojHknV",
        "outputId": "18c81131-2232-49f5-fd2c-b8be560d1e82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.5 MB\u001b[0m \u001b[31m127.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCloning into 'lag-llama'...\n",
            "remote: Enumerating objects: 508, done.\u001b[K\n",
            "remote: Counting objects: 100% (181/181), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 508 (delta 154), reused 113 (delta 113), pack-reused 327 (from 3)\u001b[K\n",
            "Receiving objects: 100% (508/508), 286.90 KiB | 10.63 MiB/s, done.\n",
            "Resolving deltas: 100% (253/253), done.\n",
            "/content/lag-llama\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m117.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m778.1/778.1 kB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.1.4 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.1.4 which is incompatible.\n",
            "xarray 2025.11.0 requires pandas>=2.2, but you have pandas 2.1.4 which is incompatible.\n",
            "mizani 0.13.5 requires pandas>=2.2.0, but you have pandas 2.1.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "✓ Setup complete! Now run Cell 2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BHvvJAXHagQ",
        "outputId": "5964fb97-e771-4615-c66f-f60d0d07122c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.2)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.44)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
            "Downloading optuna-4.6.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.10.1 optuna-4.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import os\n",
        "import warnings\n",
        "import optuna\n",
        "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# CRITICAL FIX: Patch torch.load ONCE at module level\n",
        "# ---------------------------------------------------------------------------\n",
        "import torch.serialization\n",
        "\n",
        "if not hasattr(torch.serialization, '_original_torch_load_backup'):\n",
        "    torch.serialization._original_torch_load_backup = torch.serialization.load\n",
        "\n",
        "def safe_torch_load(*args, **kwargs):\n",
        "    \"\"\"Wrapper that adds weights_only=False by default\"\"\"\n",
        "    if 'weights_only' not in kwargs:\n",
        "        kwargs['weights_only'] = False\n",
        "    return torch.serialization._original_torch_load_backup(*args, **kwargs)\n",
        "\n",
        "# Apply the patch\n",
        "torch.load = safe_torch_load\n",
        "torch.serialization.load = safe_torch_load\n",
        "\n",
        "print(\"✓ torch.load patched successfully\")\n",
        "\n",
        "# GluonTS imports\n",
        "from gluonts.dataset.pandas import PandasDataset\n",
        "from gluonts.evaluation import make_evaluation_predictions, Evaluator\n",
        "from lag_llama.gluon.estimator import LagLlamaEstimator\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 1. LOAD AND PREPROCESS DATA\n",
        "# ---------------------------------------------------------------------------\n",
        "filename = '/content/macro_index_Family_Newcomer_Services_only.csv'\n",
        "\n",
        "if not os.path.exists(filename):\n",
        "    filename = 'macro_index_Family_Newcomer_Services_only.csv'\n",
        "\n",
        "if not os.path.exists(filename):\n",
        "    print(f\"❌ Error: {filename} not found. Please upload your CSV file.\")\n",
        "    raise FileNotFoundError(\"Please upload macro_index_Family_Newcomer_Services_only.csv\")\n",
        "\n",
        "df = pd.read_csv(filename)\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df.set_index('date', inplace=True)\n",
        "df = df.asfreq('W-SUN')\n",
        "df = df.ffill().bfill()\n",
        "\n",
        "# CRITICAL: Convert all numeric data to float32\n",
        "num_cols = df.select_dtypes(include=[np.number]).columns\n",
        "df[num_cols] = df[num_cols].astype('float32')\n",
        "\n",
        "print(f\"✓ Data Loaded. Shape: {df.shape}\")\n",
        "print(f\"✓ Date range: {df.index[0]} to {df.index[-1]}\")\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 2. FEATURE SELECTION\n",
        "# ---------------------------------------------------------------------------\n",
        "target_col = 'Family Newcomer Services_EMA13'\n",
        "\n",
        "use_exogenous = True\n",
        "\n",
        "if use_exogenous:\n",
        "    selected_features = [\n",
        "        'FXUSDCAD', 'FXEURCAD', 'CPIAUCSL', 'DTWEXBGS', 'DGS10',\n",
        "        'goc_long_benchmark', 'goc_long_benchmark1'\n",
        "    ]\n",
        "    selected_features = [f for f in selected_features if f in df.columns]\n",
        "    print(f\"\\n✓ Using {len(selected_features)} exogenous features\")\n",
        "else:\n",
        "    selected_features = []\n",
        "    print(f\"\\n✓ Using UNIVARIATE forecasting (no exogenous features)\")\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 3. DATA SPLIT STRATEGY\n",
        "# ---------------------------------------------------------------------------\n",
        "prediction_length = 12\n",
        "\n",
        "# Use validation split for hyperparameter tuning\n",
        "# Train: up to -24 weeks, Val: -24 to -12, Test: last 12 weeks\n",
        "full_train_end = len(df) - 24  # Reserve last 24 weeks\n",
        "val_start = full_train_end\n",
        "val_end = len(df) - 12\n",
        "test_start = val_end\n",
        "\n",
        "train_df = df.iloc[:full_train_end]\n",
        "val_df = df.iloc[:val_end]  # Includes train + val for proper context\n",
        "test_df = df.iloc[:test_start]\n",
        "\n",
        "print(f\"\\n✓ Train dataset: {len(train_df)} weeks (up to {train_df.index[-1]})\")\n",
        "print(f\"✓ Validation period: weeks {val_start} to {val_end}\")\n",
        "print(f\"✓ Test period: last {prediction_length} weeks\")\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 4. DOWNLOAD LAG-LLAMA CHECKPOINT (ONE TIME)\n",
        "# ---------------------------------------------------------------------------\n",
        "ckpt_path = \"lag-llama.ckpt\"\n",
        "if not os.path.exists(ckpt_path):\n",
        "    print(\"\\nDownloading Lag-Llama checkpoint...\")\n",
        "    !huggingface-cli download time-series-foundation-models/Lag-Llama lag-llama.ckpt --local-dir .\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"✓ Using device: {device}\")\n",
        "\n",
        "# Load base checkpoint parameters\n",
        "ckpt = torch.load(ckpt_path, map_location=device)\n",
        "base_estimator_args = ckpt[\"hyper_parameters\"][\"model_kwargs\"]\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 5. OPTUNA OBJECTIVE FUNCTION\n",
        "# ---------------------------------------------------------------------------\n",
        "def objective(trial):\n",
        "    \"\"\"\n",
        "    Optuna objective function to minimize validation MAE\n",
        "    \"\"\"\n",
        "\n",
        "    # Suggest hyperparameters\n",
        "    context_length = trial.suggest_categorical('context_length', [16, 32, 64, 96])\n",
        "    batch_size = trial.suggest_categorical('batch_size', [8, 16, 32])\n",
        "    max_epochs = trial.suggest_int('max_epochs', 20, 100, step=10)\n",
        "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True)\n",
        "    aug_prob = trial.suggest_float('aug_prob', 0.0, 0.3)\n",
        "\n",
        "    # Optional: tune model architecture (if you want deeper optimization)\n",
        "    # n_layer = trial.suggest_int('n_layer', 4, 12)\n",
        "    # n_head = trial.suggest_int('n_head', 4, 16)\n",
        "\n",
        "    try:\n",
        "        # Create datasets\n",
        "        if selected_features:\n",
        "            train_ds = PandasDataset(train_df, target=target_col,\n",
        "                                    feat_dynamic_real=selected_features, freq=\"W-SUN\")\n",
        "            val_ds = PandasDataset(val_df, target=target_col,\n",
        "                                  feat_dynamic_real=selected_features, freq=\"W-SUN\")\n",
        "        else:\n",
        "            train_ds = PandasDataset(train_df, target=target_col, freq=\"W-SUN\")\n",
        "            val_ds = PandasDataset(val_df, target=target_col, freq=\"W-SUN\")\n",
        "\n",
        "        # Create estimator with trial hyperparameters\n",
        "        estimator = LagLlamaEstimator(\n",
        "            ckpt_path=ckpt_path,\n",
        "            prediction_length=prediction_length,\n",
        "            context_length=context_length,\n",
        "            n_layer=base_estimator_args[\"n_layer\"],  # Or use trial.suggest_int\n",
        "            n_embd_per_head=base_estimator_args[\"n_embd_per_head\"],\n",
        "            n_head=base_estimator_args[\"n_head\"],  # Or use trial.suggest_int\n",
        "            scaling=base_estimator_args[\"scaling\"],\n",
        "            time_feat=base_estimator_args[\"time_feat\"],\n",
        "            aug_prob=aug_prob,\n",
        "            batch_size=batch_size,\n",
        "            num_parallel_samples=100,\n",
        "            lr=learning_rate,\n",
        "            trainer_kwargs={\n",
        "                \"accelerator\": device,\n",
        "                \"max_epochs\": max_epochs,\n",
        "                \"enable_progress_bar\": False,  # Cleaner output\n",
        "            },\n",
        "        )\n",
        "\n",
        "        # Train model\n",
        "        predictor = estimator.train(\n",
        "            training_data=train_ds,\n",
        "            cache_data=True,\n",
        "            shuffle_buffer_length=1000\n",
        "        )\n",
        "\n",
        "        # Generate forecasts on validation set\n",
        "        forecast_it, ts_it = make_evaluation_predictions(\n",
        "            dataset=val_ds,\n",
        "            predictor=predictor,\n",
        "            num_samples=100\n",
        "        )\n",
        "\n",
        "        forecasts = list(forecast_it)\n",
        "        tss = list(ts_it)\n",
        "\n",
        "        # Get actual values for validation period\n",
        "        actual_values = df[target_col].iloc[val_start:val_end].values\n",
        "        forecast_mean = forecasts[0].mean\n",
        "\n",
        "        # Calculate MAE as optimization metric\n",
        "        mae = np.mean(np.abs(forecast_mean - actual_values))\n",
        "\n",
        "        # Also calculate RMSE for reference\n",
        "        rmse = np.sqrt(np.mean((forecast_mean - actual_values) ** 2))\n",
        "\n",
        "        # Report intermediate value for pruning\n",
        "        trial.report(mae, step=max_epochs)\n",
        "\n",
        "        # Handle pruning\n",
        "        if trial.should_prune():\n",
        "            raise optuna.TrialPruned()\n",
        "\n",
        "        print(f\"Trial {trial.number}: MAE={mae:.2f}, RMSE={rmse:.2f}\")\n",
        "\n",
        "        return mae\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Trial {trial.number} failed: {str(e)}\")\n",
        "        return float('inf')  # Return worst possible score on failure\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 6. RUN OPTUNA OPTIMIZATION\n",
        "# ---------------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🚀 STARTING HYPERPARAMETER OPTIMIZATION WITH OPTUNA\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Create study\n",
        "study = optuna.create_study(\n",
        "    direction='minimize',  # Minimize MAE\n",
        "    sampler=optuna.samplers.TPESampler(seed=42),  # Tree-structured Parzen Estimator\n",
        "    pruner=optuna.pruners.MedianPruner(n_warmup_steps=5),  # Prune bad trials early\n",
        ")\n",
        "\n",
        "# Run optimization\n",
        "n_trials = 50  # Adjust based on your computational budget\n",
        "study.optimize(objective, n_trials=n_trials, timeout=None, show_progress_bar=True)\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 7. ANALYZE RESULTS\n",
        "# ---------------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✅ OPTIMIZATION COMPLETE!\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "print(\"🏆 BEST HYPERPARAMETERS:\")\n",
        "print(\"-\" * 50)\n",
        "for key, value in study.best_params.items():\n",
        "    print(f\"  • {key}: {value}\")\n",
        "\n",
        "print(f\"\\n📊 BEST VALIDATION MAE: {study.best_value:.2f}\")\n",
        "print(f\"📈 Total trials completed: {len(study.trials)}\")\n",
        "\n",
        "# Get statistics\n",
        "completed_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
        "pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
        "\n",
        "print(f\"✓ Completed: {len(completed_trials)}\")\n",
        "print(f\"✗ Pruned: {len(pruned_trials)}\")\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 8. VISUALIZE OPTIMIZATION HISTORY\n",
        "# ---------------------------------------------------------------------------\n",
        "fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n",
        "\n",
        "# Plot 1: Optimization History\n",
        "ax1 = axes[0]\n",
        "trial_numbers = [t.number for t in completed_trials]\n",
        "trial_values = [t.value for t in completed_trials]\n",
        "\n",
        "ax1.plot(trial_numbers, trial_values, 'o-', alpha=0.6, linewidth=1, markersize=4)\n",
        "ax1.axhline(y=study.best_value, color='r', linestyle='--', linewidth=2,\n",
        "           label=f'Best MAE: {study.best_value:.2f}')\n",
        "ax1.set_xlabel('Trial Number', fontsize=12, fontweight='bold')\n",
        "ax1.set_ylabel('Validation MAE', fontsize=12, fontweight='bold')\n",
        "ax1.set_title('Optuna Optimization History', fontsize=14, fontweight='bold', pad=15)\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Parameter Importance\n",
        "ax2 = axes[1]\n",
        "try:\n",
        "    importances = optuna.importance.get_param_importances(study)\n",
        "    params = list(importances.keys())\n",
        "    values = list(importances.values())\n",
        "\n",
        "    colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(params)))\n",
        "    bars = ax2.barh(params, values, color=colors, edgecolor='black', linewidth=1.5)\n",
        "    ax2.set_xlabel('Importance', fontsize=12, fontweight='bold')\n",
        "    ax2.set_title('Hyperparameter Importance', fontsize=14, fontweight='bold', pad=15)\n",
        "    ax2.grid(True, alpha=0.3, axis='x')\n",
        "except:\n",
        "    ax2.text(0.5, 0.5, 'Not enough trials for importance analysis',\n",
        "            ha='center', va='center', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 9. TRAIN FINAL MODEL WITH BEST HYPERPARAMETERS\n",
        "# ---------------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🎯 TRAINING FINAL MODEL WITH BEST HYPERPARAMETERS\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "best_params = study.best_params\n",
        "\n",
        "# Create final datasets (use all data up to test period)\n",
        "final_train_df = df.iloc[:test_start]\n",
        "\n",
        "if selected_features:\n",
        "    final_train_ds = PandasDataset(final_train_df, target=target_col,\n",
        "                                   feat_dynamic_real=selected_features, freq=\"W-SUN\")\n",
        "    test_ds = PandasDataset(test_df, target=target_col,\n",
        "                           feat_dynamic_real=selected_features, freq=\"W-SUN\")\n",
        "else:\n",
        "    final_train_ds = PandasDataset(final_train_df, target=target_col, freq=\"W-SUN\")\n",
        "    test_ds = PandasDataset(test_df, target=target_col, freq=\"W-SUN\")\n",
        "\n",
        "# Create final estimator\n",
        "final_estimator = LagLlamaEstimator(\n",
        "    ckpt_path=ckpt_path,\n",
        "    prediction_length=prediction_length,\n",
        "    context_length=best_params['context_length'],\n",
        "    n_layer=base_estimator_args[\"n_layer\"],\n",
        "    n_embd_per_head=base_estimator_args[\"n_embd_per_head\"],\n",
        "    n_head=base_estimator_args[\"n_head\"],\n",
        "    scaling=base_estimator_args[\"scaling\"],\n",
        "    time_feat=base_estimator_args[\"time_feat\"],\n",
        "    aug_prob=best_params['aug_prob'],\n",
        "    batch_size=best_params['batch_size'],\n",
        "    num_parallel_samples=100,\n",
        "    lr=best_params['learning_rate'],\n",
        "    trainer_kwargs={\n",
        "        \"accelerator\": device,\n",
        "        \"max_epochs\": best_params['max_epochs'],\n",
        "    },\n",
        ")\n",
        "\n",
        "# Train final model\n",
        "final_predictor = final_estimator.train(\n",
        "    training_data=final_train_ds,\n",
        "    cache_data=True,\n",
        "    shuffle_buffer_length=1000\n",
        ")\n",
        "\n",
        "# Generate final forecasts\n",
        "forecast_it, ts_it = make_evaluation_predictions(\n",
        "    dataset=test_ds,\n",
        "    predictor=final_predictor,\n",
        "    num_samples=100\n",
        ")\n",
        "\n",
        "forecasts = list(forecast_it)\n",
        "tss = list(ts_it)\n",
        "\n",
        "# Get actual test values\n",
        "actual_values = df[target_col].iloc[test_start:test_start + prediction_length].values\n",
        "forecast_mean = forecasts[0].mean\n",
        "\n",
        "# Calculate final metrics\n",
        "mae = np.mean(np.abs(forecast_mean - actual_values))\n",
        "rmse = np.sqrt(np.mean((forecast_mean - actual_values) ** 2))\n",
        "mape = np.mean(np.abs((actual_values - forecast_mean) / actual_values)) * 100\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 10. PLOT FINAL RESULTS\n",
        "# ---------------------------------------------------------------------------\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
        "\n",
        "# Plot 1: Forecast with Historical Context\n",
        "ts_entry = tss[0]\n",
        "ts_index = ts_entry[-100:].index.to_timestamp()\n",
        "ts_values = ts_entry[-100:].values\n",
        "\n",
        "ax1.plot(ts_index, ts_values, label=\"Historical Data\", linewidth=2,\n",
        "         color='#2E86AB', marker='o', markersize=3, alpha=0.8)\n",
        "\n",
        "forecast_entry = forecasts[0]\n",
        "forecast_index = forecast_entry.index.to_timestamp()\n",
        "actual_index = df.index[test_start:test_start + prediction_length]\n",
        "\n",
        "ax1.plot(actual_index, actual_values, label=\"Actual (Test)\",\n",
        "         linewidth=2.5, color='#E63946', marker='o', markersize=5)\n",
        "\n",
        "ax1.plot(forecast_index, forecast_mean, label=\"Optimized Forecast\",\n",
        "         linewidth=2.5, color='#06A77D', marker='s', markersize=4, linestyle='--')\n",
        "\n",
        "q05 = forecast_entry.quantile('0.05')\n",
        "q95 = forecast_entry.quantile('0.95')\n",
        "ax1.fill_between(forecast_index, q05, q95, alpha=0.2, color='#06A77D',\n",
        "                 label='90% Prediction Interval')\n",
        "\n",
        "ax1.axvline(x=forecast_index[0], color='red', linestyle='--',\n",
        "           linewidth=1.5, alpha=0.7, label='Forecast Start')\n",
        "\n",
        "ax1.set_title(f\"Optimized Model: Weekly Intake Forecast vs Actual\\n\"\n",
        "             f\"MAE: {mae:.2f} | RMSE: {rmse:.2f} | MAPE: {mape:.1f}%\",\n",
        "             fontsize=14, fontweight='bold', pad=15)\n",
        "ax1.set_xlabel(\"Date\", fontsize=12, fontweight='bold')\n",
        "ax1.set_ylabel(\"Number of People\", fontsize=12, fontweight='bold')\n",
        "ax1.legend(fontsize=9, loc='best', framealpha=0.9)\n",
        "ax1.grid(True, alpha=0.3, linestyle='--')\n",
        "ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%b'))\n",
        "plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
        "\n",
        "# Plot 2: Forecast Error Analysis\n",
        "errors = forecast_mean - actual_values\n",
        "weeks = np.arange(1, prediction_length + 1)\n",
        "\n",
        "ax2.bar(weeks, errors, color=['#06A77D' if e >= 0 else '#E63946' for e in errors],\n",
        "       alpha=0.7, edgecolor='black', linewidth=1.5)\n",
        "ax2.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
        "ax2.set_title(\"Forecast Error by Week\", fontsize=14, fontweight='bold', pad=15)\n",
        "ax2.set_xlabel(\"Week Ahead\", fontsize=12, fontweight='bold')\n",
        "ax2.set_ylabel(\"Error (Forecast - Actual)\", fontsize=12, fontweight='bold')\n",
        "ax2.grid(True, alpha=0.3, axis='y', linestyle='--')\n",
        "ax2.set_xticks(weeks)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 11. FINAL SUMMARY\n",
        "# ---------------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✅ FINAL MODEL EVALUATION (TEST SET)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\n📊 ACCURACY METRICS:\")\n",
        "print(f\"  • MAE (Mean Absolute Error):        {mae:.2f}\")\n",
        "print(f\"  • RMSE (Root Mean Squared Error):   {rmse:.2f}\")\n",
        "print(f\"  • MAPE (Mean Absolute % Error):     {mape:.1f}%\")\n",
        "\n",
        "print(f\"\\n🏆 BEST HYPERPARAMETERS USED:\")\n",
        "for key, value in best_params.items():\n",
        "    print(f\"  • {key}: {value}\")\n",
        "\n",
        "print(f\"\\n📋 WEEK-BY-WEEK COMPARISON:\")\n",
        "print(f\"{'Week':<6} {'Actual':<10} {'Forecast':<10} {'Error':<10} {'% Error':<10}\")\n",
        "print(\"-\" * 50)\n",
        "for i, (actual, pred) in enumerate(zip(actual_values, forecast_mean), 1):\n",
        "    error = pred - actual\n",
        "    pct_error = (error / actual) * 100\n",
        "    print(f\"{i:<6} {actual:<10.2f} {pred:<10.2f} {error:<10.2f} {pct_error:<10.1f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "\n",
        "# Save best parameters to file\n",
        "import json\n",
        "with open('best_hyperparameters.json', 'w') as f:\n",
        "    json.dump(best_params, f, indent=2)\n",
        "print(\"\\n💾 Best hyperparameters saved to 'best_hyperparameters.json'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "23a96bffc608491a87fd6040f23187e8",
            "350dc801fc14458c8e3f3455419a7c01",
            "cf7b0e7f345d4c0db42b00cd4d332a80",
            "ab7e612845bc4e9b88d4fab7484a23e3",
            "71d235da785a4d41967f73dd5fe2a292",
            "52228a45231341cfbfb9689628a09ec0",
            "188a8e1a90a549d6a9e0d58e28880efe",
            "ab9c59cae1f6461f9a343e00c9fef147",
            "861b6640e8f2447fbfbb20451cebdef5",
            "da8f578892b44949b0ccad33b5330174",
            "18f8d5d18eab44b3abce0b099f05eba0",
            "d7ccecf24ff64cb5b891bbe4874daa51",
            "d911652fbad9462ab760d989d32bb915",
            "7d94338dad64445eb4f1ca3872eea94b",
            "ed4be3caa8784b518feeb2eb0e6454c7",
            "d79270511abc469aa830cbba2c4d0647",
            "ec4dd3b15a46492abfa81a7a0cbe284c",
            "387be86393df471692dd60547d6ba6bc",
            "57290ea481db4c3181e4b2d10314fbf6",
            "ce404a0a8f4645ac9e4bdb485212cc62",
            "4f3af15c1739400091c502fc1b8bf9e8",
            "1e7d0f12f3fb4bd2b7e6d20585222a32"
          ]
        },
        "id": "PM4CSQqTHeSa",
        "outputId": "e0f6369a-97cd-4cc5-a0f8-81a8ea0490df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ torch.load patched successfully\n",
            "✓ Data Loaded. Shape: (242, 44)\n",
            "✓ Date range: 2021-03-07 00:00:00 to 2025-10-19 00:00:00\n",
            "\n",
            "✓ Using 7 exogenous features\n",
            "\n",
            "✓ Train dataset: 218 weeks (up to 2025-05-04 00:00:00)\n",
            "✓ Validation period: weeks 218 to 230\n",
            "✓ Test period: last 12 weeks\n",
            "\n",
            "Downloading Lag-Llama checkpoint...\n",
            "\u001b[33m⚠️  Warning: 'huggingface-cli download' is deprecated. Use 'hf download' instead.\u001b[0m\n",
            "Downloading 'lag-llama.ckpt' to '.cache/huggingface/download/59Iq1KnnyJzBevZl6u7vR_lVuAs=.b5a5c4b8a0cfe9b81bdac35ed5d88b5033cd119b5206c28e9cd67c4b45fb2c96.incomplete'\n",
            "lag-llama.ckpt: 100% 29.5M/29.5M [00:01<00:00, 18.5MB/s]\n",
            "Download complete. Moving file to lag-llama.ckpt\n",
            "lag-llama.ckpt\n",
            "✓ Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-23 19:10:25,892] A new study created in memory with name: no-name-6ef20cb4-5fc5-4be8-8753-e261e0a15b24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "🚀 STARTING HYPERPARAMETER OPTIMIZATION WITH OPTUNA\n",
            "======================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23a96bffc608491a87fd6040f23187e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "WARNING: Missing logger folder: /content/lag-llama/lightning_logs\n",
            "WARNING:lightning.pytorch.loggers.tensorboard:Missing logger folder: /content/lag-llama/lightning_logs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 1.04798 (best 1.04798), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 1.04798 (best 1.04798), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.59381 (best 0.59381), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.59381 (best 0.59381), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.24850 (best 0.24850), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.24850 (best 0.24850), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.09283 (best 0.09283), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.09283 (best 0.09283), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached -0.16329 (best -0.16329), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached -0.16329 (best -0.16329), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached -0.25190 (best -0.25190), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached -0.25190 (best -0.25190), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached -0.30498 (best -0.30498), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached -0.30498 (best -0.30498), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached -0.35617 (best -0.35617), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached -0.35617 (best -0.35617), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached -0.54078 (best -0.54078), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached -0.54078 (best -0.54078), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' reached -0.73798 (best -0.73798), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' reached -0.73798 (best -0.73798), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' reached -0.89260 (best -0.89260), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' reached -0.89260 (best -0.89260), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' reached -0.98695 (best -0.98695), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' reached -0.98695 (best -0.98695), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' reached -1.01103 (best -1.01103), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' reached -1.01103 (best -1.01103), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' reached -1.10662 (best -1.10662), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' reached -1.10662 (best -1.10662), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' reached -1.13695 (best -1.13695), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=56-step=2850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' reached -1.13695 (best -1.13695), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=56-step=2850.ckpt' as top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' reached -1.26152 (best -1.26152), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=59-step=3000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' reached -1.26152 (best -1.26152), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=59-step=3000.ckpt' as top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 80, global step 4050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 80, global step 4050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 81, global step 4100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 81, global step 4100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 82, global step 4150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 82, global step 4150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 84, global step 4250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 84, global step 4250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 85, global step 4300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 85, global step 4300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 86, global step 4350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 86, global step 4350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 88, global step 4450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 88, global step 4450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 89, global step 4500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 89, global step 4500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=90` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=90` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 0: MAE=7.23, RMSE=10.20\n",
            "[I 2025-11-23 19:13:34,421] Trial 0 finished with value: 7.234035015106201 and parameters: {'context_length': 32, 'batch_size': 8, 'max_epochs': 90, 'learning_rate': 0.00015930522616241006, 'aug_prob': 0.21242177333881365}. Best is trial 0 with value: 7.234035015106201.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 0.94508 (best 0.94508), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 0.94508 (best 0.94508), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.17608 (best 0.17608), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.17608 (best 0.17608), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached -0.07938 (best -0.07938), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached -0.07938 (best -0.07938), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached -0.09229 (best -0.09229), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached -0.09229 (best -0.09229), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached -0.30927 (best -0.30927), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached -0.30927 (best -0.30927), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached -0.35933 (best -0.35933), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached -0.35933 (best -0.35933), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached -0.51296 (best -0.51296), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached -0.51296 (best -0.51296), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached -0.74782 (best -0.74782), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached -0.74782 (best -0.74782), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached -0.84831 (best -0.84831), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached -0.84831 (best -0.84831), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached -0.99967 (best -0.99967), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached -0.99967 (best -0.99967), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' reached -1.06937 (best -1.06937), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' reached -1.06937 (best -1.06937), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' reached -1.25820 (best -1.25820), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' reached -1.25820 (best -1.25820), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' reached -1.33801 (best -1.33801), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' reached -1.33801 (best -1.33801), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' reached -1.35527 (best -1.35527), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' reached -1.35527 (best -1.35527), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' reached -1.50685 (best -1.50685), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' reached -1.50685 (best -1.50685), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' reached -1.53029 (best -1.53029), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' reached -1.53029 (best -1.53029), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' reached -1.65748 (best -1.65748), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' reached -1.65748 (best -1.65748), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1: MAE=12.58, RMSE=14.72\n",
            "[I 2025-11-23 19:15:55,959] Trial 1 finished with value: 12.584587097167969 and parameters: {'context_length': 32, 'batch_size': 32, 'max_epochs': 60, 'learning_rate': 7.309539835912905e-05, 'aug_prob': 0.08736874205941257}. Best is trial 0 with value: 7.234035015106201.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 1.12446 (best 1.12446), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 1.12446 (best 1.12446), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.59181 (best 0.59181), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.59181 (best 0.59181), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.31026 (best 0.31026), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.31026 (best 0.31026), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached -0.07912 (best -0.07912), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached -0.07912 (best -0.07912), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached -0.13417 (best -0.13417), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached -0.13417 (best -0.13417), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached -0.33013 (best -0.33013), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached -0.33013 (best -0.33013), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached -0.47259 (best -0.47259), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached -0.47259 (best -0.47259), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached -0.65037 (best -0.65037), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached -0.65037 (best -0.65037), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached -0.65201 (best -0.65201), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached -0.65201 (best -0.65201), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached -0.66083 (best -0.66083), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached -0.66083 (best -0.66083), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached -0.83110 (best -0.83110), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached -0.83110 (best -0.83110), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' reached -0.94207 (best -0.94207), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' reached -0.94207 (best -0.94207), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached -0.96356 (best -0.96356), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached -0.96356 (best -0.96356), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' reached -1.07842 (best -1.07842), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' reached -1.07842 (best -1.07842), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' reached -1.25591 (best -1.25591), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' reached -1.25591 (best -1.25591), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' reached -1.33676 (best -1.33676), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' reached -1.33676 (best -1.33676), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' reached -1.46871 (best -1.46871), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' reached -1.46871 (best -1.46871), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' reached -1.62664 (best -1.62664), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' reached -1.62664 (best -1.62664), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' reached -1.63125 (best -1.63125), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=52-step=2650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' reached -1.63125 (best -1.63125), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=52-step=2650.ckpt' as top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' reached -1.66919 (best -1.66919), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=58-step=2950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' reached -1.66919 (best -1.66919), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=58-step=2950.ckpt' as top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' reached -1.74789 (best -1.74789), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=59-step=3000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' reached -1.74789 (best -1.74789), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=59-step=3000.ckpt' as top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 2: MAE=14.65, RMSE=17.93\n",
            "[I 2025-11-23 19:18:01,442] Trial 2 finished with value: 14.648246765136719 and parameters: {'context_length': 16, 'batch_size': 16, 'max_epochs': 60, 'learning_rate': 0.00015304852121831474, 'aug_prob': 0.013935123815999317}. Best is trial 0 with value: 7.234035015106201.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 0.70981 (best 0.70981), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 0.70981 (best 0.70981), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.47078 (best 0.47078), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.47078 (best 0.47078), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached -0.03438 (best -0.03438), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached -0.03438 (best -0.03438), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached -0.07710 (best -0.07710), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached -0.07710 (best -0.07710), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached -0.28451 (best -0.28451), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached -0.28451 (best -0.28451), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached -0.42029 (best -0.42029), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached -0.42029 (best -0.42029), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached -0.61568 (best -0.61568), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached -0.61568 (best -0.61568), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached -0.65284 (best -0.65284), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached -0.65284 (best -0.65284), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached -0.80184 (best -0.80184), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached -0.80184 (best -0.80184), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached -0.82993 (best -0.82993), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached -0.82993 (best -0.82993), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached -1.00051 (best -1.00051), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached -1.00051 (best -1.00051), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=20` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=20` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3: MAE=7.24, RMSE=8.93\n",
            "[I 2025-11-23 19:18:42,272] Trial 3 finished with value: 7.238406658172607 and parameters: {'context_length': 96, 'batch_size': 8, 'max_epochs': 20, 'learning_rate': 0.000233596350262616, 'aug_prob': 0.13204574812188039}. Best is trial 0 with value: 7.234035015106201.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 0.65979 (best 0.65979), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 0.65979 (best 0.65979), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.07322 (best 0.07322), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.07322 (best 0.07322), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached -0.27108 (best -0.27108), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached -0.27108 (best -0.27108), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached -0.36399 (best -0.36399), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached -0.36399 (best -0.36399), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached -0.48242 (best -0.48242), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached -0.48242 (best -0.48242), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached -0.59998 (best -0.59998), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached -0.59998 (best -0.59998), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached -0.87549 (best -0.87549), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached -0.87549 (best -0.87549), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached -0.92403 (best -0.92403), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached -0.92403 (best -0.92403), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached -1.00978 (best -1.00978), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached -1.00978 (best -1.00978), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached -1.15716 (best -1.15716), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached -1.15716 (best -1.15716), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached -1.34925 (best -1.34925), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached -1.34925 (best -1.34925), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached -1.42712 (best -1.42712), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached -1.42712 (best -1.42712), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached -1.49303 (best -1.49303), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached -1.49303 (best -1.49303), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached -1.55459 (best -1.55459), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached -1.55459 (best -1.55459), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' reached -1.61904 (best -1.61904), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' reached -1.61904 (best -1.61904), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' reached -1.73460 (best -1.73460), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' reached -1.73460 (best -1.73460), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' reached -1.80950 (best -1.80950), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' reached -1.80950 (best -1.80950), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' reached -1.94193 (best -1.94193), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' reached -1.94193 (best -1.94193), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' reached -2.05250 (best -2.05250), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' reached -2.05250 (best -2.05250), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 4: MAE=8.32, RMSE=9.81\n",
            "[I 2025-11-23 19:20:48,209] Trial 4 finished with value: 8.319787979125977 and parameters: {'context_length': 96, 'batch_size': 16, 'max_epochs': 60, 'learning_rate': 0.00012399967836846095, 'aug_prob': 0.05545633665765811}. Best is trial 0 with value: 7.234035015106201.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 1.26498 (best 1.26498), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 1.26498 (best 1.26498), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.98604 (best 0.98604), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.98604 (best 0.98604), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.47706 (best 0.47706), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.47706 (best 0.47706), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 0.42100 (best 0.42100), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 0.42100 (best 0.42100), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 0.41172 (best 0.41172), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 0.41172 (best 0.41172), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 0.09195 (best 0.09195), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 0.09195 (best 0.09195), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 0.00542 (best 0.00542), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 0.00542 (best 0.00542), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached -0.02820 (best -0.02820), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached -0.02820 (best -0.02820), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached -0.06011 (best -0.06011), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached -0.06011 (best -0.06011), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached -0.09089 (best -0.09089), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached -0.09089 (best -0.09089), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached -0.12039 (best -0.12039), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached -0.12039 (best -0.12039), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' reached -0.20313 (best -0.20313), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' reached -0.20313 (best -0.20313), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached -0.25246 (best -0.25246), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached -0.25246 (best -0.25246), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' reached -0.28686 (best -0.28686), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' reached -0.28686 (best -0.28686), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' reached -0.38175 (best -0.38175), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' reached -0.38175 (best -0.38175), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' reached -0.40284 (best -0.40284), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' reached -0.40284 (best -0.40284), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' reached -0.58686 (best -0.58686), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' reached -0.58686 (best -0.58686), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=30` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=30` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5: MAE=11.54, RMSE=12.91\n",
            "[I 2025-11-23 19:21:51,254] Trial 5 finished with value: 11.538666725158691 and parameters: {'context_length': 16, 'batch_size': 16, 'max_epochs': 30, 'learning_rate': 1.2315571723666024e-05, 'aug_prob': 0.0975990992289793}. Best is trial 0 with value: 7.234035015106201.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 0.92406 (best 0.92406), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 0.92406 (best 0.92406), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.67296 (best 0.67296), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.67296 (best 0.67296), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.45051 (best 0.45051), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.45051 (best 0.45051), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.36770 (best 0.36770), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.36770 (best 0.36770), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 0.10481 (best 0.10481), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 0.10481 (best 0.10481), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 0.00084 (best 0.00084), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 0.00084 (best 0.00084), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached -0.25657 (best -0.25657), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached -0.25657 (best -0.25657), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached -0.27165 (best -0.27165), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached -0.27165 (best -0.27165), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached -0.31287 (best -0.31287), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached -0.31287 (best -0.31287), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached -0.38696 (best -0.38696), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached -0.38696 (best -0.38696), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached -0.47812 (best -0.47812), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached -0.47812 (best -0.47812), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' reached -0.60242 (best -0.60242), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' reached -0.60242 (best -0.60242), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' reached -0.62893 (best -0.62893), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' reached -0.62893 (best -0.62893), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' reached -0.82942 (best -0.82942), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' reached -0.82942 (best -0.82942), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' reached -0.97635 (best -0.97635), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' reached -0.97635 (best -0.97635), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' reached -1.08803 (best -1.08803), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=59-step=3000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' reached -1.08803 (best -1.08803), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=59-step=3000.ckpt' as top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' reached -1.13973 (best -1.13973), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=63-step=3200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' reached -1.13973 (best -1.13973), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=63-step=3200.ckpt' as top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 70, global step 3550: 'train_loss' reached -1.20175 (best -1.20175), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=70-step=3550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 70, global step 3550: 'train_loss' reached -1.20175 (best -1.20175), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=70-step=3550.ckpt' as top 1\n",
            "INFO: Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 76, global step 3850: 'train_loss' reached -1.27596 (best -1.27596), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=76-step=3850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 76, global step 3850: 'train_loss' reached -1.27596 (best -1.27596), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=76-step=3850.ckpt' as top 1\n",
            "INFO: Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 80, global step 4050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 80, global step 4050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 81, global step 4100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 81, global step 4100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 82, global step 4150: 'train_loss' reached -1.31597 (best -1.31597), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=82-step=4150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 82, global step 4150: 'train_loss' reached -1.31597 (best -1.31597), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=82-step=4150.ckpt' as top 1\n",
            "INFO: Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 84, global step 4250: 'train_loss' reached -1.49196 (best -1.49196), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=84-step=4250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 84, global step 4250: 'train_loss' reached -1.49196 (best -1.49196), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=84-step=4250.ckpt' as top 1\n",
            "INFO: Epoch 85, global step 4300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 85, global step 4300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 86, global step 4350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 86, global step 4350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 88, global step 4450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 88, global step 4450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 89, global step 4500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 89, global step 4500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=90` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=90` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: GPU available: True (cuda), used: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 6: MAE=6.86, RMSE=9.42\n",
            "[I 2025-11-23 19:24:59,545] Trial 6 finished with value: 6.86461877822876 and parameters: {'context_length': 64, 'batch_size': 16, 'max_epochs': 90, 'learning_rate': 1.4096175149815848e-05, 'aug_prob': 0.2960660809801552}. Best is trial 6 with value: 6.86461877822876.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 0.62052 (best 0.62052), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 0.62052 (best 0.62052), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.10016 (best 0.10016), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.10016 (best 0.10016), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached -0.45738 (best -0.45738), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached -0.45738 (best -0.45738), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached -0.79107 (best -0.79107), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached -0.79107 (best -0.79107), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached -0.95773 (best -0.95773), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached -0.95773 (best -0.95773), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached -1.11645 (best -1.11645), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached -1.11645 (best -1.11645), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached -1.21620 (best -1.21620), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached -1.21620 (best -1.21620), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached -1.34998 (best -1.34998), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached -1.34998 (best -1.34998), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached -1.38007 (best -1.38007), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached -1.38007 (best -1.38007), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached -1.41414 (best -1.41414), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached -1.41414 (best -1.41414), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached -1.55000 (best -1.55000), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached -1.55000 (best -1.55000), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' reached -1.59298 (best -1.59298), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' reached -1.59298 (best -1.59298), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached -1.70699 (best -1.70699), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached -1.70699 (best -1.70699), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached -1.74485 (best -1.74485), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached -1.74485 (best -1.74485), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=20` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=20` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 7 failed: \n",
            "[I 2025-11-23 19:25:50,412] Trial 7 finished with value: inf and parameters: {'context_length': 96, 'batch_size': 32, 'max_epochs': 20, 'learning_rate': 5.211124595788268e-05, 'aug_prob': 0.03476071785753891}. Best is trial 6 with value: 6.86461877822876.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 1.19194 (best 1.19194), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 1.19194 (best 1.19194), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.85373 (best 0.85373), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.85373 (best 0.85373), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.61332 (best 0.61332), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.61332 (best 0.61332), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.35120 (best 0.35120), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.35120 (best 0.35120), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 0.16997 (best 0.16997), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 0.16997 (best 0.16997), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 0.10920 (best 0.10920), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 0.10920 (best 0.10920), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached -0.12898 (best -0.12898), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached -0.12898 (best -0.12898), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached -0.23507 (best -0.23507), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached -0.23507 (best -0.23507), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached -0.28305 (best -0.28305), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached -0.28305 (best -0.28305), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached -0.42290 (best -0.42290), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached -0.42290 (best -0.42290), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached -0.45882 (best -0.45882), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached -0.45882 (best -0.45882), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' reached -0.64867 (best -0.64867), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' reached -0.64867 (best -0.64867), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' reached -0.68921 (best -0.68921), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' reached -0.68921 (best -0.68921), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' reached -0.85355 (best -0.85355), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' reached -0.85355 (best -0.85355), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' reached -0.94431 (best -0.94431), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' reached -0.94431 (best -0.94431), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' reached -0.99079 (best -0.99079), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' reached -0.99079 (best -0.99079), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' reached -1.04600 (best -1.04600), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=53-step=2700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' reached -1.04600 (best -1.04600), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=53-step=2700.ckpt' as top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' reached -1.11663 (best -1.11663), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=56-step=2850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' reached -1.11663 (best -1.11663), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=56-step=2850.ckpt' as top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 8: MAE=2.32, RMSE=2.94\n",
            "[I 2025-11-23 19:28:28,772] Trial 8 finished with value: 2.320657968521118 and parameters: {'context_length': 16, 'batch_size': 32, 'max_epochs': 70, 'learning_rate': 0.000594874681321977, 'aug_prob': 0.14166447754858477}. Best is trial 8 with value: 2.320657968521118.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 0.88859 (best 0.88859), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 0.88859 (best 0.88859), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.67167 (best 0.67167), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.67167 (best 0.67167), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.45690 (best 0.45690), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.45690 (best 0.45690), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.19313 (best 0.19313), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.19313 (best 0.19313), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached -0.01657 (best -0.01657), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached -0.01657 (best -0.01657), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached -0.03091 (best -0.03091), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached -0.03091 (best -0.03091), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached -0.23336 (best -0.23336), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached -0.23336 (best -0.23336), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached -0.37322 (best -0.37322), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached -0.37322 (best -0.37322), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached -0.41294 (best -0.41294), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached -0.41294 (best -0.41294), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached -0.50175 (best -0.50175), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached -0.50175 (best -0.50175), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached -0.70683 (best -0.70683), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached -0.70683 (best -0.70683), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached -0.70737 (best -0.70737), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached -0.70737 (best -0.70737), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached -0.85414 (best -0.85414), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached -0.85414 (best -0.85414), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' reached -0.92109 (best -0.92109), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' reached -0.92109 (best -0.92109), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' reached -0.94659 (best -0.94659), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' reached -0.94659 (best -0.94659), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' reached -0.96242 (best -0.96242), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' reached -0.96242 (best -0.96242), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' reached -1.01762 (best -1.01762), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' reached -1.01762 (best -1.01762), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' reached -1.05011 (best -1.05011), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' reached -1.05011 (best -1.05011), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' reached -1.14834 (best -1.14834), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' reached -1.14834 (best -1.14834), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' reached -1.20948 (best -1.20948), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' reached -1.20948 (best -1.20948), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' reached -1.23794 (best -1.23794), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' reached -1.23794 (best -1.23794), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' reached -1.33238 (best -1.33238), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' reached -1.33238 (best -1.33238), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' reached -1.36651 (best -1.36651), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' reached -1.36651 (best -1.36651), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' reached -1.40684 (best -1.40684), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' reached -1.40684 (best -1.40684), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' reached -1.47119 (best -1.47119), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' reached -1.47119 (best -1.47119), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=50` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=50` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 9: MAE=7.03, RMSE=9.43\n",
            "[I 2025-11-23 19:30:08,709] Trial 9 finished with value: 7.026679515838623 and parameters: {'context_length': 64, 'batch_size': 8, 'max_epochs': 50, 'learning_rate': 1.1241862095793047e-05, 'aug_prob': 0.032367428097991334}. Best is trial 8 with value: 2.320657968521118.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 1.27589 (best 1.27589), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 1.27589 (best 1.27589), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.81113 (best 0.81113), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.81113 (best 0.81113), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.68792 (best 0.68792), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.68792 (best 0.68792), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.41703 (best 0.41703), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.41703 (best 0.41703), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 0.30941 (best 0.30941), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 0.30941 (best 0.30941), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 0.13850 (best 0.13850), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 0.13850 (best 0.13850), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 0.12265 (best 0.12265), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 0.12265 (best 0.12265), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached -0.05508 (best -0.05508), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached -0.05508 (best -0.05508), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached -0.11752 (best -0.11752), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached -0.11752 (best -0.11752), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached -0.13897 (best -0.13897), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached -0.13897 (best -0.13897), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached -0.22372 (best -0.22372), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached -0.22372 (best -0.22372), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached -0.35991 (best -0.35991), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached -0.35991 (best -0.35991), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' reached -0.50820 (best -0.50820), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' reached -0.50820 (best -0.50820), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' reached -0.52874 (best -0.52874), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' reached -0.52874 (best -0.52874), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' reached -0.60445 (best -0.60445), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' reached -0.60445 (best -0.60445), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' reached -0.61025 (best -0.61025), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' reached -0.61025 (best -0.61025), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' reached -0.88615 (best -0.88615), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' reached -0.88615 (best -0.88615), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' reached -0.91932 (best -0.91932), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=55-step=2800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' reached -0.91932 (best -0.91932), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=55-step=2800.ckpt' as top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' reached -0.97854 (best -0.97854), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=58-step=2950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' reached -0.97854 (best -0.97854), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=58-step=2950.ckpt' as top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' reached -0.99597 (best -0.99597), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=69-step=3500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' reached -0.99597 (best -0.99597), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=69-step=3500.ckpt' as top 1\n",
            "INFO: Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 72, global step 3650: 'train_loss' reached -1.05753 (best -1.05753), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=72-step=3650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 72, global step 3650: 'train_loss' reached -1.05753 (best -1.05753), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=72-step=3650.ckpt' as top 1\n",
            "INFO: Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 77, global step 3900: 'train_loss' reached -1.12279 (best -1.12279), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=77-step=3900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 77, global step 3900: 'train_loss' reached -1.12279 (best -1.12279), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=77-step=3900.ckpt' as top 1\n",
            "INFO: Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 79, global step 4000: 'train_loss' reached -1.19363 (best -1.19363), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=79-step=4000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 79, global step 4000: 'train_loss' reached -1.19363 (best -1.19363), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=79-step=4000.ckpt' as top 1\n",
            "INFO: Epoch 80, global step 4050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 80, global step 4050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 81, global step 4100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 81, global step 4100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 82, global step 4150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 82, global step 4150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 84, global step 4250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 84, global step 4250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 85, global step 4300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 85, global step 4300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 86, global step 4350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 86, global step 4350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 88, global step 4450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 88, global step 4450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 89, global step 4500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 89, global step 4500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 90, global step 4550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 90, global step 4550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 91, global step 4600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 91, global step 4600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 92, global step 4650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 92, global step 4650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 93, global step 4700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 93, global step 4700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 94, global step 4750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 94, global step 4750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 95, global step 4800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 95, global step 4800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 96, global step 4850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 96, global step 4850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 97, global step 4900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 97, global step 4900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 98, global step 4950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 98, global step 4950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 99, global step 5000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 99, global step 5000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=100` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=100` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10: MAE=11.18, RMSE=13.71\n",
            "[I 2025-11-23 19:34:03,161] Trial 10 finished with value: 11.182936668395996 and parameters: {'context_length': 16, 'batch_size': 32, 'max_epochs': 100, 'learning_rate': 0.0008115044874888275, 'aug_prob': 0.19555996523345354}. Best is trial 8 with value: 2.320657968521118.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 1.15487 (best 1.15487), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 1.15487 (best 1.15487), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.65092 (best 0.65092), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.65092 (best 0.65092), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.46055 (best 0.46055), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.46055 (best 0.46055), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.29205 (best 0.29205), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.29205 (best 0.29205), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 0.12161 (best 0.12161), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 0.12161 (best 0.12161), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 0.04599 (best 0.04599), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 0.04599 (best 0.04599), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 0.04056 (best 0.04056), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 0.04056 (best 0.04056), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached -0.02592 (best -0.02592), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached -0.02592 (best -0.02592), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached -0.13557 (best -0.13557), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached -0.13557 (best -0.13557), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached -0.19263 (best -0.19263), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached -0.19263 (best -0.19263), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached -0.35587 (best -0.35587), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached -0.35587 (best -0.35587), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached -0.43151 (best -0.43151), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached -0.43151 (best -0.43151), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' reached -0.47942 (best -0.47942), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' reached -0.47942 (best -0.47942), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' reached -0.48245 (best -0.48245), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' reached -0.48245 (best -0.48245), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' reached -0.61946 (best -0.61946), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' reached -0.61946 (best -0.61946), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' reached -0.68931 (best -0.68931), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' reached -0.68931 (best -0.68931), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' reached -0.85246 (best -0.85246), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' reached -0.85246 (best -0.85246), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' reached -0.87615 (best -0.87615), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=61-step=3100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' reached -0.87615 (best -0.87615), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=61-step=3100.ckpt' as top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' reached -0.90070 (best -0.90070), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=64-step=3250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' reached -0.90070 (best -0.90070), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=64-step=3250.ckpt' as top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=80` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=80` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 11: MAE=1.38, RMSE=1.70\n",
            "[I 2025-11-23 19:36:50,265] Trial 11 finished with value: 1.3830891847610474 and parameters: {'context_length': 64, 'batch_size': 16, 'max_epochs': 80, 'learning_rate': 0.0007832921114568409, 'aug_prob': 0.29449885269166737}. Best is trial 11 with value: 1.3830891847610474.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 1.35121 (best 1.35121), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 1.35121 (best 1.35121), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.69460 (best 0.69460), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.69460 (best 0.69460), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.53133 (best 0.53133), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.53133 (best 0.53133), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.22649 (best 0.22649), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.22649 (best 0.22649), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 0.13251 (best 0.13251), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 0.13251 (best 0.13251), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached -0.05083 (best -0.05083), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached -0.05083 (best -0.05083), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached -0.20573 (best -0.20573), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached -0.20573 (best -0.20573), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached -0.32737 (best -0.32737), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached -0.32737 (best -0.32737), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' reached -0.46268 (best -0.46268), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' reached -0.46268 (best -0.46268), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' reached -0.56444 (best -0.56444), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' reached -0.56444 (best -0.56444), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' reached -0.68001 (best -0.68001), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' reached -0.68001 (best -0.68001), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' reached -0.78216 (best -0.78216), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' reached -0.78216 (best -0.78216), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' reached -0.81810 (best -0.81810), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=58-step=2950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' reached -0.81810 (best -0.81810), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=58-step=2950.ckpt' as top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' reached -0.88524 (best -0.88524), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=64-step=3250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' reached -0.88524 (best -0.88524), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=64-step=3250.ckpt' as top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=80` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=80` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 12 failed: \n",
            "[I 2025-11-23 19:39:52,950] Trial 12 finished with value: inf and parameters: {'context_length': 64, 'batch_size': 32, 'max_epochs': 80, 'learning_rate': 0.0009628632040881559, 'aug_prob': 0.28737595466325333}. Best is trial 11 with value: 1.3830891847610474.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 1.28132 (best 1.28132), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 1.28132 (best 1.28132), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.74038 (best 0.74038), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.74038 (best 0.74038), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.50339 (best 0.50339), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.50339 (best 0.50339), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.12786 (best 0.12786), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.12786 (best 0.12786), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 0.00148 (best 0.00148), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 0.00148 (best 0.00148), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached -0.01753 (best -0.01753), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached -0.01753 (best -0.01753), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached -0.16227 (best -0.16227), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached -0.16227 (best -0.16227), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached -0.17042 (best -0.17042), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached -0.17042 (best -0.17042), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached -0.20487 (best -0.20487), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached -0.20487 (best -0.20487), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached -0.39058 (best -0.39058), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached -0.39058 (best -0.39058), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached -0.40883 (best -0.40883), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached -0.40883 (best -0.40883), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' reached -0.60308 (best -0.60308), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' reached -0.60308 (best -0.60308), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' reached -0.72078 (best -0.72078), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' reached -0.72078 (best -0.72078), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' reached -0.78197 (best -0.78197), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' reached -0.78197 (best -0.78197), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' reached -0.83835 (best -0.83835), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=64-step=3250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' reached -0.83835 (best -0.83835), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=64-step=3250.ckpt' as top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' reached -0.91315 (best -0.91315), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=67-step=3400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' reached -0.91315 (best -0.91315), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=67-step=3400.ckpt' as top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=80` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=80` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 13 failed: \n",
            "[I 2025-11-23 19:42:43,566] Trial 13 finished with value: inf and parameters: {'context_length': 16, 'batch_size': 16, 'max_epochs': 80, 'learning_rate': 0.00044149735004750845, 'aug_prob': 0.19375693221097234}. Best is trial 11 with value: 1.3830891847610474.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 0.80285 (best 0.80285), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 0.80285 (best 0.80285), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.38175 (best 0.38175), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.38175 (best 0.38175), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.20287 (best 0.20287), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.20287 (best 0.20287), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached -0.14463 (best -0.14463), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached -0.14463 (best -0.14463), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached -0.25527 (best -0.25527), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached -0.25527 (best -0.25527), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached -0.52852 (best -0.52852), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached -0.52852 (best -0.52852), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached -0.62833 (best -0.62833), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached -0.62833 (best -0.62833), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' reached -0.67733 (best -0.67733), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' reached -0.67733 (best -0.67733), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' reached -0.71276 (best -0.71276), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' reached -0.71276 (best -0.71276), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' reached -0.81712 (best -0.81712), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' reached -0.81712 (best -0.81712), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' reached -0.90084 (best -0.90084), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' reached -0.90084 (best -0.90084), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' reached -0.99467 (best -0.99467), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' reached -0.99467 (best -0.99467), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' reached -1.03305 (best -1.03305), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' reached -1.03305 (best -1.03305), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' reached -1.11102 (best -1.11102), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=50-step=2550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' reached -1.11102 (best -1.11102), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=50-step=2550.ckpt' as top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' reached -1.14425 (best -1.14425), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=64-step=3250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' reached -1.14425 (best -1.14425), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=64-step=3250.ckpt' as top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' reached -1.17862 (best -1.17862), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=67-step=3400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' reached -1.17862 (best -1.17862), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=67-step=3400.ckpt' as top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' reached -1.25366 (best -1.25366), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=69-step=3500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' reached -1.25366 (best -1.25366), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=69-step=3500.ckpt' as top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 14 failed: \n",
            "[I 2025-11-23 19:45:30,670] Trial 14 finished with value: inf and parameters: {'context_length': 64, 'batch_size': 32, 'max_epochs': 70, 'learning_rate': 0.00041311613055976297, 'aug_prob': 0.2430382308626583}. Best is trial 11 with value: 1.3830891847610474.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 1.30935 (best 1.30935), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 1.30935 (best 1.30935), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.76530 (best 0.76530), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.76530 (best 0.76530), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.43612 (best 0.43612), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.43612 (best 0.43612), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 0.19233 (best 0.19233), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 0.19233 (best 0.19233), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached -0.02897 (best -0.02897), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached -0.02897 (best -0.02897), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached -0.09467 (best -0.09467), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached -0.09467 (best -0.09467), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached -0.24833 (best -0.24833), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached -0.24833 (best -0.24833), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached -0.25801 (best -0.25801), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached -0.25801 (best -0.25801), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached -0.27919 (best -0.27919), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached -0.27919 (best -0.27919), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached -0.29254 (best -0.29254), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached -0.29254 (best -0.29254), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached -0.47129 (best -0.47129), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached -0.47129 (best -0.47129), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' reached -0.53498 (best -0.53498), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' reached -0.53498 (best -0.53498), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' reached -0.57076 (best -0.57076), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' reached -0.57076 (best -0.57076), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' reached -0.60783 (best -0.60783), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' reached -0.60783 (best -0.60783), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' reached -0.69384 (best -0.69384), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' reached -0.69384 (best -0.69384), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=40` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=40` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 15: MAE=3.61, RMSE=5.10\n",
            "[I 2025-11-23 19:46:56,842] Trial 15 finished with value: 3.609461545944214 and parameters: {'context_length': 16, 'batch_size': 16, 'max_epochs': 40, 'learning_rate': 0.0004943018624063403, 'aug_prob': 0.15449112420628297}. Best is trial 11 with value: 1.3830891847610474.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 0.75459 (best 0.75459), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 0.75459 (best 0.75459), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.34278 (best 0.34278), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.34278 (best 0.34278), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.07877 (best 0.07877), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.07877 (best 0.07877), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached -0.11438 (best -0.11438), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached -0.11438 (best -0.11438), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached -0.23576 (best -0.23576), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached -0.23576 (best -0.23576), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached -0.40472 (best -0.40472), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached -0.40472 (best -0.40472), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached -0.59251 (best -0.59251), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached -0.59251 (best -0.59251), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached -0.78138 (best -0.78138), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached -0.78138 (best -0.78138), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached -0.92067 (best -0.92067), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached -0.92067 (best -0.92067), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached -0.95993 (best -0.95993), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached -0.95993 (best -0.95993), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached -0.97648 (best -0.97648), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached -0.97648 (best -0.97648), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' reached -1.28280 (best -1.28280), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' reached -1.28280 (best -1.28280), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' reached -1.45599 (best -1.45599), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' reached -1.45599 (best -1.45599), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' reached -1.52034 (best -1.52034), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' reached -1.52034 (best -1.52034), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' reached -1.58154 (best -1.58154), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=54-step=2750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' reached -1.58154 (best -1.58154), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=54-step=2750.ckpt' as top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' reached -1.66071 (best -1.66071), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=58-step=2950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' reached -1.66071 (best -1.66071), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=58-step=2950.ckpt' as top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' reached -1.73567 (best -1.73567), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=60-step=3050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' reached -1.73567 (best -1.73567), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=60-step=3050.ckpt' as top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' reached -1.75560 (best -1.75560), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=62-step=3150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' reached -1.75560 (best -1.75560), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=62-step=3150.ckpt' as top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 16 failed: \n",
            "[I 2025-11-23 19:49:42,773] Trial 16 finished with value: inf and parameters: {'context_length': 64, 'batch_size': 32, 'max_epochs': 70, 'learning_rate': 3.0416543930766186e-05, 'aug_prob': 0.14912561808325575}. Best is trial 11 with value: 1.3830891847610474.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 0.85225 (best 0.85225), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 0.85225 (best 0.85225), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.56661 (best 0.56661), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.56661 (best 0.56661), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.21095 (best 0.21095), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.21095 (best 0.21095), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.16440 (best 0.16440), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.16440 (best 0.16440), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 0.05141 (best 0.05141), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 0.05141 (best 0.05141), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached -0.11528 (best -0.11528), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached -0.11528 (best -0.11528), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached -0.13989 (best -0.13989), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached -0.13989 (best -0.13989), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached -0.14529 (best -0.14529), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached -0.14529 (best -0.14529), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached -0.26767 (best -0.26767), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached -0.26767 (best -0.26767), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached -0.42920 (best -0.42920), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached -0.42920 (best -0.42920), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached -0.52832 (best -0.52832), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached -0.52832 (best -0.52832), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached -0.56511 (best -0.56511), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached -0.56511 (best -0.56511), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' reached -0.60693 (best -0.60693), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' reached -0.60693 (best -0.60693), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached -0.61832 (best -0.61832), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached -0.61832 (best -0.61832), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' reached -0.81978 (best -0.81978), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' reached -0.81978 (best -0.81978), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' reached -0.88812 (best -0.88812), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' reached -0.88812 (best -0.88812), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' reached -0.92467 (best -0.92467), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' reached -0.92467 (best -0.92467), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' reached -0.92535 (best -0.92535), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=55-step=2800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' reached -0.92535 (best -0.92535), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=55-step=2800.ckpt' as top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' reached -0.94381 (best -0.94381), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=57-step=2900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' reached -0.94381 (best -0.94381), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=57-step=2900.ckpt' as top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' reached -1.02112 (best -1.02112), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=58-step=2950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' reached -1.02112 (best -1.02112), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=58-step=2950.ckpt' as top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' reached -1.05716 (best -1.05716), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=68-step=3450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' reached -1.05716 (best -1.05716), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=68-step=3450.ckpt' as top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 76, global step 3850: 'train_loss' reached -1.14480 (best -1.14480), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=76-step=3850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 76, global step 3850: 'train_loss' reached -1.14480 (best -1.14480), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=76-step=3850.ckpt' as top 1\n",
            "INFO: Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 80, global step 4050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 80, global step 4050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 81, global step 4100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 81, global step 4100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 82, global step 4150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 82, global step 4150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 84, global step 4250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 84, global step 4250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 85, global step 4300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 85, global step 4300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 86, global step 4350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 86, global step 4350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 88, global step 4450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 88, global step 4450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 89, global step 4500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 89, global step 4500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 90, global step 4550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 90, global step 4550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 91, global step 4600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 91, global step 4600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 92, global step 4650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 92, global step 4650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 93, global step 4700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 93, global step 4700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 94, global step 4750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 94, global step 4750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 95, global step 4800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 95, global step 4800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 96, global step 4850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 96, global step 4850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 97, global step 4900: 'train_loss' reached -1.17178 (best -1.17178), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=97-step=4900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 97, global step 4900: 'train_loss' reached -1.17178 (best -1.17178), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=97-step=4900.ckpt' as top 1\n",
            "INFO: Epoch 98, global step 4950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 98, global step 4950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 99, global step 5000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 99, global step 5000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=100` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=100` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 17: MAE=6.66, RMSE=6.97\n",
            "[I 2025-11-23 19:53:15,377] Trial 17 finished with value: 6.655473232269287 and parameters: {'context_length': 32, 'batch_size': 16, 'max_epochs': 100, 'learning_rate': 0.0002850432000718151, 'aug_prob': 0.2495111495748285}. Best is trial 11 with value: 1.3830891847610474.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 1.17186 (best 1.17186), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 1.17186 (best 1.17186), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.82439 (best 0.82439), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.82439 (best 0.82439), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.62784 (best 0.62784), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.62784 (best 0.62784), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.41205 (best 0.41205), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.41205 (best 0.41205), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 0.07098 (best 0.07098), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 0.07098 (best 0.07098), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached -0.08568 (best -0.08568), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached -0.08568 (best -0.08568), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached -0.19808 (best -0.19808), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached -0.19808 (best -0.19808), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached -0.26445 (best -0.26445), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached -0.26445 (best -0.26445), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached -0.37850 (best -0.37850), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached -0.37850 (best -0.37850), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' reached -0.41021 (best -0.41021), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' reached -0.41021 (best -0.41021), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached -0.43327 (best -0.43327), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached -0.43327 (best -0.43327), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' reached -0.46252 (best -0.46252), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' reached -0.46252 (best -0.46252), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' reached -0.67693 (best -0.67693), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' reached -0.67693 (best -0.67693), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' reached -0.78596 (best -0.78596), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' reached -0.78596 (best -0.78596), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' reached -0.91460 (best -0.91460), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' reached -0.91460 (best -0.91460), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' reached -0.98484 (best -0.98484), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' reached -0.98484 (best -0.98484), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' reached -1.04043 (best -1.04043), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' reached -1.04043 (best -1.04043), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' reached -1.07943 (best -1.07943), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=50-step=2550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' reached -1.07943 (best -1.07943), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=50-step=2550.ckpt' as top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' reached -1.11507 (best -1.11507), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=53-step=2700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' reached -1.11507 (best -1.11507), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=53-step=2700.ckpt' as top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' reached -1.33774 (best -1.33774), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=63-step=3200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' reached -1.33774 (best -1.33774), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=63-step=3200.ckpt' as top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=80` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=80` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 18 failed: \n",
            "[I 2025-11-23 19:56:20,335] Trial 18 finished with value: inf and parameters: {'context_length': 16, 'batch_size': 32, 'max_epochs': 80, 'learning_rate': 0.0006317518842175362, 'aug_prob': 0.11987410373223323}. Best is trial 11 with value: 1.3830891847610474.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 0.77001 (best 0.77001), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 0.77001 (best 0.77001), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.59964 (best 0.59964), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.59964 (best 0.59964), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.25569 (best 0.25569), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.25569 (best 0.25569), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached -0.00266 (best -0.00266), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached -0.00266 (best -0.00266), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached -0.04385 (best -0.04385), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached -0.04385 (best -0.04385), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached -0.19918 (best -0.19918), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached -0.19918 (best -0.19918), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached -0.29650 (best -0.29650), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached -0.29650 (best -0.29650), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached -0.53814 (best -0.53814), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached -0.53814 (best -0.53814), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached -0.61425 (best -0.61425), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached -0.61425 (best -0.61425), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached -0.71335 (best -0.71335), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached -0.71335 (best -0.71335), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached -0.77875 (best -0.77875), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached -0.77875 (best -0.77875), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' reached -0.80103 (best -0.80103), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' reached -0.80103 (best -0.80103), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' reached -0.94127 (best -0.94127), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' reached -0.94127 (best -0.94127), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' reached -0.95747 (best -0.95747), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' reached -0.95747 (best -0.95747), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' reached -1.07573 (best -1.07573), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' reached -1.07573 (best -1.07573), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' reached -1.12883 (best -1.12883), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' reached -1.12883 (best -1.12883), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=50` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=50` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 19 failed: \n",
            "[I 2025-11-23 19:58:01,972] Trial 19 finished with value: inf and parameters: {'context_length': 64, 'batch_size': 8, 'max_epochs': 50, 'learning_rate': 0.0003061271931601501, 'aug_prob': 0.16785400078265708}. Best is trial 11 with value: 1.3830891847610474.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 1.02041 (best 1.02041), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 1.02041 (best 1.02041), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.56123 (best 0.56123), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.56123 (best 0.56123), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.44464 (best 0.44464), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.44464 (best 0.44464), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.21739 (best 0.21739), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.21739 (best 0.21739), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached -0.03438 (best -0.03438), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached -0.03438 (best -0.03438), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached -0.27940 (best -0.27940), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached -0.27940 (best -0.27940), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached -0.32350 (best -0.32350), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached -0.32350 (best -0.32350), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached -0.40015 (best -0.40015), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached -0.40015 (best -0.40015), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached -0.44066 (best -0.44066), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached -0.44066 (best -0.44066), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached -0.55094 (best -0.55094), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached -0.55094 (best -0.55094), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' reached -0.56175 (best -0.56175), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' reached -0.56175 (best -0.56175), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' reached -0.56874 (best -0.56874), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' reached -0.56874 (best -0.56874), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' reached -0.57389 (best -0.57389), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' reached -0.57389 (best -0.57389), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' reached -0.60639 (best -0.60639), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' reached -0.60639 (best -0.60639), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' reached -0.85028 (best -0.85028), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' reached -0.85028 (best -0.85028), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' reached -0.85559 (best -0.85559), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' reached -0.85559 (best -0.85559), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' reached -0.88974 (best -0.88974), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' reached -0.88974 (best -0.88974), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' reached -0.98693 (best -0.98693), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=57-step=2900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' reached -0.98693 (best -0.98693), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=57-step=2900.ckpt' as top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' reached -1.00148 (best -1.00148), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=61-step=3100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' reached -1.00148 (best -1.00148), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=61-step=3100.ckpt' as top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 20: MAE=1.33, RMSE=1.53\n",
            "[I 2025-11-23 20:00:45,367] Trial 20 finished with value: 1.3314929008483887 and parameters: {'context_length': 64, 'batch_size': 32, 'max_epochs': 70, 'learning_rate': 0.0009006020499939714, 'aug_prob': 0.25563682258678205}. Best is trial 20 with value: 1.3314929008483887.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 1.24265 (best 1.24265), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 1.24265 (best 1.24265), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.65285 (best 0.65285), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.65285 (best 0.65285), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.48746 (best 0.48746), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.48746 (best 0.48746), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.48683 (best 0.48683), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.48683 (best 0.48683), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 0.34518 (best 0.34518), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 0.34518 (best 0.34518), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 0.06614 (best 0.06614), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 0.06614 (best 0.06614), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached -0.17250 (best -0.17250), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached -0.17250 (best -0.17250), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached -0.35420 (best -0.35420), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached -0.35420 (best -0.35420), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached -0.41756 (best -0.41756), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached -0.41756 (best -0.41756), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' reached -0.46932 (best -0.46932), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' reached -0.46932 (best -0.46932), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' reached -0.46963 (best -0.46963), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' reached -0.46963 (best -0.46963), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' reached -0.59721 (best -0.59721), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' reached -0.59721 (best -0.59721), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' reached -0.65455 (best -0.65455), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' reached -0.65455 (best -0.65455), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' reached -0.70114 (best -0.70114), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' reached -0.70114 (best -0.70114), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' reached -0.83253 (best -0.83253), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' reached -0.83253 (best -0.83253), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' reached -0.84442 (best -0.84442), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' reached -0.84442 (best -0.84442), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' reached -1.03285 (best -1.03285), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=51-step=2600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' reached -1.03285 (best -1.03285), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=51-step=2600.ckpt' as top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 21 failed: \n",
            "[I 2025-11-23 20:03:26,184] Trial 21 finished with value: inf and parameters: {'context_length': 64, 'batch_size': 32, 'max_epochs': 70, 'learning_rate': 0.0008148473513762445, 'aug_prob': 0.2606395455797769}. Best is trial 20 with value: 1.3314929008483887.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 0.86656 (best 0.86656), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 0.86656 (best 0.86656), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.45944 (best 0.45944), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.45944 (best 0.45944), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.26096 (best 0.26096), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.26096 (best 0.26096), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.02652 (best 0.02652), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.02652 (best 0.02652), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached -0.00398 (best -0.00398), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached -0.00398 (best -0.00398), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached -0.09491 (best -0.09491), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached -0.09491 (best -0.09491), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached -0.38237 (best -0.38237), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached -0.38237 (best -0.38237), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached -0.66870 (best -0.66870), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached -0.66870 (best -0.66870), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' reached -0.72714 (best -0.72714), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' reached -0.72714 (best -0.72714), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' reached -0.74686 (best -0.74686), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' reached -0.74686 (best -0.74686), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' reached -1.01621 (best -1.01621), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' reached -1.01621 (best -1.01621), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' reached -1.06202 (best -1.06202), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' reached -1.06202 (best -1.06202), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' reached -1.25417 (best -1.25417), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' reached -1.25417 (best -1.25417), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 80, global step 4050: 'train_loss' reached -1.37451 (best -1.37451), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=80-step=4050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 80, global step 4050: 'train_loss' reached -1.37451 (best -1.37451), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=80-step=4050.ckpt' as top 1\n",
            "INFO: Epoch 81, global step 4100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 81, global step 4100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 82, global step 4150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 82, global step 4150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 84, global step 4250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 84, global step 4250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 85, global step 4300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 85, global step 4300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 86, global step 4350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 86, global step 4350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 88, global step 4450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 88, global step 4450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 89, global step 4500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 89, global step 4500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=90` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=90` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 22 failed: \n",
            "[I 2025-11-23 20:06:54,177] Trial 22 finished with value: inf and parameters: {'context_length': 64, 'batch_size': 32, 'max_epochs': 90, 'learning_rate': 0.0005753097931071182, 'aug_prob': 0.22267648307910848}. Best is trial 20 with value: 1.3314929008483887.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 1.01442 (best 1.01442), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 1.01442 (best 1.01442), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.63835 (best 0.63835), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.63835 (best 0.63835), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.48616 (best 0.48616), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.48616 (best 0.48616), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.47209 (best 0.47209), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.47209 (best 0.47209), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 0.42196 (best 0.42196), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 0.42196 (best 0.42196), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 0.11202 (best 0.11202), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 0.11202 (best 0.11202), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached -0.09132 (best -0.09132), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached -0.09132 (best -0.09132), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached -0.24457 (best -0.24457), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached -0.24457 (best -0.24457), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached -0.50872 (best -0.50872), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached -0.50872 (best -0.50872), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' reached -0.59300 (best -0.59300), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' reached -0.59300 (best -0.59300), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' reached -0.66186 (best -0.66186), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' reached -0.66186 (best -0.66186), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' reached -0.67591 (best -0.67591), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' reached -0.67591 (best -0.67591), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' reached -0.87752 (best -0.87752), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' reached -0.87752 (best -0.87752), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' reached -0.88724 (best -0.88724), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=54-step=2750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' reached -0.88724 (best -0.88724), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=54-step=2750.ckpt' as top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' reached -0.93083 (best -0.93083), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=57-step=2900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' reached -0.93083 (best -0.93083), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=57-step=2900.ckpt' as top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 23: MAE=1.76, RMSE=2.10\n",
            "[I 2025-11-23 20:09:33,930] Trial 23 finished with value: 1.758862853050232 and parameters: {'context_length': 64, 'batch_size': 32, 'max_epochs': 70, 'learning_rate': 0.0009959371466181804, 'aug_prob': 0.28312039360326396}. Best is trial 20 with value: 1.3314929008483887.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 1.00128 (best 1.00128), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 1.00128 (best 1.00128), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.55177 (best 0.55177), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.55177 (best 0.55177), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.37599 (best 0.37599), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.37599 (best 0.37599), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.22674 (best 0.22674), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.22674 (best 0.22674), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 0.02401 (best 0.02401), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 0.02401 (best 0.02401), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 0.01429 (best 0.01429), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 0.01429 (best 0.01429), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached -0.12499 (best -0.12499), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached -0.12499 (best -0.12499), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached -0.22359 (best -0.22359), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached -0.22359 (best -0.22359), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached -0.30338 (best -0.30338), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached -0.30338 (best -0.30338), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached -0.44978 (best -0.44978), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached -0.44978 (best -0.44978), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached -0.45283 (best -0.45283), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached -0.45283 (best -0.45283), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' reached -0.49573 (best -0.49573), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' reached -0.49573 (best -0.49573), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' reached -0.55370 (best -0.55370), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' reached -0.55370 (best -0.55370), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' reached -0.63001 (best -0.63001), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' reached -0.63001 (best -0.63001), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' reached -0.79007 (best -0.79007), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' reached -0.79007 (best -0.79007), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' reached -0.89744 (best -0.89744), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' reached -0.89744 (best -0.89744), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' reached -0.92175 (best -0.92175), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=63-step=3200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' reached -0.92175 (best -0.92175), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=63-step=3200.ckpt' as top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' reached -0.95306 (best -0.95306), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=65-step=3300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' reached -0.95306 (best -0.95306), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=65-step=3300.ckpt' as top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' reached -0.96328 (best -0.96328), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=66-step=3350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' reached -0.96328 (best -0.96328), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=66-step=3350.ckpt' as top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' reached -1.06677 (best -1.06677), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=69-step=3500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' reached -1.06677 (best -1.06677), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=69-step=3500.ckpt' as top 1\n",
            "INFO: Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 78, global step 3950: 'train_loss' reached -1.10475 (best -1.10475), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=78-step=3950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 78, global step 3950: 'train_loss' reached -1.10475 (best -1.10475), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=78-step=3950.ckpt' as top 1\n",
            "INFO: Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=80` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=80` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 24: MAE=1.46, RMSE=2.01\n",
            "[I 2025-11-23 20:12:37,878] Trial 24 finished with value: 1.4631460905075073 and parameters: {'context_length': 64, 'batch_size': 32, 'max_epochs': 80, 'learning_rate': 0.0008520499116629795, 'aug_prob': 0.27451337234447754}. Best is trial 20 with value: 1.3314929008483887.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 0.76611 (best 0.76611), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 0.76611 (best 0.76611), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.30710 (best 0.30710), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.30710 (best 0.30710), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached -0.05095 (best -0.05095), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached -0.05095 (best -0.05095), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached -0.08267 (best -0.08267), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached -0.08267 (best -0.08267), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached -0.24908 (best -0.24908), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached -0.24908 (best -0.24908), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached -0.43090 (best -0.43090), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached -0.43090 (best -0.43090), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached -0.46212 (best -0.46212), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached -0.46212 (best -0.46212), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached -0.56522 (best -0.56522), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached -0.56522 (best -0.56522), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached -0.58815 (best -0.58815), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached -0.58815 (best -0.58815), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached -0.60846 (best -0.60846), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached -0.60846 (best -0.60846), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' reached -0.67475 (best -0.67475), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' reached -0.67475 (best -0.67475), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' reached -0.73361 (best -0.73361), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' reached -0.73361 (best -0.73361), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' reached -0.96921 (best -0.96921), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' reached -0.96921 (best -0.96921), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' reached -1.02692 (best -1.02692), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' reached -1.02692 (best -1.02692), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' reached -1.17629 (best -1.17629), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' reached -1.17629 (best -1.17629), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' reached -1.26229 (best -1.26229), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=66-step=3350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' reached -1.26229 (best -1.26229), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=66-step=3350.ckpt' as top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 73, global step 3700: 'train_loss' reached -1.34033 (best -1.34033), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=73-step=3700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 73, global step 3700: 'train_loss' reached -1.34033 (best -1.34033), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=73-step=3700.ckpt' as top 1\n",
            "INFO: Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=80` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=80` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 25 failed: \n",
            "[I 2025-11-23 20:15:27,537] Trial 25 finished with value: inf and parameters: {'context_length': 64, 'batch_size': 16, 'max_epochs': 80, 'learning_rate': 0.0002228578773057806, 'aug_prob': 0.26764482197367334}. Best is trial 20 with value: 1.3314929008483887.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 0.86779 (best 0.86779), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 0.86779 (best 0.86779), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.33823 (best 0.33823), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.33823 (best 0.33823), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.12226 (best 0.12226), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.12226 (best 0.12226), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.00007 (best 0.00007), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.00007 (best 0.00007), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached -0.12015 (best -0.12015), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached -0.12015 (best -0.12015), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached -0.35924 (best -0.35924), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached -0.35924 (best -0.35924), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached -0.44104 (best -0.44104), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached -0.44104 (best -0.44104), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached -0.60133 (best -0.60133), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached -0.60133 (best -0.60133), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached -0.61684 (best -0.61684), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached -0.61684 (best -0.61684), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' reached -0.66141 (best -0.66141), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' reached -0.66141 (best -0.66141), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' reached -0.74151 (best -0.74151), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' reached -0.74151 (best -0.74151), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' reached -1.00355 (best -1.00355), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' reached -1.00355 (best -1.00355), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' reached -1.00988 (best -1.00988), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' reached -1.00988 (best -1.00988), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' reached -1.06990 (best -1.06990), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' reached -1.06990 (best -1.06990), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' reached -1.20176 (best -1.20176), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' reached -1.20176 (best -1.20176), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' reached -1.35881 (best -1.35881), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=56-step=2850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' reached -1.35881 (best -1.35881), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=56-step=2850.ckpt' as top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 80, global step 4050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 80, global step 4050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 81, global step 4100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 81, global step 4100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 82, global step 4150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 82, global step 4150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 84, global step 4250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 84, global step 4250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 85, global step 4300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 85, global step 4300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 86, global step 4350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 86, global step 4350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 88, global step 4450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 88, global step 4450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 89, global step 4500: 'train_loss' reached -1.47893 (best -1.47893), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=89-step=4500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 89, global step 4500: 'train_loss' reached -1.47893 (best -1.47893), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=89-step=4500.ckpt' as top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=90` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=90` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 26: MAE=4.80, RMSE=6.29\n",
            "[I 2025-11-23 20:18:56,700] Trial 26 finished with value: 4.8000664710998535 and parameters: {'context_length': 64, 'batch_size': 32, 'max_epochs': 90, 'learning_rate': 0.00036322938017496363, 'aug_prob': 0.22821654935510813}. Best is trial 20 with value: 1.3314929008483887.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 0.95048 (best 0.95048), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 0.95048 (best 0.95048), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.42969 (best 0.42969), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.42969 (best 0.42969), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.23953 (best 0.23953), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.23953 (best 0.23953), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.07851 (best 0.07851), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.07851 (best 0.07851), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached -0.01350 (best -0.01350), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached -0.01350 (best -0.01350), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached -0.21271 (best -0.21271), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached -0.21271 (best -0.21271), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached -0.32280 (best -0.32280), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached -0.32280 (best -0.32280), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached -0.44518 (best -0.44518), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached -0.44518 (best -0.44518), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached -0.45560 (best -0.45560), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached -0.45560 (best -0.45560), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached -0.49549 (best -0.49549), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached -0.49549 (best -0.49549), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached -0.53121 (best -0.53121), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached -0.53121 (best -0.53121), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached -0.64080 (best -0.64080), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached -0.64080 (best -0.64080), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' reached -0.65114 (best -0.65114), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' reached -0.65114 (best -0.65114), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' reached -0.79935 (best -0.79935), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' reached -0.79935 (best -0.79935), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' reached -0.86556 (best -0.86556), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' reached -0.86556 (best -0.86556), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' reached -0.91711 (best -0.91711), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' reached -0.91711 (best -0.91711), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=50` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=50` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 27: MAE=2.29, RMSE=2.66\n",
            "[I 2025-11-23 20:20:53,799] Trial 27 finished with value: 2.289212942123413 and parameters: {'context_length': 64, 'batch_size': 32, 'max_epochs': 50, 'learning_rate': 0.0006374335250059675, 'aug_prob': 0.27147612774512947}. Best is trial 20 with value: 1.3314929008483887.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 1.02650 (best 1.02650), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 1.02650 (best 1.02650), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.58912 (best 0.58912), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.58912 (best 0.58912), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.48336 (best 0.48336), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.48336 (best 0.48336), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.29079 (best 0.29079), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.29079 (best 0.29079), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 0.26294 (best 0.26294), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 0.26294 (best 0.26294), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 0.08115 (best 0.08115), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 0.08115 (best 0.08115), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 0.07762 (best 0.07762), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 0.07762 (best 0.07762), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached -0.21925 (best -0.21925), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached -0.21925 (best -0.21925), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached -0.29217 (best -0.29217), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached -0.29217 (best -0.29217), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached -0.37540 (best -0.37540), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached -0.37540 (best -0.37540), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached -0.49978 (best -0.49978), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached -0.49978 (best -0.49978), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' reached -0.63924 (best -0.63924), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' reached -0.63924 (best -0.63924), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' reached -0.69510 (best -0.69510), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' reached -0.69510 (best -0.69510), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' reached -0.71684 (best -0.71684), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' reached -0.71684 (best -0.71684), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' reached -0.72760 (best -0.72760), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' reached -0.72760 (best -0.72760), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' reached -0.73720 (best -0.73720), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=50-step=2550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' reached -0.73720 (best -0.73720), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=50-step=2550.ckpt' as top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' reached -0.81735 (best -0.81735), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=53-step=2700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' reached -0.81735 (best -0.81735), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=53-step=2700.ckpt' as top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' reached -0.82911 (best -0.82911), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=61-step=3100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' reached -0.82911 (best -0.82911), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=61-step=3100.ckpt' as top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' reached -0.83207 (best -0.83207), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=62-step=3150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' reached -0.83207 (best -0.83207), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=62-step=3150.ckpt' as top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=80` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=80` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 28 failed: \n",
            "[I 2025-11-23 20:23:45,232] Trial 28 finished with value: inf and parameters: {'context_length': 64, 'batch_size': 16, 'max_epochs': 80, 'learning_rate': 0.0007482969280347205, 'aug_prob': 0.29966673586856524}. Best is trial 20 with value: 1.3314929008483887.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 0.78741 (best 0.78741), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 0.78741 (best 0.78741), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.61180 (best 0.61180), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.61180 (best 0.61180), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.42828 (best 0.42828), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.42828 (best 0.42828), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.05497 (best 0.05497), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.05497 (best 0.05497), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached -0.09008 (best -0.09008), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached -0.09008 (best -0.09008), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached -0.21355 (best -0.21355), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached -0.21355 (best -0.21355), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached -0.30754 (best -0.30754), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached -0.30754 (best -0.30754), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached -0.32714 (best -0.32714), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached -0.32714 (best -0.32714), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached -0.37349 (best -0.37349), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached -0.37349 (best -0.37349), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached -0.57311 (best -0.57311), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached -0.57311 (best -0.57311), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' reached -0.61973 (best -0.61973), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' reached -0.61973 (best -0.61973), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached -0.67365 (best -0.67365), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached -0.67365 (best -0.67365), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' reached -0.68167 (best -0.68167), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' reached -0.68167 (best -0.68167), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' reached -0.69635 (best -0.69635), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' reached -0.69635 (best -0.69635), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' reached -0.71873 (best -0.71873), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' reached -0.71873 (best -0.71873), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' reached -0.74595 (best -0.74595), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' reached -0.74595 (best -0.74595), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' reached -0.74868 (best -0.74868), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' reached -0.74868 (best -0.74868), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' reached -0.94437 (best -0.94437), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' reached -0.94437 (best -0.94437), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' reached -0.99509 (best -0.99509), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=50-step=2550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' reached -0.99509 (best -0.99509), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=50-step=2550.ckpt' as top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' reached -1.00368 (best -1.00368), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=65-step=3300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' reached -1.00368 (best -1.00368), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=65-step=3300.ckpt' as top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 73, global step 3700: 'train_loss' reached -1.05659 (best -1.05659), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=73-step=3700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 73, global step 3700: 'train_loss' reached -1.05659 (best -1.05659), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=73-step=3700.ckpt' as top 1\n",
            "INFO: Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 80, global step 4050: 'train_loss' reached -1.07270 (best -1.07270), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=80-step=4050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 80, global step 4050: 'train_loss' reached -1.07270 (best -1.07270), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=80-step=4050.ckpt' as top 1\n",
            "INFO: Epoch 81, global step 4100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 81, global step 4100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 82, global step 4150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 82, global step 4150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 84, global step 4250: 'train_loss' reached -1.09898 (best -1.09898), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=84-step=4250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 84, global step 4250: 'train_loss' reached -1.09898 (best -1.09898), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=84-step=4250.ckpt' as top 1\n",
            "INFO: Epoch 85, global step 4300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 85, global step 4300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 86, global step 4350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 86, global step 4350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 88, global step 4450: 'train_loss' reached -1.24334 (best -1.24334), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=88-step=4450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 88, global step 4450: 'train_loss' reached -1.24334 (best -1.24334), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=88-step=4450.ckpt' as top 1\n",
            "INFO: Epoch 89, global step 4500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 89, global step 4500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=90` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=90` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 29: MAE=3.24, RMSE=4.37\n",
            "[I 2025-11-23 20:26:44,998] Trial 29 finished with value: 3.236654043197632 and parameters: {'context_length': 32, 'batch_size': 8, 'max_epochs': 90, 'learning_rate': 0.00022323985559533698, 'aug_prob': 0.19442685625669148}. Best is trial 20 with value: 1.3314929008483887.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 0.79539 (best 0.79539), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 0.79539 (best 0.79539), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.31180 (best 0.31180), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.31180 (best 0.31180), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.05113 (best 0.05113), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.05113 (best 0.05113), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached -0.03316 (best -0.03316), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached -0.03316 (best -0.03316), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached -0.26205 (best -0.26205), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached -0.26205 (best -0.26205), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached -0.32301 (best -0.32301), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached -0.32301 (best -0.32301), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached -0.44566 (best -0.44566), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached -0.44566 (best -0.44566), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached -0.56685 (best -0.56685), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached -0.56685 (best -0.56685), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached -0.77975 (best -0.77975), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached -0.77975 (best -0.77975), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached -0.84328 (best -0.84328), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached -0.84328 (best -0.84328), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' reached -0.93743 (best -0.93743), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' reached -0.93743 (best -0.93743), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' reached -0.95602 (best -0.95602), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' reached -0.95602 (best -0.95602), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' reached -1.05973 (best -1.05973), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' reached -1.05973 (best -1.05973), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' reached -1.18152 (best -1.18152), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' reached -1.18152 (best -1.18152), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' reached -1.21074 (best -1.21074), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' reached -1.21074 (best -1.21074), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' reached -1.37896 (best -1.37896), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=52-step=2650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' reached -1.37896 (best -1.37896), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=52-step=2650.ckpt' as top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30: MAE=6.56, RMSE=8.38\n",
            "[I 2025-11-23 20:28:41,146] Trial 30 finished with value: 6.5599141120910645 and parameters: {'context_length': 64, 'batch_size': 8, 'max_epochs': 60, 'learning_rate': 7.24351089753097e-05, 'aug_prob': 0.23448418054064207}. Best is trial 20 with value: 1.3314929008483887.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 0.98574 (best 0.98574), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 0.98574 (best 0.98574), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.60230 (best 0.60230), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.60230 (best 0.60230), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.33199 (best 0.33199), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.33199 (best 0.33199), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 0.25489 (best 0.25489), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 0.25489 (best 0.25489), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 0.16061 (best 0.16061), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 0.16061 (best 0.16061), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached -0.00358 (best -0.00358), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached -0.00358 (best -0.00358), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached -0.01093 (best -0.01093), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached -0.01093 (best -0.01093), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached -0.14679 (best -0.14679), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached -0.14679 (best -0.14679), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached -0.22334 (best -0.22334), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached -0.22334 (best -0.22334), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached -0.45028 (best -0.45028), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached -0.45028 (best -0.45028), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' reached -0.46108 (best -0.46108), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' reached -0.46108 (best -0.46108), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' reached -0.47127 (best -0.47127), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' reached -0.47127 (best -0.47127), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' reached -0.55121 (best -0.55121), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' reached -0.55121 (best -0.55121), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' reached -0.63389 (best -0.63389), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' reached -0.63389 (best -0.63389), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' reached -0.65164 (best -0.65164), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' reached -0.65164 (best -0.65164), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' reached -0.74175 (best -0.74175), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' reached -0.74175 (best -0.74175), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' reached -0.99860 (best -0.99860), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' reached -0.99860 (best -0.99860), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' reached -1.01289 (best -1.01289), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=65-step=3300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' reached -1.01289 (best -1.01289), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=65-step=3300.ckpt' as top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 31: MAE=3.79, RMSE=5.37\n",
            "[I 2025-11-23 20:31:16,734] Trial 31 finished with value: 3.7885582447052 and parameters: {'context_length': 64, 'batch_size': 32, 'max_epochs': 70, 'learning_rate': 0.0009422303842033233, 'aug_prob': 0.28069777022341535}. Best is trial 20 with value: 1.3314929008483887.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 1.04819 (best 1.04819), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 1.04819 (best 1.04819), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.64291 (best 0.64291), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.64291 (best 0.64291), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.56124 (best 0.56124), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.56124 (best 0.56124), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.34408 (best 0.34408), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.34408 (best 0.34408), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 0.09395 (best 0.09395), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 0.09395 (best 0.09395), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached -0.05503 (best -0.05503), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached -0.05503 (best -0.05503), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached -0.11591 (best -0.11591), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached -0.11591 (best -0.11591), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached -0.23533 (best -0.23533), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached -0.23533 (best -0.23533), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached -0.32963 (best -0.32963), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached -0.32963 (best -0.32963), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' reached -0.34807 (best -0.34807), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' reached -0.34807 (best -0.34807), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' reached -0.39907 (best -0.39907), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' reached -0.39907 (best -0.39907), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' reached -0.62592 (best -0.62592), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' reached -0.62592 (best -0.62592), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' reached -0.78696 (best -0.78696), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' reached -0.78696 (best -0.78696), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' reached -0.78823 (best -0.78823), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' reached -0.78823 (best -0.78823), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' reached -0.79884 (best -0.79884), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=53-step=2700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' reached -0.79884 (best -0.79884), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=53-step=2700.ckpt' as top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' reached -0.81257 (best -0.81257), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=57-step=2900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' reached -0.81257 (best -0.81257), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=57-step=2900.ckpt' as top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' reached -0.87205 (best -0.87205), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=61-step=3100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' reached -0.87205 (best -0.87205), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=61-step=3100.ckpt' as top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' reached -0.95353 (best -0.95353), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=63-step=3200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' reached -0.95353 (best -0.95353), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=63-step=3200.ckpt' as top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' reached -0.97740 (best -0.97740), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=64-step=3250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' reached -0.97740 (best -0.97740), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=64-step=3250.ckpt' as top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' reached -0.97823 (best -0.97823), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=67-step=3400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' reached -0.97823 (best -0.97823), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=67-step=3400.ckpt' as top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=80` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=80` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 32 failed: \n",
            "[I 2025-11-23 20:34:13,601] Trial 32 finished with value: inf and parameters: {'context_length': 64, 'batch_size': 32, 'max_epochs': 80, 'learning_rate': 0.0009775112789756402, 'aug_prob': 0.25845258797730203}. Best is trial 20 with value: 1.3314929008483887.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 1.00340 (best 1.00340), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 1.00340 (best 1.00340), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.64398 (best 0.64398), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.64398 (best 0.64398), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.25070 (best 0.25070), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.25070 (best 0.25070), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached -0.02891 (best -0.02891), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached -0.02891 (best -0.02891), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached -0.24769 (best -0.24769), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached -0.24769 (best -0.24769), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached -0.32628 (best -0.32628), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached -0.32628 (best -0.32628), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached -0.36070 (best -0.36070), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached -0.36070 (best -0.36070), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached -0.50726 (best -0.50726), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached -0.50726 (best -0.50726), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' reached -0.69708 (best -0.69708), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' reached -0.69708 (best -0.69708), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' reached -0.74950 (best -0.74950), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' reached -0.74950 (best -0.74950), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' reached -0.75145 (best -0.75145), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' reached -0.75145 (best -0.75145), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' reached -0.96757 (best -0.96757), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' reached -0.96757 (best -0.96757), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' reached -0.98834 (best -0.98834), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=50-step=2550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' reached -0.98834 (best -0.98834), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=50-step=2550.ckpt' as top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' reached -1.00852 (best -1.00852), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=58-step=2950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' reached -1.00852 (best -1.00852), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=58-step=2950.ckpt' as top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' reached -1.17562 (best -1.17562), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=69-step=3500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' reached -1.17562 (best -1.17562), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=69-step=3500.ckpt' as top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 33 failed: \n",
            "[I 2025-11-23 20:36:51,304] Trial 33 finished with value: inf and parameters: {'context_length': 32, 'batch_size': 32, 'max_epochs': 70, 'learning_rate': 0.0005039991246682288, 'aug_prob': 0.27523168993137787}. Best is trial 20 with value: 1.3314929008483887.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 0.87635 (best 0.87635), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 0.87635 (best 0.87635), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.44997 (best 0.44997), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.44997 (best 0.44997), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.09557 (best 0.09557), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.09557 (best 0.09557), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached -0.28993 (best -0.28993), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached -0.28993 (best -0.28993), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached -0.61265 (best -0.61265), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached -0.61265 (best -0.61265), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' reached -0.75380 (best -0.75380), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' reached -0.75380 (best -0.75380), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' reached -0.83189 (best -0.83189), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' reached -0.83189 (best -0.83189), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' reached -0.87391 (best -0.87391), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' reached -0.87391 (best -0.87391), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' reached -0.97768 (best -0.97768), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' reached -0.97768 (best -0.97768), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' reached -1.10844 (best -1.10844), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' reached -1.10844 (best -1.10844), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 34: MAE=5.68, RMSE=6.08\n",
            "[I 2025-11-23 20:39:05,499] Trial 34 finished with value: 5.683088779449463 and parameters: {'context_length': 64, 'batch_size': 32, 'max_epochs': 60, 'learning_rate': 0.0007081098297556114, 'aug_prob': 0.21160595222673628}. Best is trial 20 with value: 1.3314929008483887.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 0.75907 (best 0.75907), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 0.75907 (best 0.75907), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.28881 (best 0.28881), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.28881 (best 0.28881), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.07916 (best 0.07916), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.07916 (best 0.07916), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached -0.02625 (best -0.02625), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached -0.02625 (best -0.02625), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached -0.14652 (best -0.14652), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached -0.14652 (best -0.14652), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached -0.17437 (best -0.17437), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached -0.17437 (best -0.17437), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached -0.26569 (best -0.26569), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached -0.26569 (best -0.26569), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached -0.26700 (best -0.26700), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached -0.26700 (best -0.26700), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached -0.46687 (best -0.46687), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached -0.46687 (best -0.46687), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached -0.66999 (best -0.66999), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached -0.66999 (best -0.66999), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' reached -0.79584 (best -0.79584), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' reached -0.79584 (best -0.79584), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' reached -0.80038 (best -0.80038), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' reached -0.80038 (best -0.80038), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' reached -0.94500 (best -0.94500), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' reached -0.94500 (best -0.94500), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' reached -1.10309 (best -1.10309), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' reached -1.10309 (best -1.10309), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' reached -1.28286 (best -1.28286), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=57-step=2900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' reached -1.28286 (best -1.28286), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=57-step=2900.ckpt' as top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 80, global step 4050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 80, global step 4050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 81, global step 4100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 81, global step 4100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 82, global step 4150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 82, global step 4150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 84, global step 4250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 84, global step 4250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 85, global step 4300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 85, global step 4300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 86, global step 4350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 86, global step 4350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 88, global step 4450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 88, global step 4450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 89, global step 4500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 89, global step 4500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=90` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=90` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 35: MAE=5.32, RMSE=7.34\n",
            "[I 2025-11-23 20:42:50,792] Trial 35 finished with value: 5.3239521980285645 and parameters: {'context_length': 96, 'batch_size': 32, 'max_epochs': 90, 'learning_rate': 0.00034898408997423574, 'aug_prob': 0.29861470665311024}. Best is trial 20 with value: 1.3314929008483887.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 0.79586 (best 0.79586), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 0.79586 (best 0.79586), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.28949 (best 0.28949), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.28949 (best 0.28949), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.01963 (best 0.01963), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.01963 (best 0.01963), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached -0.08150 (best -0.08150), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached -0.08150 (best -0.08150), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached -0.16088 (best -0.16088), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached -0.16088 (best -0.16088), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached -0.32786 (best -0.32786), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached -0.32786 (best -0.32786), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached -0.49185 (best -0.49185), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached -0.49185 (best -0.49185), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached -0.53162 (best -0.53162), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached -0.53162 (best -0.53162), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached -0.54319 (best -0.54319), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached -0.54319 (best -0.54319), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached -0.78391 (best -0.78391), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached -0.78391 (best -0.78391), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' reached -0.79011 (best -0.79011), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' reached -0.79011 (best -0.79011), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' reached -1.07416 (best -1.07416), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' reached -1.07416 (best -1.07416), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' reached -1.17098 (best -1.17098), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' reached -1.17098 (best -1.17098), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' reached -1.29863 (best -1.29863), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' reached -1.29863 (best -1.29863), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' reached -1.34361 (best -1.34361), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=53-step=2700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' reached -1.34361 (best -1.34361), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=53-step=2700.ckpt' as top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' reached -1.56915 (best -1.56915), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=62-step=3150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' reached -1.56915 (best -1.56915), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=62-step=3150.ckpt' as top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 36 failed: \n",
            "[I 2025-11-23 20:45:13,646] Trial 36 finished with value: inf and parameters: {'context_length': 64, 'batch_size': 16, 'max_epochs': 70, 'learning_rate': 0.00014946476932774713, 'aug_prob': 0.2504083546846964}. Best is trial 20 with value: 1.3314929008483887.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 0.86613 (best 0.86613), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 0.86613 (best 0.86613), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.34957 (best 0.34957), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.34957 (best 0.34957), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.12562 (best 0.12562), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.12562 (best 0.12562), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached -0.06785 (best -0.06785), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached -0.06785 (best -0.06785), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached -0.14559 (best -0.14559), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached -0.14559 (best -0.14559), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached -0.32839 (best -0.32839), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached -0.32839 (best -0.32839), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached -0.32914 (best -0.32914), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached -0.32914 (best -0.32914), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached -0.62235 (best -0.62235), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached -0.62235 (best -0.62235), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached -0.69230 (best -0.69230), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached -0.69230 (best -0.69230), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' reached -0.79225 (best -0.79225), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' reached -0.79225 (best -0.79225), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' reached -0.79445 (best -0.79445), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' reached -0.79445 (best -0.79445), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' reached -0.88911 (best -0.88911), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' reached -0.88911 (best -0.88911), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' reached -0.98871 (best -0.98871), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' reached -0.98871 (best -0.98871), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' reached -1.06010 (best -1.06010), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=58-step=2950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' reached -1.06010 (best -1.06010), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=58-step=2950.ckpt' as top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 37: MAE=4.41, RMSE=6.40\n",
            "[I 2025-11-23 20:47:43,761] Trial 37 finished with value: 4.407979965209961 and parameters: {'context_length': 96, 'batch_size': 32, 'max_epochs': 60, 'learning_rate': 0.0004740306174623648, 'aug_prob': 0.2775379403222826}. Best is trial 20 with value: 1.3314929008483887.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 0.74006 (best 0.74006), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 0.74006 (best 0.74006), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.16721 (best 0.16721), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.16721 (best 0.16721), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached -0.05270 (best -0.05270), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached -0.05270 (best -0.05270), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached -0.33360 (best -0.33360), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached -0.33360 (best -0.33360), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached -0.46158 (best -0.46158), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached -0.46158 (best -0.46158), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached -0.58930 (best -0.58930), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached -0.58930 (best -0.58930), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached -0.73771 (best -0.73771), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached -0.73771 (best -0.73771), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached -0.80555 (best -0.80555), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached -0.80555 (best -0.80555), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' reached -0.83479 (best -0.83479), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' reached -0.83479 (best -0.83479), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' reached -1.02931 (best -1.02931), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' reached -1.02931 (best -1.02931), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' reached -1.15823 (best -1.15823), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' reached -1.15823 (best -1.15823), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' reached -1.17448 (best -1.17448), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' reached -1.17448 (best -1.17448), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' reached -1.30002 (best -1.30002), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' reached -1.30002 (best -1.30002), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' reached -1.34444 (best -1.34444), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' reached -1.34444 (best -1.34444), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' reached -1.57845 (best -1.57845), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' reached -1.57845 (best -1.57845), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 70, global step 3550: 'train_loss' reached -1.75279 (best -1.75279), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=70-step=3550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 70, global step 3550: 'train_loss' reached -1.75279 (best -1.75279), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=70-step=3550.ckpt' as top 1\n",
            "INFO: Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=80` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=80` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 38 failed: \n",
            "[I 2025-11-23 20:50:25,771] Trial 38 finished with value: inf and parameters: {'context_length': 64, 'batch_size': 16, 'max_epochs': 80, 'learning_rate': 9.92043869645724e-05, 'aug_prob': 0.21030310412508207}. Best is trial 20 with value: 1.3314929008483887.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 1.05878 (best 1.05878), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 1.05878 (best 1.05878), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.64269 (best 0.64269), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.64269 (best 0.64269), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.54208 (best 0.54208), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.54208 (best 0.54208), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.27313 (best 0.27313), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.27313 (best 0.27313), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 0.04077 (best 0.04077), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 0.04077 (best 0.04077), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached -0.01132 (best -0.01132), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached -0.01132 (best -0.01132), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached -0.26229 (best -0.26229), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached -0.26229 (best -0.26229), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached -0.28536 (best -0.28536), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached -0.28536 (best -0.28536), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached -0.33771 (best -0.33771), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached -0.33771 (best -0.33771), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached -0.42369 (best -0.42369), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached -0.42369 (best -0.42369), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' reached -0.68204 (best -0.68204), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' reached -0.68204 (best -0.68204), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' reached -0.69256 (best -0.69256), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' reached -0.69256 (best -0.69256), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' reached -0.79366 (best -0.79366), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' reached -0.79366 (best -0.79366), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' reached -0.82467 (best -0.82467), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' reached -0.82467 (best -0.82467), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' reached -0.88878 (best -0.88878), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' reached -0.88878 (best -0.88878), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' reached -0.95872 (best -0.95872), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=55-step=2800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' reached -0.95872 (best -0.95872), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=55-step=2800.ckpt' as top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 39 failed: \n",
            "[I 2025-11-23 20:52:41,864] Trial 39 finished with value: inf and parameters: {'context_length': 32, 'batch_size': 32, 'max_epochs': 60, 'learning_rate': 1.84695549144325e-05, 'aug_prob': 0.2848479374987658}. Best is trial 20 with value: 1.3314929008483887.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 1.08408 (best 1.08408), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 1.08408 (best 1.08408), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.64269 (best 0.64269), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.64269 (best 0.64269), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.38553 (best 0.38553), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.38553 (best 0.38553), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.31039 (best 0.31039), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.31039 (best 0.31039), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached -0.01804 (best -0.01804), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached -0.01804 (best -0.01804), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached -0.24460 (best -0.24460), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached -0.24460 (best -0.24460), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached -0.45171 (best -0.45171), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached -0.45171 (best -0.45171), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached -0.57279 (best -0.57279), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached -0.57279 (best -0.57279), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached -0.59887 (best -0.59887), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached -0.59887 (best -0.59887), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' reached -0.60220 (best -0.60220), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' reached -0.60220 (best -0.60220), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached -0.68180 (best -0.68180), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached -0.68180 (best -0.68180), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' reached -0.74284 (best -0.74284), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' reached -0.74284 (best -0.74284), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' reached -0.85111 (best -0.85111), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' reached -0.85111 (best -0.85111), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' reached -0.86760 (best -0.86760), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' reached -0.86760 (best -0.86760), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' reached -0.91200 (best -0.91200), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' reached -0.91200 (best -0.91200), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' reached -0.98712 (best -0.98712), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' reached -0.98712 (best -0.98712), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' reached -1.06304 (best -1.06304), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' reached -1.06304 (best -1.06304), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' reached -1.07345 (best -1.07345), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=50-step=2550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' reached -1.07345 (best -1.07345), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=50-step=2550.ckpt' as top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' reached -1.10436 (best -1.10436), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=53-step=2700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' reached -1.10436 (best -1.10436), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=53-step=2700.ckpt' as top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' reached -1.19002 (best -1.19002), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=55-step=2800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' reached -1.19002 (best -1.19002), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=55-step=2800.ckpt' as top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' reached -1.21709 (best -1.21709), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=62-step=3150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' reached -1.21709 (best -1.21709), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=62-step=3150.ckpt' as top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 75, global step 3800: 'train_loss' reached -1.24453 (best -1.24453), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=75-step=3800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 75, global step 3800: 'train_loss' reached -1.24453 (best -1.24453), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=75-step=3800.ckpt' as top 1\n",
            "INFO: Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 79, global step 4000: 'train_loss' reached -1.27525 (best -1.27525), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=79-step=4000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 79, global step 4000: 'train_loss' reached -1.27525 (best -1.27525), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=79-step=4000.ckpt' as top 1\n",
            "INFO: Epoch 80, global step 4050: 'train_loss' reached -1.28884 (best -1.28884), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=80-step=4050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 80, global step 4050: 'train_loss' reached -1.28884 (best -1.28884), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=80-step=4050.ckpt' as top 1\n",
            "INFO: Epoch 81, global step 4100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 81, global step 4100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 82, global step 4150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 82, global step 4150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 84, global step 4250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 84, global step 4250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 85, global step 4300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 85, global step 4300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 86, global step 4350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 86, global step 4350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 88, global step 4450: 'train_loss' reached -1.33322 (best -1.33322), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=88-step=4450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 88, global step 4450: 'train_loss' reached -1.33322 (best -1.33322), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=88-step=4450.ckpt' as top 1\n",
            "INFO: Epoch 89, global step 4500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 89, global step 4500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 90, global step 4550: 'train_loss' reached -1.41519 (best -1.41519), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=90-step=4550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 90, global step 4550: 'train_loss' reached -1.41519 (best -1.41519), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=90-step=4550.ckpt' as top 1\n",
            "INFO: Epoch 91, global step 4600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 91, global step 4600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 92, global step 4650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 92, global step 4650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 93, global step 4700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 93, global step 4700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 94, global step 4750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 94, global step 4750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 95, global step 4800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 95, global step 4800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 96, global step 4850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 96, global step 4850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 97, global step 4900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 97, global step 4900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 98, global step 4950: 'train_loss' reached -1.56689 (best -1.56689), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=98-step=4950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 98, global step 4950: 'train_loss' reached -1.56689 (best -1.56689), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=98-step=4950.ckpt' as top 1\n",
            "INFO: Epoch 99, global step 5000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 99, global step 5000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=100` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=100` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 40: MAE=8.23, RMSE=10.55\n",
            "[I 2025-11-23 20:55:56,054] Trial 40 finished with value: 8.23146915435791 and parameters: {'context_length': 64, 'batch_size': 8, 'max_epochs': 100, 'learning_rate': 0.0007234304534639039, 'aug_prob': 0.07062554556640983}. Best is trial 20 with value: 1.3314929008483887.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 1.02093 (best 1.02093), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 1.02093 (best 1.02093), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.49974 (best 0.49974), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.49974 (best 0.49974), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.48638 (best 0.48638), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.48638 (best 0.48638), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.28567 (best 0.28567), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.28567 (best 0.28567), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 0.17074 (best 0.17074), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 0.17074 (best 0.17074), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached -0.08702 (best -0.08702), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached -0.08702 (best -0.08702), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached -0.10691 (best -0.10691), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached -0.10691 (best -0.10691), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached -0.12372 (best -0.12372), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached -0.12372 (best -0.12372), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached -0.45325 (best -0.45325), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached -0.45325 (best -0.45325), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' reached -0.65313 (best -0.65313), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' reached -0.65313 (best -0.65313), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' reached -0.73713 (best -0.73713), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' reached -0.73713 (best -0.73713), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' reached -0.75437 (best -0.75437), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' reached -0.75437 (best -0.75437), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' reached -0.77581 (best -0.77581), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' reached -0.77581 (best -0.77581), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' reached -0.83442 (best -0.83442), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' reached -0.83442 (best -0.83442), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' reached -0.84070 (best -0.84070), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' reached -0.84070 (best -0.84070), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' reached -0.85740 (best -0.85740), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' reached -0.85740 (best -0.85740), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=50` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=50` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 41: MAE=1.82, RMSE=2.52\n",
            "[I 2025-11-23 20:57:47,182] Trial 41 finished with value: 1.8229628801345825 and parameters: {'context_length': 64, 'batch_size': 32, 'max_epochs': 50, 'learning_rate': 0.0006080064526926603, 'aug_prob': 0.2689744521919199}. Best is trial 20 with value: 1.3314929008483887.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 1.31216 (best 1.31216), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 1.31216 (best 1.31216), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.64873 (best 0.64873), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.64873 (best 0.64873), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.55619 (best 0.55619), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.55619 (best 0.55619), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.36945 (best 0.36945), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.36945 (best 0.36945), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 0.16988 (best 0.16988), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 0.16988 (best 0.16988), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 0.16774 (best 0.16774), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 0.16774 (best 0.16774), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached -0.17067 (best -0.17067), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached -0.17067 (best -0.17067), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached -0.38402 (best -0.38402), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached -0.38402 (best -0.38402), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached -0.39877 (best -0.39877), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached -0.39877 (best -0.39877), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' reached -0.42734 (best -0.42734), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' reached -0.42734 (best -0.42734), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' reached -0.50272 (best -0.50272), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' reached -0.50272 (best -0.50272), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' reached -0.65127 (best -0.65127), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' reached -0.65127 (best -0.65127), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' reached -0.70689 (best -0.70689), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' reached -0.70689 (best -0.70689), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' reached -0.73591 (best -0.73591), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' reached -0.73591 (best -0.73591), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' reached -0.76733 (best -0.76733), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' reached -0.76733 (best -0.76733), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=40` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=40` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 42: MAE=1.85, RMSE=2.42\n",
            "[I 2025-11-23 20:59:19,266] Trial 42 finished with value: 1.8459614515304565 and parameters: {'context_length': 64, 'batch_size': 32, 'max_epochs': 40, 'learning_rate': 0.0009779910895910667, 'aug_prob': 0.26104881336110786}. Best is trial 20 with value: 1.3314929008483887.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 0.92991 (best 0.92991), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 0.92991 (best 0.92991), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.50922 (best 0.50922), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.50922 (best 0.50922), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.15252 (best 0.15252), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.15252 (best 0.15252), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.04141 (best 0.04141), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.04141 (best 0.04141), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached -0.09449 (best -0.09449), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached -0.09449 (best -0.09449), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached -0.26246 (best -0.26246), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached -0.26246 (best -0.26246), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached -0.36511 (best -0.36511), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached -0.36511 (best -0.36511), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached -0.61417 (best -0.61417), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached -0.61417 (best -0.61417), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' reached -0.71111 (best -0.71111), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' reached -0.71111 (best -0.71111), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' reached -0.77322 (best -0.77322), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' reached -0.77322 (best -0.77322), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' reached -0.78367 (best -0.78367), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' reached -0.78367 (best -0.78367), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' reached -1.03471 (best -1.03471), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' reached -1.03471 (best -1.03471), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=40` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=40` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 43 failed: \n",
            "[I 2025-11-23 21:00:53,409] Trial 43 finished with value: inf and parameters: {'context_length': 64, 'batch_size': 32, 'max_epochs': 40, 'learning_rate': 0.0005662737721496156, 'aug_prob': 0.23704012036019537}. Best is trial 20 with value: 1.3314929008483887.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 1.11047 (best 1.11047), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 1.11047 (best 1.11047), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.51041 (best 0.51041), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.51041 (best 0.51041), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.33848 (best 0.33848), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.33848 (best 0.33848), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.24140 (best 0.24140), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.24140 (best 0.24140), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached -0.06773 (best -0.06773), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached -0.06773 (best -0.06773), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached -0.17348 (best -0.17348), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached -0.17348 (best -0.17348), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached -0.32502 (best -0.32502), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached -0.32502 (best -0.32502), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached -0.43206 (best -0.43206), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached -0.43206 (best -0.43206), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' reached -0.58698 (best -0.58698), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' reached -0.58698 (best -0.58698), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' reached -0.62165 (best -0.62165), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' reached -0.62165 (best -0.62165), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' reached -0.69009 (best -0.69009), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' reached -0.69009 (best -0.69009), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' reached -0.93284 (best -0.93284), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' reached -0.93284 (best -0.93284), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=50` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=50` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 44: MAE=3.60, RMSE=4.08\n",
            "[I 2025-11-23 21:03:00,412] Trial 44 finished with value: 3.596691846847534 and parameters: {'context_length': 96, 'batch_size': 32, 'max_epochs': 50, 'learning_rate': 0.000787580519059715, 'aug_prob': 0.287767582160027}. Best is trial 20 with value: 1.3314929008483887.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 0.91542 (best 0.91542), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 0.91542 (best 0.91542), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.38750 (best 0.38750), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.38750 (best 0.38750), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.15706 (best 0.15706), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.15706 (best 0.15706), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.00117 (best 0.00117), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.00117 (best 0.00117), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached -0.22897 (best -0.22897), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached -0.22897 (best -0.22897), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached -0.23267 (best -0.23267), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached -0.23267 (best -0.23267), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached -0.38152 (best -0.38152), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached -0.38152 (best -0.38152), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached -0.66435 (best -0.66435), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached -0.66435 (best -0.66435), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached -0.78852 (best -0.78852), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached -0.78852 (best -0.78852), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' reached -0.83994 (best -0.83994), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' reached -0.83994 (best -0.83994), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' reached -0.96799 (best -0.96799), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' reached -0.96799 (best -0.96799), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' reached -0.97542 (best -0.97542), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' reached -0.97542 (best -0.97542), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' reached -0.97931 (best -0.97931), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' reached -0.97931 (best -0.97931), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' reached -1.02959 (best -1.02959), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' reached -1.02959 (best -1.02959), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' reached -1.03788 (best -1.03788), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' reached -1.03788 (best -1.03788), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' reached -1.06270 (best -1.06270), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=58-step=2950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' reached -1.06270 (best -1.06270), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=58-step=2950.ckpt' as top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' reached -1.06541 (best -1.06541), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=59-step=3000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' reached -1.06541 (best -1.06541), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=59-step=3000.ckpt' as top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 45: MAE=2.55, RMSE=2.82\n",
            "[I 2025-11-23 21:05:21,050] Trial 45 finished with value: 2.5505590438842773 and parameters: {'context_length': 64, 'batch_size': 32, 'max_epochs': 60, 'learning_rate': 0.0004069294150609219, 'aug_prob': 0.24532040786925605}. Best is trial 20 with value: 1.3314929008483887.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 0.83471 (best 0.83471), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 0.83471 (best 0.83471), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.33282 (best 0.33282), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.33282 (best 0.33282), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.05924 (best 0.05924), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.05924 (best 0.05924), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached -0.16119 (best -0.16119), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached -0.16119 (best -0.16119), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached -0.17455 (best -0.17455), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached -0.17455 (best -0.17455), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached -0.31021 (best -0.31021), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached -0.31021 (best -0.31021), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached -0.41338 (best -0.41338), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached -0.41338 (best -0.41338), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached -0.53337 (best -0.53337), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached -0.53337 (best -0.53337), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached -0.64693 (best -0.64693), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached -0.64693 (best -0.64693), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached -0.77720 (best -0.77720), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached -0.77720 (best -0.77720), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' reached -0.79021 (best -0.79021), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' reached -0.79021 (best -0.79021), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' reached -0.82307 (best -0.82307), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' reached -0.82307 (best -0.82307), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' reached -0.87408 (best -0.87408), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' reached -0.87408 (best -0.87408), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' reached -0.89465 (best -0.89465), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' reached -0.89465 (best -0.89465), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' reached -0.91458 (best -0.91458), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' reached -0.91458 (best -0.91458), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' reached -0.99449 (best -0.99449), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' reached -0.99449 (best -0.99449), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' reached -1.09047 (best -1.09047), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' reached -1.09047 (best -1.09047), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' reached -1.14216 (best -1.14216), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' reached -1.14216 (best -1.14216), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' reached -1.33690 (best -1.33690), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' reached -1.33690 (best -1.33690), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' reached -1.39038 (best -1.39038), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=62-step=3150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' reached -1.39038 (best -1.39038), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=62-step=3150.ckpt' as top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 46 failed: \n",
            "[I 2025-11-23 21:07:53,606] Trial 46 finished with value: inf and parameters: {'context_length': 64, 'batch_size': 16, 'max_epochs': 70, 'learning_rate': 0.00027221925517055296, 'aug_prob': 0.17364882459869355}. Best is trial 20 with value: 1.3314929008483887.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 0.99525 (best 0.99525), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 0.99525 (best 0.99525), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.46600 (best 0.46600), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.46600 (best 0.46600), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.32234 (best 0.32234), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.32234 (best 0.32234), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached -0.01965 (best -0.01965), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached -0.01965 (best -0.01965), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached -0.04129 (best -0.04129), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached -0.04129 (best -0.04129), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached -0.34430 (best -0.34430), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached -0.34430 (best -0.34430), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached -0.50507 (best -0.50507), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached -0.50507 (best -0.50507), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached -0.50745 (best -0.50745), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached -0.50745 (best -0.50745), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' reached -0.51258 (best -0.51258), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' reached -0.51258 (best -0.51258), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' reached -0.52755 (best -0.52755), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' reached -0.52755 (best -0.52755), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' reached -0.54020 (best -0.54020), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' reached -0.54020 (best -0.54020), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' reached -0.72315 (best -0.72315), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' reached -0.72315 (best -0.72315), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=30` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=30` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 47: MAE=2.39, RMSE=2.96\n",
            "[I 2025-11-23 21:09:03,960] Trial 47 finished with value: 2.391014575958252 and parameters: {'context_length': 64, 'batch_size': 32, 'max_epochs': 30, 'learning_rate': 0.0008357710502409979, 'aug_prob': 0.2672062008615014}. Best is trial 20 with value: 1.3314929008483887.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 0.90737 (best 0.90737), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 0.90737 (best 0.90737), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.43697 (best 0.43697), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.43697 (best 0.43697), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.25067 (best 0.25067), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.25067 (best 0.25067), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.21798 (best 0.21798), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.21798 (best 0.21798), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 0.05329 (best 0.05329), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 0.05329 (best 0.05329), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached -0.07877 (best -0.07877), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached -0.07877 (best -0.07877), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached -0.41601 (best -0.41601), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached -0.41601 (best -0.41601), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached -0.47297 (best -0.47297), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached -0.47297 (best -0.47297), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' reached -0.51661 (best -0.51661), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' reached -0.51661 (best -0.51661), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' reached -0.63413 (best -0.63413), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' reached -0.63413 (best -0.63413), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' reached -0.67598 (best -0.67598), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' reached -0.67598 (best -0.67598), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' reached -0.69602 (best -0.69602), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' reached -0.69602 (best -0.69602), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' reached -0.83629 (best -0.83629), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' reached -0.83629 (best -0.83629), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' reached -0.87700 (best -0.87700), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' reached -0.87700 (best -0.87700), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' reached -0.91196 (best -0.91196), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' reached -0.91196 (best -0.91196), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' reached -1.00851 (best -1.00851), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=51-step=2600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' reached -1.00851 (best -1.00851), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=51-step=2600.ckpt' as top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' reached -1.05310 (best -1.05310), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=57-step=2900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' reached -1.05310 (best -1.05310), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=57-step=2900.ckpt' as top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 80, global step 4050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 80, global step 4050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 81, global step 4100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 81, global step 4100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 82, global step 4150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 82, global step 4150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 84, global step 4250: 'train_loss' reached -1.07651 (best -1.07651), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=84-step=4250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 84, global step 4250: 'train_loss' reached -1.07651 (best -1.07651), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=84-step=4250.ckpt' as top 1\n",
            "INFO: Epoch 85, global step 4300: 'train_loss' reached -1.19359 (best -1.19359), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=85-step=4300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 85, global step 4300: 'train_loss' reached -1.19359 (best -1.19359), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=85-step=4300.ckpt' as top 1\n",
            "INFO: Epoch 86, global step 4350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 86, global step 4350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 88, global step 4450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 88, global step 4450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 89, global step 4500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 89, global step 4500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=90` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=90` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 48: MAE=3.26, RMSE=4.86\n",
            "[I 2025-11-23 21:12:28,439] Trial 48 finished with value: 3.258681297302246 and parameters: {'context_length': 64, 'batch_size': 32, 'max_epochs': 90, 'learning_rate': 0.0005819016067308687, 'aug_prob': 0.28937565168575885}. Best is trial 20 with value: 1.3314929008483887.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 1.27260 (best 1.27260), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 1.27260 (best 1.27260), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.78793 (best 0.78793), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.78793 (best 0.78793), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.52013 (best 0.52013), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.52013 (best 0.52013), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.29635 (best 0.29635), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.29635 (best 0.29635), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 0.22572 (best 0.22572), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 0.22572 (best 0.22572), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 0.13051 (best 0.13051), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 0.13051 (best 0.13051), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached -0.09258 (best -0.09258), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached -0.09258 (best -0.09258), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached -0.10434 (best -0.10434), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached -0.10434 (best -0.10434), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached -0.12822 (best -0.12822), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached -0.12822 (best -0.12822), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached -0.23548 (best -0.23548), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached -0.23548 (best -0.23548), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached -0.37080 (best -0.37080), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached -0.37080 (best -0.37080), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' reached -0.49235 (best -0.49235), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' reached -0.49235 (best -0.49235), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' reached -0.51921 (best -0.51921), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' reached -0.51921 (best -0.51921), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' reached -0.60063 (best -0.60063), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' reached -0.60063 (best -0.60063), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' reached -0.66726 (best -0.66726), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' reached -0.66726 (best -0.66726), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' reached -0.69540 (best -0.69540), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' reached -0.69540 (best -0.69540), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' reached -0.81724 (best -0.81724), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' reached -0.81724 (best -0.81724), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' reached -0.99819 (best -0.99819), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' reached -0.99819 (best -0.99819), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' reached -1.03472 (best -1.03472), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=68-step=3450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' reached -1.03472 (best -1.03472), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=68-step=3450.ckpt' as top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=80` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=80` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 49: MAE=1.33, RMSE=1.67\n",
            "[I 2025-11-23 21:15:14,962] Trial 49 finished with value: 1.3296008110046387 and parameters: {'context_length': 64, 'batch_size': 16, 'max_epochs': 80, 'learning_rate': 0.0009908246534102456, 'aug_prob': 0.22234275927777986}. Best is trial 49 with value: 1.3296008110046387.\n",
            "\n",
            "======================================================================\n",
            "✅ OPTIMIZATION COMPLETE!\n",
            "======================================================================\n",
            "\n",
            "🏆 BEST HYPERPARAMETERS:\n",
            "--------------------------------------------------\n",
            "  • context_length: 64\n",
            "  • batch_size: 16\n",
            "  • max_epochs: 80\n",
            "  • learning_rate: 0.0009908246534102456\n",
            "  • aug_prob: 0.22234275927777986\n",
            "\n",
            "📊 BEST VALIDATION MAE: 1.33\n",
            "📈 Total trials completed: 50\n",
            "✓ Completed: 50\n",
            "✗ Pruned: 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "🎯 TRAINING FINAL MODEL WITH BEST HYPERPARAMETERS\n",
            "======================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7ccecf24ff64cb5b891bbe4874daa51"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 1.31194 (best 1.31194), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 1.31194 (best 1.31194), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.63052 (best 0.63052), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.63052 (best 0.63052), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.42055 (best 0.42055), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.42055 (best 0.42055), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 0.35223 (best 0.35223), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 0.35223 (best 0.35223), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 0.35078 (best 0.35078), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 0.35078 (best 0.35078), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 0.17970 (best 0.17970), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 0.17970 (best 0.17970), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached 0.06103 (best 0.06103), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 0.06103 (best 0.06103), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached -0.10568 (best -0.10568), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached -0.10568 (best -0.10568), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached -0.15528 (best -0.15528), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached -0.15528 (best -0.15528), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached -0.26510 (best -0.26510), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached -0.26510 (best -0.26510), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' reached -0.51342 (best -0.51342), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' reached -0.51342 (best -0.51342), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' reached -0.57492 (best -0.57492), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' reached -0.57492 (best -0.57492), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' reached -0.74233 (best -0.74233), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' reached -0.74233 (best -0.74233), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' reached -0.82219 (best -0.82219), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=56-step=2850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' reached -0.82219 (best -0.82219), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=56-step=2850.ckpt' as top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' reached -0.88848 (best -0.88848), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=57-step=2900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' reached -0.88848 (best -0.88848), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=57-step=2900.ckpt' as top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' reached -0.88982 (best -0.88982), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=62-step=3150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' reached -0.88982 (best -0.88982), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=62-step=3150.ckpt' as top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' reached -0.97869 (best -0.97869), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=68-step=3450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' reached -0.97869 (best -0.97869), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=68-step=3450.ckpt' as top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 73, global step 3700: 'train_loss' reached -1.03584 (best -1.03584), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=73-step=3700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 73, global step 3700: 'train_loss' reached -1.03584 (best -1.03584), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=73-step=3700.ckpt' as top 1\n",
            "INFO: Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=80` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=80` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "✅ FINAL MODEL EVALUATION (TEST SET)\n",
            "======================================================================\n",
            "\n",
            "📊 ACCURACY METRICS:\n",
            "  • MAE (Mean Absolute Error):        4.12\n",
            "  • RMSE (Root Mean Squared Error):   4.47\n",
            "  • MAPE (Mean Absolute % Error):     12.7%\n",
            "\n",
            "🏆 BEST HYPERPARAMETERS USED:\n",
            "  • context_length: 64\n",
            "  • batch_size: 16\n",
            "  • max_epochs: 80\n",
            "  • learning_rate: 0.0009908246534102456\n",
            "  • aug_prob: 0.22234275927777986\n",
            "\n",
            "📋 WEEK-BY-WEEK COMPARISON:\n",
            "Week   Actual     Forecast   Error      % Error   \n",
            "--------------------------------------------------\n",
            "1      34.07      34.50      0.43       1.3       %\n",
            "2      31.91      34.63      2.71       8.5       %\n",
            "3      31.50      33.80      2.30       7.3       %\n",
            "4      31.14      35.73      4.59       14.7      %\n",
            "5      31.84      36.76      4.93       15.5      %\n",
            "6      29.29      36.20      6.91       23.6      %\n",
            "7      32.96      36.90      3.94       12.0      %\n",
            "8      32.97      38.55      5.59       16.9      %\n",
            "9      33.97      39.25      5.28       15.5      %\n",
            "10     35.12      39.48      4.36       12.4      %\n",
            "11     35.67      38.23      2.56       7.2       %\n",
            "12     34.01      39.82      5.81       17.1      %\n",
            "\n",
            "======================================================================\n",
            "\n",
            "💾 Best hyperparameters saved to 'best_hyperparameters.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# CRITICAL FIX: Patch torch.load ONCE at module level\n",
        "# ---------------------------------------------------------------------------\n",
        "import torch.serialization\n",
        "\n",
        "if not hasattr(torch.serialization, '_original_torch_load_backup'):\n",
        "    torch.serialization._original_torch_load_backup = torch.serialization.load\n",
        "\n",
        "def safe_torch_load(*args, **kwargs):\n",
        "    \"\"\"Wrapper that adds weights_only=False by default\"\"\"\n",
        "    if 'weights_only' not in kwargs:\n",
        "        kwargs['weights_only'] = False\n",
        "    return torch.serialization._original_torch_load_backup(*args, **kwargs)\n",
        "\n",
        "# Apply the patch\n",
        "torch.load = safe_torch_load\n",
        "torch.serialization.load = safe_torch_load\n",
        "\n",
        "print(\"✓ torch.load patched successfully\")\n",
        "\n",
        "# GluonTS imports\n",
        "from gluonts.dataset.pandas import PandasDataset\n",
        "from gluonts.evaluation import make_evaluation_predictions, Evaluator\n",
        "from lag_llama.gluon.estimator import LagLlamaEstimator\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 1. LOAD AND PREPROCESS DATA\n",
        "# ---------------------------------------------------------------------------\n",
        "filename = '/content/macro_index_Family_Newcomer_Services_only.csv'\n",
        "\n",
        "if not os.path.exists(filename):\n",
        "    filename = 'macro_index_Family_Newcomer_Services_only.csv'\n",
        "\n",
        "if not os.path.exists(filename):\n",
        "    print(f\"❌ Error: {filename} not found. Please upload your CSV file.\")\n",
        "    raise FileNotFoundError(\"Please upload macro_index_Family_Newcomer_Services_only.csv\")\n",
        "\n",
        "df = pd.read_csv(filename)\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df.set_index('date', inplace=True)\n",
        "df = df.asfreq('W-SUN')\n",
        "df = df.ffill().bfill()\n",
        "\n",
        "# CRITICAL: Convert all numeric data to float32\n",
        "num_cols = df.select_dtypes(include=[np.number]).columns\n",
        "df[num_cols] = df[num_cols].astype('float32')\n",
        "\n",
        "print(f\"✓ Data Loaded. Shape: {df.shape}\")\n",
        "print(f\"✓ Date range: {df.index[0]} to {df.index[-1]}\")\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 2. FEATURE SELECTION\n",
        "# ---------------------------------------------------------------------------\n",
        "target_col = 'Family Newcomer Services_EMA13'\n",
        "\n",
        "# OPTION: Use NO exogenous features (univariate forecasting)\n",
        "use_exogenous = True\n",
        "\n",
        "if use_exogenous:\n",
        "    selected_features = [\n",
        "    'FXUSDCAD', 'FXEURCAD', 'CPIAUCSL', 'DTWEXBGS', 'DGS10',\n",
        "        'goc_long_benchmark', 'goc_long_benchmark1'\n",
        "    ]\n",
        "    selected_features = [f for f in selected_features if f in df.columns]\n",
        "    print(f\"\\n✓ Using {len(selected_features)} exogenous features\")\n",
        "else:\n",
        "    selected_features = []\n",
        "    print(f\"\\n✓ Using UNIVARIATE forecasting (no exogenous features)\")\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 3. PROPER TRAIN/TEST SPLIT\n",
        "# ---------------------------------------------------------------------------\n",
        "prediction_length = 12\n",
        "context_length = 64\n",
        "\n",
        "# Split data properly - reserve last 12 weeks for testing\n",
        "split_point = len(df) - prediction_length\n",
        "\n",
        "train_df = df.iloc[:split_point]\n",
        "test_df = df.iloc[:split_point]  # TEST DATASET SHOULD NOT INCLUDE FUTURE DATA\n",
        "\n",
        "print(f\"\\n✓ Train dataset: {len(train_df)} weeks (up to {train_df.index[-1]})\")\n",
        "print(f\"✓ Holdout period: {prediction_length} weeks (from {df.index[split_point]})\")\n",
        "print(f\"✓ Last actual value in training: {train_df[target_col].iloc[-1]:.2f}\")\n",
        "\n",
        "# Create datasets\n",
        "if selected_features:\n",
        "    train_ds = PandasDataset(train_df, target=target_col, feat_dynamic_real=selected_features, freq=\"W-SUN\")\n",
        "    test_ds = PandasDataset(test_df, target=target_col, feat_dynamic_real=selected_features, freq=\"W-SUN\")\n",
        "else:\n",
        "    train_ds = PandasDataset(train_df, target=target_col, freq=\"W-SUN\")\n",
        "    test_ds = PandasDataset(test_df, target=target_col, freq=\"W-SUN\")\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 4. LOAD AND FINE-TUNE MODEL\n",
        "# ---------------------------------------------------------------------------\n",
        "print(\"\\nDownloading Lag-Llama checkpoint...\")\n",
        "!huggingface-cli download time-series-foundation-models/Lag-Llama lag-llama.ckpt --local-dir .\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"✓ Using device: {device}\")\n",
        "\n",
        "ckpt_path = \"lag-llama.ckpt\"\n",
        "ckpt = torch.load(ckpt_path, map_location=device)\n",
        "estimator_args = ckpt[\"hyper_parameters\"][\"model_kwargs\"]\n",
        "\n",
        "estimator = LagLlamaEstimator(\n",
        "    ckpt_path=ckpt_path,\n",
        "    prediction_length=prediction_length,\n",
        "    context_length=context_length,\n",
        "    n_layer=estimator_args[\"n_layer\"],\n",
        "    n_embd_per_head=estimator_args[\"n_embd_per_head\"],\n",
        "    n_head=estimator_args[\"n_head\"],\n",
        "    scaling=estimator_args[\"scaling\"],\n",
        "    time_feat=estimator_args[\"time_feat\"],\n",
        "    aug_prob=0.22234275927777986,  # Disable augmentations\n",
        "    lr=0.0009908246534102456,\n",
        "    batch_size=16,  # Reduced for stability\n",
        "    num_parallel_samples=100,\n",
        "    trainer_kwargs={\n",
        "        \"accelerator\": device,\n",
        "        \"max_epochs\": 80,  # Reduced to prevent overfitting\n",
        "    },\n",
        ")\n",
        "\n",
        "print(\"\\n🚀 Starting Fine-Tuning...\")\n",
        "predictor = estimator.train(\n",
        "    training_data=train_ds,\n",
        "    cache_data=True,\n",
        "    shuffle_buffer_length=1000\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 5. PREDICT AND EVALUATE\n",
        "# ---------------------------------------------------------------------------\n",
        "print(\"\\n📊 Generating Forecasts...\")\n",
        "forecast_it, ts_it = make_evaluation_predictions(\n",
        "    dataset=test_ds,\n",
        "    predictor=predictor,\n",
        "    num_samples=100\n",
        ")\n",
        "\n",
        "forecasts = list(forecast_it)\n",
        "tss = list(ts_it)\n",
        "\n",
        "# Get actual values for the forecast period\n",
        "actual_values = df[target_col].iloc[split_point:split_point + prediction_length].values\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 6. CALCULATE METRICS\n",
        "# ---------------------------------------------------------------------------\n",
        "ts_entry = tss[0]\n",
        "forecast_entry = forecasts[0]\n",
        "forecast_mean = forecast_entry.mean\n",
        "\n",
        "# Calculate errors\n",
        "mae = np.mean(np.abs(forecast_mean - actual_values))\n",
        "rmse = np.sqrt(np.mean((forecast_mean - actual_values) ** 2))\n",
        "mape = np.mean(np.abs((actual_values - forecast_mean) / actual_values)) * 100\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 7. PLOT RESULTS\n",
        "# ---------------------------------------------------------------------------\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
        "\n",
        "# ========== PLOT 1: FORECAST WITH HISTORICAL CONTEXT ==========\n",
        "ts_index = ts_entry[-100:].index.to_timestamp()\n",
        "ts_values = ts_entry[-100:].values\n",
        "\n",
        "ax1.plot(ts_index, ts_values, label=\"Historical Data\", linewidth=2,\n",
        "         color='#2E86AB', marker='o', markersize=3, alpha=0.8)\n",
        "\n",
        "forecast_index = forecast_entry.index.to_timestamp()\n",
        "\n",
        "# Plot actual values in forecast period\n",
        "actual_index = df.index[split_point:split_point + prediction_length]\n",
        "ax1.plot(actual_index, actual_values, label=\"Actual (Holdout)\",\n",
        "         linewidth=2.5, color='#E63946', marker='o', markersize=5)\n",
        "\n",
        "# Plot forecast\n",
        "ax1.plot(forecast_index, forecast_mean, label=\"Forecast Mean\",\n",
        "         linewidth=2.5, color='#06A77D', marker='s', markersize=4, linestyle='--')\n",
        "\n",
        "# Prediction intervals\n",
        "q05 = forecast_entry.quantile('0.05')\n",
        "q95 = forecast_entry.quantile('0.95')\n",
        "ax1.fill_between(forecast_index, q05, q95, alpha=0.2, color='#06A77D',\n",
        "                 label='90% Prediction Interval')\n",
        "\n",
        "ax1.axvline(x=forecast_index[0], color='red', linestyle='--',\n",
        "           linewidth=1.5, alpha=0.7, label='Forecast Start')\n",
        "\n",
        "ax1.set_title(f\"Weekly Intake Forecast vs Actual\\n\"\n",
        "             f\"MAE: {mae:.2f} | RMSE: {rmse:.2f} | MAPE: {mape:.1f}%\",\n",
        "             fontsize=14, fontweight='bold', pad=15)\n",
        "ax1.set_xlabel(\"Date\", fontsize=12, fontweight='bold')\n",
        "ax1.set_ylabel(\"Number of People\", fontsize=12, fontweight='bold')\n",
        "ax1.legend(fontsize=9, loc='best', framealpha=0.9)\n",
        "ax1.grid(True, alpha=0.3, linestyle='--')\n",
        "ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%b'))\n",
        "plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
        "\n",
        "# ========== PLOT 2: FORECAST ERROR ANALYSIS ==========\n",
        "errors = forecast_mean - actual_values\n",
        "weeks = np.arange(1, prediction_length + 1)\n",
        "\n",
        "ax2.bar(weeks, errors, color=['#06A77D' if e >= 0 else '#E63946' for e in errors],\n",
        "       alpha=0.7, edgecolor='black', linewidth=1.5)\n",
        "ax2.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
        "ax2.set_title(\"Forecast Error by Week\", fontsize=14, fontweight='bold', pad=15)\n",
        "ax2.set_xlabel(\"Week Ahead\", fontsize=12, fontweight='bold')\n",
        "ax2.set_ylabel(\"Error (Forecast - Actual)\", fontsize=12, fontweight='bold')\n",
        "ax2.grid(True, alpha=0.3, axis='y', linestyle='--')\n",
        "ax2.set_xticks(weeks)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 8. PRINT DETAILED SUMMARY\n",
        "# ---------------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✅ FORECAST EVALUATION COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\n📊 ACCURACY METRICS:\")\n",
        "print(f\"  • MAE (Mean Absolute Error):        {mae:.2f}\")\n",
        "print(f\"  • RMSE (Root Mean Squared Error):   {rmse:.2f}\")\n",
        "print(f\"  • MAPE (Mean Absolute % Error):     {mape:.1f}%\")\n",
        "\n",
        "print(f\"\\n📈 FORECAST SUMMARY (Next {prediction_length} weeks):\")\n",
        "print(f\"  • Mean Forecast:     {forecast_mean.mean():.2f}\")\n",
        "print(f\"  • Median Forecast:   {np.median(forecast_mean):.2f}\")\n",
        "print(f\"  • Min Forecast:      {forecast_mean.min():.2f}\")\n",
        "print(f\"  • Max Forecast:      {forecast_mean.max():.2f}\")\n",
        "print(f\"  • Std Deviation:     {forecast_mean.std():.2f}\")\n",
        "\n",
        "print(f\"\\n📉 ACTUAL VALUES (Holdout Period):\")\n",
        "print(f\"  • Mean Actual:       {actual_values.mean():.2f}\")\n",
        "print(f\"  • Min Actual:        {actual_values.min():.2f}\")\n",
        "print(f\"  • Max Actual:        {actual_values.max():.2f}\")\n",
        "\n",
        "print(f\"\\n📋 WEEK-BY-WEEK COMPARISON:\")\n",
        "print(f\"{'Week':<6} {'Actual':<10} {'Forecast':<10} {'Error':<10} {'% Error':<10}\")\n",
        "print(\"-\" * 50)\n",
        "for i, (actual, pred) in enumerate(zip(actual_values, forecast_mean), 1):\n",
        "    error = pred - actual\n",
        "    pct_error = (error / actual) * 100\n",
        "    print(f\"{i:<6} {actual:<10.2f} {pred:<10.2f} {error:<10.2f} {pct_error:<10.1f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)"
      ],
      "metadata": {
        "id": "l8R9IPHnl_zo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e73176ce01ac4125bcb343d805a3f635",
            "21af3e6689724fe0a879f93e4d87149a",
            "b62668626a794e6bb7643735915590bd",
            "b35e1b0cf66542178de28b1624a32709",
            "5607248d22314e7bb44c8ffef7f3694a",
            "60897c92ed1548e2b44404a2aabe156c",
            "ed02181408aa48608e259fa27a24c6a4",
            "284447e0a0044dd8a7ddd4d7229fd3b5",
            "8de39a548b1844d7aef7dd9b1b4c9959",
            "297b870284a1478894b1256ac5e0c43f",
            "281fefcde61c47cf857e346f43e4035c"
          ]
        },
        "outputId": "8a1868f2-4740-4ec7-9023-f5b2c385c67b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ torch.load patched successfully\n",
            "✓ Data Loaded. Shape: (242, 44)\n",
            "✓ Date range: 2021-03-07 00:00:00 to 2025-10-19 00:00:00\n",
            "\n",
            "✓ Using 7 exogenous features\n",
            "\n",
            "✓ Train dataset: 230 weeks (up to 2025-07-27 00:00:00)\n",
            "✓ Holdout period: 12 weeks (from 2025-08-03 00:00:00)\n",
            "✓ Last actual value in training: 29.91\n",
            "\n",
            "Downloading Lag-Llama checkpoint...\n",
            "\u001b[33m⚠️  Warning: 'huggingface-cli download' is deprecated. Use 'hf download' instead.\u001b[0m\n",
            "lag-llama.ckpt\n",
            "✓ Using device: cuda\n",
            "\n",
            "🚀 Starting Fine-Tuning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e73176ce01ac4125bcb343d805a3f635"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 1.28451 (best 1.28451), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 1.28451 (best 1.28451), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 0.66783 (best 0.66783), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 0.66783 (best 0.66783), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 0.51805 (best 0.51805), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 0.51805 (best 0.51805), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 0.45076 (best 0.45076), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 0.45076 (best 0.45076), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 0.33377 (best 0.33377), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 0.33377 (best 0.33377), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 0.23233 (best 0.23233), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 0.23233 (best 0.23233), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 0.10292 (best 0.10292), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 0.10292 (best 0.10292), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 0.03824 (best 0.03824), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 0.03824 (best 0.03824), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached 0.02544 (best 0.02544), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 0.02544 (best 0.02544), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached -0.10948 (best -0.10948), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached -0.10948 (best -0.10948), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached -0.25584 (best -0.25584), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached -0.25584 (best -0.25584), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached -0.31089 (best -0.31089), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached -0.31089 (best -0.31089), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' reached -0.42252 (best -0.42252), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' reached -0.42252 (best -0.42252), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' reached -0.45333 (best -0.45333), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' reached -0.45333 (best -0.45333), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' reached -0.48041 (best -0.48041), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' reached -0.48041 (best -0.48041), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' reached -0.54779 (best -0.54779), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' reached -0.54779 (best -0.54779), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' reached -0.69426 (best -0.69426), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' reached -0.69426 (best -0.69426), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' reached -0.80209 (best -0.80209), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=51-step=2600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' reached -0.80209 (best -0.80209), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=51-step=2600.ckpt' as top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' reached -0.80343 (best -0.80343), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=58-step=2950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' reached -0.80343 (best -0.80343), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=58-step=2950.ckpt' as top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' reached -1.02779 (best -1.02779), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=68-step=3450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' reached -1.02779 (best -1.02779), saving model to '/content/lag-llama/lightning_logs/version_52/checkpoints/epoch=68-step=3450.ckpt' as top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=80` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=80` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Generating Forecasts...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "✅ FORECAST EVALUATION COMPLETE!\n",
            "======================================================================\n",
            "\n",
            "📊 ACCURACY METRICS:\n",
            "  • MAE (Mean Absolute Error):        1.55\n",
            "  • RMSE (Root Mean Squared Error):   1.88\n",
            "  • MAPE (Mean Absolute % Error):     4.9%\n",
            "\n",
            "📈 FORECAST SUMMARY (Next 12 weeks):\n",
            "  • Mean Forecast:     33.99\n",
            "  • Median Forecast:   33.83\n",
            "  • Min Forecast:      32.41\n",
            "  • Max Forecast:      35.68\n",
            "  • Std Deviation:     0.95\n",
            "\n",
            "📉 ACTUAL VALUES (Holdout Period):\n",
            "  • Mean Actual:       32.87\n",
            "  • Min Actual:        29.29\n",
            "  • Max Actual:        35.67\n",
            "\n",
            "📋 WEEK-BY-WEEK COMPARISON:\n",
            "Week   Actual     Forecast   Error      % Error   \n",
            "--------------------------------------------------\n",
            "1      34.07      33.68      -0.39      -1.1      %\n",
            "2      31.91      33.25      1.34       4.2       %\n",
            "3      31.50      32.41      0.91       2.9       %\n",
            "4      31.14      33.92      2.78       8.9       %\n",
            "5      31.84      33.99      2.15       6.8       %\n",
            "6      29.29      33.00      3.72       12.7      %\n",
            "7      32.96      33.83      0.87       2.7       %\n",
            "8      32.97      35.47      2.50       7.6       %\n",
            "9      33.97      35.68      1.70       5.0       %\n",
            "10     35.12      35.18      0.06       0.2       %\n",
            "11     35.67      33.82      -1.85      -5.2      %\n",
            "12     34.01      33.63      -0.38      -1.1      %\n",
            "\n",
            "======================================================================\n"
          ]
        }
      ]
    }
  ]
}