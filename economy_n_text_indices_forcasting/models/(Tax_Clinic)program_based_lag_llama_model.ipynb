{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cc3b10544f1e4bd48de5508cd2623741": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c1d58e19f5f491fbeec27ced3faa494",
              "IPY_MODEL_dbb8f7d81ded4b64a74986a6ce7c3020",
              "IPY_MODEL_10669b68cc5749e99f61d787c33414e1"
            ],
            "layout": "IPY_MODEL_c6cf5c486cea4514a172422432a8eceb"
          }
        },
        "1c1d58e19f5f491fbeec27ced3faa494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc94fc6d94374e6796bdd63c09860348",
            "placeholder": "​",
            "style": "IPY_MODEL_6d58556d5b2e475aa22081d00891ff4b",
            "value": "Best trial: 1. Best value: 14.9965: 100%"
          }
        },
        "dbb8f7d81ded4b64a74986a6ce7c3020": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_def48516c6df436998c9da86adabb798",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71debde217724588a487a3e955bbc9c8",
            "value": 50
          }
        },
        "10669b68cc5749e99f61d787c33414e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d530c29cb954bc385590e0545ff671f",
            "placeholder": "​",
            "style": "IPY_MODEL_6919b8ab453e49d78107a5294e49585b",
            "value": " 50/50 [1:57:50&lt;00:00, 111.28s/it]"
          }
        },
        "c6cf5c486cea4514a172422432a8eceb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc94fc6d94374e6796bdd63c09860348": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d58556d5b2e475aa22081d00891ff4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "def48516c6df436998c9da86adabb798": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71debde217724588a487a3e955bbc9c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d530c29cb954bc385590e0545ff671f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6919b8ab453e49d78107a5294e49585b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3cf9c66dcd38460899b6b5c398790069": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cfdb66fe4fb348d882d13f8eb7cdfc52",
              "IPY_MODEL_c1b1c556aaba4cba99f568fb954d11cc",
              "IPY_MODEL_01592fed5c0841e7ab22a5a85f3fbb4e"
            ],
            "layout": "IPY_MODEL_d61958e8cc0e474490e3fe0dbc43b75b"
          }
        },
        "cfdb66fe4fb348d882d13f8eb7cdfc52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_644c7f2bb95a4440a6315b50b0112595",
            "placeholder": "​",
            "style": "IPY_MODEL_e3f8c40e41e3400bb4eb33fcaa5bedbc",
            "value": "Epoch 59: "
          }
        },
        "c1b1c556aaba4cba99f568fb954d11cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb94d7739a654779bd68339ac18b0c3c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_600bd371805c49df9dcc3980de99bdbb",
            "value": 1
          }
        },
        "01592fed5c0841e7ab22a5a85f3fbb4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0ee3097b4f74331a3e30e88ec23934e",
            "placeholder": "​",
            "style": "IPY_MODEL_d092321a5e7a4188872b663e6cbcf16e",
            "value": " 40/? [00:03&lt;00:00, 11.83it/s, v_num=50]"
          }
        },
        "d61958e8cc0e474490e3fe0dbc43b75b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "644c7f2bb95a4440a6315b50b0112595": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3f8c40e41e3400bb4eb33fcaa5bedbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb94d7739a654779bd68339ac18b0c3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "600bd371805c49df9dcc3980de99bdbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0ee3097b4f74331a3e30e88ec23934e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d092321a5e7a4188872b663e6cbcf16e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6b835c8de694146b1817cf61cc400cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0e11eb858af44609bb07b183b93d2a3",
              "IPY_MODEL_22dc010b5ef7496e99c803dd7e0efc1f",
              "IPY_MODEL_96b767983c9c47988567239857e360f5"
            ],
            "layout": "IPY_MODEL_86403585daea4c879d48e804c7e4014f"
          }
        },
        "b0e11eb858af44609bb07b183b93d2a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c06c7f03c8594a4eafd76f5a14211066",
            "placeholder": "​",
            "style": "IPY_MODEL_fef5de66a31a4af48f23bfbe36812adc",
            "value": "Epoch 59: "
          }
        },
        "22dc010b5ef7496e99c803dd7e0efc1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9307d42d0e8d4b4a94c753f57e1c8411",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02b7c751662b4c46b4f317a40bc2579a",
            "value": 1
          }
        },
        "96b767983c9c47988567239857e360f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8868881bdd464449966e9051ebcc5337",
            "placeholder": "​",
            "style": "IPY_MODEL_438122338e744e15afe12615fc3a518d",
            "value": " 40/? [00:02&lt;00:00, 15.87it/s, v_num=51]"
          }
        },
        "86403585daea4c879d48e804c7e4014f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "c06c7f03c8594a4eafd76f5a14211066": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fef5de66a31a4af48f23bfbe36812adc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9307d42d0e8d4b4a94c753f57e1c8411": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02b7c751662b4c46b4f317a40bc2579a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8868881bdd464449966e9051ebcc5337": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "438122338e744e15afe12615fc3a518d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        " #Run this cell FIRST and ONLY ONCE\n",
        "\n",
        "# 1. Downgrade numpy to fix the \"dtype size changed\" error\n",
        "!pip install \"numpy<2.0\" --force-reinstall\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "MIvC_ZrIHiDd",
        "outputId": "d7a8ce61-5c43-433d-9262-0a3cc11852d2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy<2.0\n",
            "  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "de382319e5f347e9927dc7382c5af3d9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Install GluonTS and other dependencies\n",
        "!pip install gluonts torch pandas matplotlib seaborn --quiet\n",
        "\n",
        "# 3. Clone and install Lag-Llama\n",
        "import os\n",
        "if not os.path.exists(\"lag-llama\"):\n",
        "    !git clone https://github.com/time-series-foundation-models/lag-llama/\n",
        "\n",
        "%cd lag-llama\n",
        "!pip install -r requirements.txt --quiet\n",
        "\n",
        "print(\"\\n✓ Setup complete! Now run Cell 2.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kv52b5ojHknV",
        "outputId": "fb3501e1-f8f6-4421-978d-9d49489963fb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCloning into 'lag-llama'...\n",
            "remote: Enumerating objects: 508, done.\u001b[K\n",
            "remote: Counting objects: 100% (183/183), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "remote: Total 508 (delta 155), reused 114 (delta 114), pack-reused 325 (from 3)\u001b[K\n",
            "Receiving objects: 100% (508/508), 286.89 KiB | 7.17 MiB/s, done.\n",
            "Resolving deltas: 100% (253/253), done.\n",
            "/content/lag-llama\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m778.1/778.1 kB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.1.4 which is incompatible.\n",
            "xarray 2025.11.0 requires pandas>=2.2, but you have pandas 2.1.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.1.4 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\n",
            "mizani 0.13.5 requires pandas>=2.2.0, but you have pandas 2.1.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "✓ Setup complete! Now run Cell 2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BHvvJAXHagQ",
        "outputId": "cda55fd8-639e-425f-e40a-f8cfb9ff3ea8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.2)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.44)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
            "Downloading optuna-4.6.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.10.1 optuna-4.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import os\n",
        "import warnings\n",
        "import optuna\n",
        "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# CRITICAL FIX: Patch torch.load ONCE at module level\n",
        "# ---------------------------------------------------------------------------\n",
        "import torch.serialization\n",
        "\n",
        "if not hasattr(torch.serialization, '_original_torch_load_backup'):\n",
        "    torch.serialization._original_torch_load_backup = torch.serialization.load\n",
        "\n",
        "def safe_torch_load(*args, **kwargs):\n",
        "    \"\"\"Wrapper that adds weights_only=False by default\"\"\"\n",
        "    if 'weights_only' not in kwargs:\n",
        "        kwargs['weights_only'] = False\n",
        "    return torch.serialization._original_torch_load_backup(*args, **kwargs)\n",
        "\n",
        "# Apply the patch\n",
        "torch.load = safe_torch_load\n",
        "torch.serialization.load = safe_torch_load\n",
        "\n",
        "print(\"✓ torch.load patched successfully\")\n",
        "\n",
        "# GluonTS imports\n",
        "from gluonts.dataset.pandas import PandasDataset\n",
        "from gluonts.evaluation import make_evaluation_predictions, Evaluator\n",
        "from lag_llama.gluon.estimator import LagLlamaEstimator\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 1. LOAD AND PREPROCESS DATA\n",
        "# ---------------------------------------------------------------------------\n",
        "filename = '/content/macro_index_Tax_Clinic_only.csv'\n",
        "\n",
        "if not os.path.exists(filename):\n",
        "    filename = 'macro_index_Tax_Clinic_only.csv'\n",
        "\n",
        "if not os.path.exists(filename):\n",
        "    print(f\"❌ Error: {filename} not found. Please upload your CSV file.\")\n",
        "    raise FileNotFoundError(\"Please upload macro_index_Tax_Clinic_only.csv\")\n",
        "\n",
        "df = pd.read_csv(filename)\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df.set_index('date', inplace=True)\n",
        "df = df.asfreq('W-SUN')\n",
        "df = df.ffill().bfill()\n",
        "\n",
        "# CRITICAL: Convert all numeric data to float32\n",
        "num_cols = df.select_dtypes(include=[np.number]).columns\n",
        "df[num_cols] = df[num_cols].astype('float32')\n",
        "\n",
        "print(f\"✓ Data Loaded. Shape: {df.shape}\")\n",
        "print(f\"✓ Date range: {df.index[0]} to {df.index[-1]}\")\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 2. FEATURE SELECTION\n",
        "# ---------------------------------------------------------------------------\n",
        "target_col = 'Tax Clinic_MA3'\n",
        "\n",
        "use_exogenous = True\n",
        "\n",
        "if use_exogenous:\n",
        "    selected_features = [\n",
        "        'FXUSDCAD', 'FXEURCAD', 'CPIAUCSL', 'DTWEXBGS', 'DGS10',\n",
        "        'woodgreen_seniors_care_text_information',\n",
        "        'woodgreen_employment_text_information',\n",
        "        'goc_avg_over10y', 'DFF', 'spread_10y_5y',\n",
        "        'goc_long_benchmark', 'goc_long_benchmark1'\n",
        "    ]\n",
        "    selected_features = [f for f in selected_features if f in df.columns]\n",
        "    print(f\"\\n✓ Using {len(selected_features)} exogenous features\")\n",
        "else:\n",
        "    selected_features = []\n",
        "    print(f\"\\n✓ Using UNIVARIATE forecasting (no exogenous features)\")\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 3. DATA SPLIT STRATEGY\n",
        "# ---------------------------------------------------------------------------\n",
        "prediction_length = 12\n",
        "\n",
        "# Use validation split for hyperparameter tuning\n",
        "# Train: up to -24 weeks, Val: -24 to -12, Test: last 12 weeks\n",
        "full_train_end = len(df) - 24  # Reserve last 24 weeks\n",
        "val_start = full_train_end\n",
        "val_end = len(df) - 12\n",
        "test_start = val_end\n",
        "\n",
        "train_df = df.iloc[:full_train_end]\n",
        "val_df = df.iloc[:val_end]  # Includes train + val for proper context\n",
        "test_df = df.iloc[:test_start]\n",
        "\n",
        "print(f\"\\n✓ Train dataset: {len(train_df)} weeks (up to {train_df.index[-1]})\")\n",
        "print(f\"✓ Validation period: weeks {val_start} to {val_end}\")\n",
        "print(f\"✓ Test period: last {prediction_length} weeks\")\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 4. DOWNLOAD LAG-LLAMA CHECKPOINT (ONE TIME)\n",
        "# ---------------------------------------------------------------------------\n",
        "ckpt_path = \"lag-llama.ckpt\"\n",
        "if not os.path.exists(ckpt_path):\n",
        "    print(\"\\nDownloading Lag-Llama checkpoint...\")\n",
        "    !huggingface-cli download time-series-foundation-models/Lag-Llama lag-llama.ckpt --local-dir .\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"✓ Using device: {device}\")\n",
        "\n",
        "# Load base checkpoint parameters\n",
        "ckpt = torch.load(ckpt_path, map_location=device)\n",
        "base_estimator_args = ckpt[\"hyper_parameters\"][\"model_kwargs\"]\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 5. OPTUNA OBJECTIVE FUNCTION\n",
        "# ---------------------------------------------------------------------------\n",
        "def objective(trial):\n",
        "    \"\"\"\n",
        "    Optuna objective function to minimize validation MAE\n",
        "    \"\"\"\n",
        "\n",
        "    # Suggest hyperparameters\n",
        "    context_length = trial.suggest_categorical('context_length', [16, 32, 64, 96])\n",
        "    batch_size = trial.suggest_categorical('batch_size', [8, 16, 32])\n",
        "    max_epochs = trial.suggest_int('max_epochs', 20, 100, step=10)\n",
        "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True)\n",
        "    aug_prob = trial.suggest_float('aug_prob', 0.0, 0.3)\n",
        "\n",
        "    # Optional: tune model architecture (if you want deeper optimization)\n",
        "    # n_layer = trial.suggest_int('n_layer', 4, 12)\n",
        "    # n_head = trial.suggest_int('n_head', 4, 16)\n",
        "\n",
        "    try:\n",
        "        # Create datasets\n",
        "        if selected_features:\n",
        "            train_ds = PandasDataset(train_df, target=target_col,\n",
        "                                    feat_dynamic_real=selected_features, freq=\"W-SUN\")\n",
        "            val_ds = PandasDataset(val_df, target=target_col,\n",
        "                                  feat_dynamic_real=selected_features, freq=\"W-SUN\")\n",
        "        else:\n",
        "            train_ds = PandasDataset(train_df, target=target_col, freq=\"W-SUN\")\n",
        "            val_ds = PandasDataset(val_df, target=target_col, freq=\"W-SUN\")\n",
        "\n",
        "        # Create estimator with trial hyperparameters\n",
        "        estimator = LagLlamaEstimator(\n",
        "            ckpt_path=ckpt_path,\n",
        "            prediction_length=prediction_length,\n",
        "            context_length=context_length,\n",
        "            n_layer=base_estimator_args[\"n_layer\"],  # Or use trial.suggest_int\n",
        "            n_embd_per_head=base_estimator_args[\"n_embd_per_head\"],\n",
        "            n_head=base_estimator_args[\"n_head\"],  # Or use trial.suggest_int\n",
        "            scaling=base_estimator_args[\"scaling\"],\n",
        "            time_feat=base_estimator_args[\"time_feat\"],\n",
        "            aug_prob=aug_prob,\n",
        "            batch_size=batch_size,\n",
        "            num_parallel_samples=100,\n",
        "            lr=learning_rate,\n",
        "            trainer_kwargs={\n",
        "                \"accelerator\": device,\n",
        "                \"max_epochs\": max_epochs,\n",
        "                \"enable_progress_bar\": False,  # Cleaner output\n",
        "            },\n",
        "        )\n",
        "\n",
        "        # Train model\n",
        "        predictor = estimator.train(\n",
        "            training_data=train_ds,\n",
        "            cache_data=True,\n",
        "            shuffle_buffer_length=1000\n",
        "        )\n",
        "\n",
        "        # Generate forecasts on validation set\n",
        "        forecast_it, ts_it = make_evaluation_predictions(\n",
        "            dataset=val_ds,\n",
        "            predictor=predictor,\n",
        "            num_samples=100\n",
        "        )\n",
        "\n",
        "        forecasts = list(forecast_it)\n",
        "        tss = list(ts_it)\n",
        "\n",
        "        # Get actual values for validation period\n",
        "        actual_values = df[target_col].iloc[val_start:val_end].values\n",
        "        forecast_mean = forecasts[0].mean\n",
        "\n",
        "        # Calculate MAE as optimization metric\n",
        "        mae = np.mean(np.abs(forecast_mean - actual_values))\n",
        "\n",
        "        # Also calculate RMSE for reference\n",
        "        rmse = np.sqrt(np.mean((forecast_mean - actual_values) ** 2))\n",
        "\n",
        "        # Report intermediate value for pruning\n",
        "        trial.report(mae, step=max_epochs)\n",
        "\n",
        "        # Handle pruning\n",
        "        if trial.should_prune():\n",
        "            raise optuna.TrialPruned()\n",
        "\n",
        "        print(f\"Trial {trial.number}: MAE={mae:.2f}, RMSE={rmse:.2f}\")\n",
        "\n",
        "        return mae\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Trial {trial.number} failed: {str(e)}\")\n",
        "        return float('inf')  # Return worst possible score on failure\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 6. RUN OPTUNA OPTIMIZATION\n",
        "# ---------------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🚀 STARTING HYPERPARAMETER OPTIMIZATION WITH OPTUNA\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Create study\n",
        "study = optuna.create_study(\n",
        "    direction='minimize',  # Minimize MAE\n",
        "    sampler=optuna.samplers.TPESampler(seed=42),  # Tree-structured Parzen Estimator\n",
        "    pruner=optuna.pruners.MedianPruner(n_warmup_steps=5),  # Prune bad trials early\n",
        ")\n",
        "\n",
        "# Run optimization\n",
        "n_trials = 50  # Adjust based on your computational budget\n",
        "study.optimize(objective, n_trials=n_trials, timeout=None, show_progress_bar=True)\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 7. ANALYZE RESULTS\n",
        "# ---------------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✅ OPTIMIZATION COMPLETE!\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "print(\"🏆 BEST HYPERPARAMETERS:\")\n",
        "print(\"-\" * 50)\n",
        "for key, value in study.best_params.items():\n",
        "    print(f\"  • {key}: {value}\")\n",
        "\n",
        "print(f\"\\n📊 BEST VALIDATION MAE: {study.best_value:.2f}\")\n",
        "print(f\"📈 Total trials completed: {len(study.trials)}\")\n",
        "\n",
        "# Get statistics\n",
        "completed_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
        "pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
        "\n",
        "print(f\"✓ Completed: {len(completed_trials)}\")\n",
        "print(f\"✗ Pruned: {len(pruned_trials)}\")\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 8. VISUALIZE OPTIMIZATION HISTORY\n",
        "# ---------------------------------------------------------------------------\n",
        "fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n",
        "\n",
        "# Plot 1: Optimization History\n",
        "ax1 = axes[0]\n",
        "trial_numbers = [t.number for t in completed_trials]\n",
        "trial_values = [t.value for t in completed_trials]\n",
        "\n",
        "ax1.plot(trial_numbers, trial_values, 'o-', alpha=0.6, linewidth=1, markersize=4)\n",
        "ax1.axhline(y=study.best_value, color='r', linestyle='--', linewidth=2,\n",
        "           label=f'Best MAE: {study.best_value:.2f}')\n",
        "ax1.set_xlabel('Trial Number', fontsize=12, fontweight='bold')\n",
        "ax1.set_ylabel('Validation MAE', fontsize=12, fontweight='bold')\n",
        "ax1.set_title('Optuna Optimization History', fontsize=14, fontweight='bold', pad=15)\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Parameter Importance\n",
        "ax2 = axes[1]\n",
        "try:\n",
        "    importances = optuna.importance.get_param_importances(study)\n",
        "    params = list(importances.keys())\n",
        "    values = list(importances.values())\n",
        "\n",
        "    colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(params)))\n",
        "    bars = ax2.barh(params, values, color=colors, edgecolor='black', linewidth=1.5)\n",
        "    ax2.set_xlabel('Importance', fontsize=12, fontweight='bold')\n",
        "    ax2.set_title('Hyperparameter Importance', fontsize=14, fontweight='bold', pad=15)\n",
        "    ax2.grid(True, alpha=0.3, axis='x')\n",
        "except:\n",
        "    ax2.text(0.5, 0.5, 'Not enough trials for importance analysis',\n",
        "            ha='center', va='center', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 9. TRAIN FINAL MODEL WITH BEST HYPERPARAMETERS\n",
        "# ---------------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🎯 TRAINING FINAL MODEL WITH BEST HYPERPARAMETERS\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "best_params = study.best_params\n",
        "\n",
        "# Create final datasets (use all data up to test period)\n",
        "final_train_df = df.iloc[:test_start]\n",
        "\n",
        "if selected_features:\n",
        "    final_train_ds = PandasDataset(final_train_df, target=target_col,\n",
        "                                   feat_dynamic_real=selected_features, freq=\"W-SUN\")\n",
        "    test_ds = PandasDataset(test_df, target=target_col,\n",
        "                           feat_dynamic_real=selected_features, freq=\"W-SUN\")\n",
        "else:\n",
        "    final_train_ds = PandasDataset(final_train_df, target=target_col, freq=\"W-SUN\")\n",
        "    test_ds = PandasDataset(test_df, target=target_col, freq=\"W-SUN\")\n",
        "\n",
        "# Create final estimator\n",
        "final_estimator = LagLlamaEstimator(\n",
        "    ckpt_path=ckpt_path,\n",
        "    prediction_length=prediction_length,\n",
        "    context_length=best_params['context_length'],\n",
        "    n_layer=base_estimator_args[\"n_layer\"],\n",
        "    n_embd_per_head=base_estimator_args[\"n_embd_per_head\"],\n",
        "    n_head=base_estimator_args[\"n_head\"],\n",
        "    scaling=base_estimator_args[\"scaling\"],\n",
        "    time_feat=base_estimator_args[\"time_feat\"],\n",
        "    aug_prob=best_params['aug_prob'],\n",
        "    batch_size=best_params['batch_size'],\n",
        "    num_parallel_samples=100,\n",
        "    lr=best_params['learning_rate'],\n",
        "    trainer_kwargs={\n",
        "        \"accelerator\": device,\n",
        "        \"max_epochs\": best_params['max_epochs'],\n",
        "    },\n",
        ")\n",
        "\n",
        "# Train final model\n",
        "final_predictor = final_estimator.train(\n",
        "    training_data=final_train_ds,\n",
        "    cache_data=True,\n",
        "    shuffle_buffer_length=1000\n",
        ")\n",
        "\n",
        "# Generate final forecasts\n",
        "forecast_it, ts_it = make_evaluation_predictions(\n",
        "    dataset=test_ds,\n",
        "    predictor=final_predictor,\n",
        "    num_samples=100\n",
        ")\n",
        "\n",
        "forecasts = list(forecast_it)\n",
        "tss = list(ts_it)\n",
        "\n",
        "# Get actual test values\n",
        "actual_values = df[target_col].iloc[test_start:test_start + prediction_length].values\n",
        "forecast_mean = forecasts[0].mean\n",
        "\n",
        "# Calculate final metrics\n",
        "mae = np.mean(np.abs(forecast_mean - actual_values))\n",
        "rmse = np.sqrt(np.mean((forecast_mean - actual_values) ** 2))\n",
        "mape = np.mean(np.abs((actual_values - forecast_mean) / actual_values)) * 100\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 10. PLOT FINAL RESULTS\n",
        "# ---------------------------------------------------------------------------\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
        "\n",
        "# Plot 1: Forecast with Historical Context\n",
        "ts_entry = tss[0]\n",
        "ts_index = ts_entry[-100:].index.to_timestamp()\n",
        "ts_values = ts_entry[-100:].values\n",
        "\n",
        "ax1.plot(ts_index, ts_values, label=\"Historical Data\", linewidth=2,\n",
        "         color='#2E86AB', marker='o', markersize=3, alpha=0.8)\n",
        "\n",
        "forecast_entry = forecasts[0]\n",
        "forecast_index = forecast_entry.index.to_timestamp()\n",
        "actual_index = df.index[test_start:test_start + prediction_length]\n",
        "\n",
        "ax1.plot(actual_index, actual_values, label=\"Actual (Test)\",\n",
        "         linewidth=2.5, color='#E63946', marker='o', markersize=5)\n",
        "\n",
        "ax1.plot(forecast_index, forecast_mean, label=\"Optimized Forecast\",\n",
        "         linewidth=2.5, color='#06A77D', marker='s', markersize=4, linestyle='--')\n",
        "\n",
        "q05 = forecast_entry.quantile('0.05')\n",
        "q95 = forecast_entry.quantile('0.95')\n",
        "ax1.fill_between(forecast_index, q05, q95, alpha=0.2, color='#06A77D',\n",
        "                 label='90% Prediction Interval')\n",
        "\n",
        "ax1.axvline(x=forecast_index[0], color='red', linestyle='--',\n",
        "           linewidth=1.5, alpha=0.7, label='Forecast Start')\n",
        "\n",
        "ax1.set_title(f\"Optimized Model: Weekly Intake Forecast vs Actual\\n\"\n",
        "             f\"MAE: {mae:.2f} | RMSE: {rmse:.2f} | MAPE: {mape:.1f}%\",\n",
        "             fontsize=14, fontweight='bold', pad=15)\n",
        "ax1.set_xlabel(\"Date\", fontsize=12, fontweight='bold')\n",
        "ax1.set_ylabel(\"Number of People\", fontsize=12, fontweight='bold')\n",
        "ax1.legend(fontsize=9, loc='best', framealpha=0.9)\n",
        "ax1.grid(True, alpha=0.3, linestyle='--')\n",
        "ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%b'))\n",
        "plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
        "\n",
        "# Plot 2: Forecast Error Analysis\n",
        "errors = forecast_mean - actual_values\n",
        "weeks = np.arange(1, prediction_length + 1)\n",
        "\n",
        "ax2.bar(weeks, errors, color=['#06A77D' if e >= 0 else '#E63946' for e in errors],\n",
        "       alpha=0.7, edgecolor='black', linewidth=1.5)\n",
        "ax2.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
        "ax2.set_title(\"Forecast Error by Week\", fontsize=14, fontweight='bold', pad=15)\n",
        "ax2.set_xlabel(\"Week Ahead\", fontsize=12, fontweight='bold')\n",
        "ax2.set_ylabel(\"Error (Forecast - Actual)\", fontsize=12, fontweight='bold')\n",
        "ax2.grid(True, alpha=0.3, axis='y', linestyle='--')\n",
        "ax2.set_xticks(weeks)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 11. FINAL SUMMARY\n",
        "# ---------------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✅ FINAL MODEL EVALUATION (TEST SET)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\n📊 ACCURACY METRICS:\")\n",
        "print(f\"  • MAE (Mean Absolute Error):        {mae:.2f}\")\n",
        "print(f\"  • RMSE (Root Mean Squared Error):   {rmse:.2f}\")\n",
        "print(f\"  • MAPE (Mean Absolute % Error):     {mape:.1f}%\")\n",
        "\n",
        "print(f\"\\n🏆 BEST HYPERPARAMETERS USED:\")\n",
        "for key, value in best_params.items():\n",
        "    print(f\"  • {key}: {value}\")\n",
        "\n",
        "print(f\"\\n📋 WEEK-BY-WEEK COMPARISON:\")\n",
        "print(f\"{'Week':<6} {'Actual':<10} {'Forecast':<10} {'Error':<10} {'% Error':<10}\")\n",
        "print(\"-\" * 50)\n",
        "for i, (actual, pred) in enumerate(zip(actual_values, forecast_mean), 1):\n",
        "    error = pred - actual\n",
        "    pct_error = (error / actual) * 100\n",
        "    print(f\"{i:<6} {actual:<10.2f} {pred:<10.2f} {error:<10.2f} {pct_error:<10.1f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "\n",
        "# Save best parameters to file\n",
        "import json\n",
        "with open('best_hyperparameters.json', 'w') as f:\n",
        "    json.dump(best_params, f, indent=2)\n",
        "print(\"\\n💾 Best hyperparameters saved to 'best_hyperparameters.json'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "cc3b10544f1e4bd48de5508cd2623741",
            "1c1d58e19f5f491fbeec27ced3faa494",
            "dbb8f7d81ded4b64a74986a6ce7c3020",
            "10669b68cc5749e99f61d787c33414e1",
            "c6cf5c486cea4514a172422432a8eceb",
            "cc94fc6d94374e6796bdd63c09860348",
            "6d58556d5b2e475aa22081d00891ff4b",
            "def48516c6df436998c9da86adabb798",
            "71debde217724588a487a3e955bbc9c8",
            "2d530c29cb954bc385590e0545ff671f",
            "6919b8ab453e49d78107a5294e49585b",
            "3cf9c66dcd38460899b6b5c398790069",
            "cfdb66fe4fb348d882d13f8eb7cdfc52",
            "c1b1c556aaba4cba99f568fb954d11cc",
            "01592fed5c0841e7ab22a5a85f3fbb4e",
            "d61958e8cc0e474490e3fe0dbc43b75b",
            "644c7f2bb95a4440a6315b50b0112595",
            "e3f8c40e41e3400bb4eb33fcaa5bedbc",
            "fb94d7739a654779bd68339ac18b0c3c",
            "600bd371805c49df9dcc3980de99bdbb",
            "a0ee3097b4f74331a3e30e88ec23934e",
            "d092321a5e7a4188872b663e6cbcf16e"
          ]
        },
        "id": "PM4CSQqTHeSa",
        "outputId": "11d26931-c06f-40ba-9c41-1be7f28fdbf7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ torch.load patched successfully\n",
            "✓ Data Loaded. Shape: (242, 45)\n",
            "✓ Date range: 2021-03-07 00:00:00 to 2025-10-19 00:00:00\n",
            "\n",
            "✓ Using 12 exogenous features\n",
            "\n",
            "✓ Train dataset: 218 weeks (up to 2025-05-04 00:00:00)\n",
            "✓ Validation period: weeks 218 to 230\n",
            "✓ Test period: last 12 weeks\n",
            "\n",
            "Downloading Lag-Llama checkpoint...\n",
            "\u001b[33m⚠️  Warning: 'huggingface-cli download' is deprecated. Use 'hf download' instead.\u001b[0m\n",
            "Downloading 'lag-llama.ckpt' to '.cache/huggingface/download/59Iq1KnnyJzBevZl6u7vR_lVuAs=.b5a5c4b8a0cfe9b81bdac35ed5d88b5033cd119b5206c28e9cd67c4b45fb2c96.incomplete'\n",
            "lag-llama.ckpt: 100% 29.5M/29.5M [00:01<00:00, 25.3MB/s]\n",
            "Download complete. Moving file to lag-llama.ckpt\n",
            "lag-llama.ckpt\n",
            "✓ Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-25 02:26:03,422] A new study created in memory with name: no-name-98410229-2c3e-4358-9922-67d66817078e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "🚀 STARTING HYPERPARAMETER OPTIMIZATION WITH OPTUNA\n",
            "======================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc3b10544f1e4bd48de5508cd2623741"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "WARNING: Missing logger folder: /content/lag-llama/lightning_logs\n",
            "WARNING:lightning.pytorch.loggers.tensorboard:Missing logger folder: /content/lag-llama/lightning_logs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.64832 (best 3.64832), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.64832 (best 3.64832), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.18334 (best 3.18334), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.18334 (best 3.18334), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.81496 (best 2.81496), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.81496 (best 2.81496), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.40649 (best 2.40649), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.40649 (best 2.40649), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 2.17663 (best 2.17663), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 2.17663 (best 2.17663), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached 2.17020 (best 2.17020), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached 2.17020 (best 2.17020), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached 1.99608 (best 1.99608), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached 1.99608 (best 1.99608), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached 1.97389 (best 1.97389), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached 1.97389 (best 1.97389), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached 1.91673 (best 1.91673), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached 1.91673 (best 1.91673), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached 1.84604 (best 1.84604), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached 1.84604 (best 1.84604), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' reached 1.74670 (best 1.74670), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' reached 1.74670 (best 1.74670), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' reached 1.70510 (best 1.70510), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' reached 1.70510 (best 1.70510), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' reached 1.63398 (best 1.63398), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' reached 1.63398 (best 1.63398), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' reached 1.44464 (best 1.44464), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' reached 1.44464 (best 1.44464), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' reached 1.31547 (best 1.31547), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' reached 1.31547 (best 1.31547), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' reached 1.28126 (best 1.28126), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=67-step=3400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' reached 1.28126 (best 1.28126), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=67-step=3400.ckpt' as top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 80, global step 4050: 'train_loss' reached 1.16945 (best 1.16945), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=80-step=4050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 80, global step 4050: 'train_loss' reached 1.16945 (best 1.16945), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=80-step=4050.ckpt' as top 1\n",
            "INFO: Epoch 81, global step 4100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 81, global step 4100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 82, global step 4150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 82, global step 4150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 84, global step 4250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 84, global step 4250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 85, global step 4300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 85, global step 4300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 86, global step 4350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 86, global step 4350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 88, global step 4450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 88, global step 4450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 89, global step 4500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 89, global step 4500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=90` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=90` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 0: MAE=62.36, RMSE=67.33\n",
            "[I 2025-11-25 02:29:15,679] Trial 0 finished with value: 62.356658935546875 and parameters: {'context_length': 32, 'batch_size': 8, 'max_epochs': 90, 'learning_rate': 0.00015930522616241006, 'aug_prob': 0.21242177333881365}. Best is trial 0 with value: 62.356658935546875.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.55611 (best 3.55611), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.55611 (best 3.55611), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.07011 (best 3.07011), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.07011 (best 3.07011), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.85117 (best 2.85117), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.85117 (best 2.85117), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.29492 (best 2.29492), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.29492 (best 2.29492), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 1.81917 (best 1.81917), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 1.81917 (best 1.81917), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 1.66304 (best 1.66304), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 1.66304 (best 1.66304), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached 1.48389 (best 1.48389), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached 1.48389 (best 1.48389), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached 1.38126 (best 1.38126), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached 1.38126 (best 1.38126), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached 1.19860 (best 1.19860), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached 1.19860 (best 1.19860), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached 1.12250 (best 1.12250), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached 1.12250 (best 1.12250), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' reached 1.09526 (best 1.09526), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' reached 1.09526 (best 1.09526), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' reached 1.08152 (best 1.08152), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' reached 1.08152 (best 1.08152), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' reached 0.89864 (best 0.89864), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' reached 0.89864 (best 0.89864), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' reached 0.87207 (best 0.87207), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' reached 0.87207 (best 0.87207), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' reached 0.81587 (best 0.81587), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' reached 0.81587 (best 0.81587), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' reached 0.72823 (best 0.72823), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=53-step=2700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' reached 0.72823 (best 0.72823), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=53-step=2700.ckpt' as top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' reached 0.70054 (best 0.70054), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=56-step=2850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' reached 0.70054 (best 0.70054), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=56-step=2850.ckpt' as top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' reached 0.60178 (best 0.60178), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=59-step=3000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' reached 0.60178 (best 0.60178), saving model to '/content/lag-llama/lightning_logs/version_1/checkpoints/epoch=59-step=3000.ckpt' as top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1: MAE=15.00, RMSE=18.58\n",
            "[I 2025-11-25 02:31:36,946] Trial 1 finished with value: 14.996456146240234 and parameters: {'context_length': 32, 'batch_size': 32, 'max_epochs': 60, 'learning_rate': 7.309539835912905e-05, 'aug_prob': 0.08736874205941257}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.93543 (best 3.93543), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.93543 (best 3.93543), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 2.99392 (best 2.99392), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 2.99392 (best 2.99392), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.60455 (best 2.60455), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.60455 (best 2.60455), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.28232 (best 2.28232), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.28232 (best 2.28232), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.25775 (best 2.25775), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.25775 (best 2.25775), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 1.93244 (best 1.93244), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 1.93244 (best 1.93244), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 1.71881 (best 1.71881), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 1.71881 (best 1.71881), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached 1.60462 (best 1.60462), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached 1.60462 (best 1.60462), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached 1.54517 (best 1.54517), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached 1.54517 (best 1.54517), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached 1.46287 (best 1.46287), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached 1.46287 (best 1.46287), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached 1.35440 (best 1.35440), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached 1.35440 (best 1.35440), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' reached 1.29268 (best 1.29268), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' reached 1.29268 (best 1.29268), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' reached 1.25861 (best 1.25861), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' reached 1.25861 (best 1.25861), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' reached 1.16226 (best 1.16226), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' reached 1.16226 (best 1.16226), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' reached 1.11060 (best 1.11060), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' reached 1.11060 (best 1.11060), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' reached 1.08056 (best 1.08056), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' reached 1.08056 (best 1.08056), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' reached 0.97912 (best 0.97912), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' reached 0.97912 (best 0.97912), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' reached 0.92258 (best 0.92258), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' reached 0.92258 (best 0.92258), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' reached 0.85480 (best 0.85480), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' reached 0.85480 (best 0.85480), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' reached 0.77579 (best 0.77579), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=50-step=2550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' reached 0.77579 (best 0.77579), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=50-step=2550.ckpt' as top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' reached 0.71473 (best 0.71473), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=52-step=2650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' reached 0.71473 (best 0.71473), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=52-step=2650.ckpt' as top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' reached 0.71144 (best 0.71144), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=54-step=2750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' reached 0.71144 (best 0.71144), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=54-step=2750.ckpt' as top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' reached 0.66717 (best 0.66717), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=55-step=2800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' reached 0.66717 (best 0.66717), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=55-step=2800.ckpt' as top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' reached 0.63504 (best 0.63504), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=57-step=2900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' reached 0.63504 (best 0.63504), saving model to '/content/lag-llama/lightning_logs/version_2/checkpoints/epoch=57-step=2900.ckpt' as top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 2: MAE=23.70, RMSE=30.18\n",
            "[I 2025-11-25 02:33:46,247] Trial 2 finished with value: 23.702001571655273 and parameters: {'context_length': 16, 'batch_size': 16, 'max_epochs': 60, 'learning_rate': 0.00015304852121831474, 'aug_prob': 0.013935123815999317}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.59684 (best 3.59684), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.59684 (best 3.59684), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 2.93549 (best 2.93549), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 2.93549 (best 2.93549), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.71568 (best 2.71568), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.71568 (best 2.71568), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.57725 (best 2.57725), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.57725 (best 2.57725), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.43648 (best 2.43648), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.43648 (best 2.43648), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 1.89111 (best 1.89111), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 1.89111 (best 1.89111), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 1.82131 (best 1.82131), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 1.82131 (best 1.82131), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 1.62940 (best 1.62940), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 1.62940 (best 1.62940), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached 1.50260 (best 1.50260), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached 1.50260 (best 1.50260), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' reached 1.45334 (best 1.45334), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' reached 1.45334 (best 1.45334), saving model to '/content/lag-llama/lightning_logs/version_3/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=20` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=20` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3: MAE=34.23, RMSE=40.23\n",
            "[I 2025-11-25 02:34:29,746] Trial 3 finished with value: 34.2265510559082 and parameters: {'context_length': 96, 'batch_size': 8, 'max_epochs': 20, 'learning_rate': 0.000233596350262616, 'aug_prob': 0.13204574812188039}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.50443 (best 3.50443), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.50443 (best 3.50443), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 2.64342 (best 2.64342), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 2.64342 (best 2.64342), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.17494 (best 2.17494), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.17494 (best 2.17494), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 1.84741 (best 1.84741), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 1.84741 (best 1.84741), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 1.57501 (best 1.57501), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 1.57501 (best 1.57501), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 1.27950 (best 1.27950), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 1.27950 (best 1.27950), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached 1.27132 (best 1.27132), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 1.27132 (best 1.27132), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached 1.22266 (best 1.22266), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached 1.22266 (best 1.22266), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached 1.04004 (best 1.04004), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached 1.04004 (best 1.04004), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' reached 1.02026 (best 1.02026), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' reached 1.02026 (best 1.02026), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' reached 0.82558 (best 0.82558), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' reached 0.82558 (best 0.82558), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' reached 0.75434 (best 0.75434), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' reached 0.75434 (best 0.75434), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' reached 0.50377 (best 0.50377), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' reached 0.50377 (best 0.50377), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' reached 0.45737 (best 0.45737), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=50-step=2550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' reached 0.45737 (best 0.45737), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=50-step=2550.ckpt' as top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' reached 0.23505 (best 0.23505), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=57-step=2900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' reached 0.23505 (best 0.23505), saving model to '/content/lag-llama/lightning_logs/version_4/checkpoints/epoch=57-step=2900.ckpt' as top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 4: MAE=37.06, RMSE=45.43\n",
            "[I 2025-11-25 02:36:42,718] Trial 4 finished with value: 37.059425354003906 and parameters: {'context_length': 96, 'batch_size': 16, 'max_epochs': 60, 'learning_rate': 0.00012399967836846095, 'aug_prob': 0.05545633665765811}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.94257 (best 3.94257), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.94257 (best 3.94257), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.82778 (best 3.82778), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.82778 (best 3.82778), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 3.62278 (best 3.62278), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 3.62278 (best 3.62278), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 3.44330 (best 3.44330), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 3.44330 (best 3.44330), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 3.38345 (best 3.38345), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 3.38345 (best 3.38345), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 3.00857 (best 3.00857), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 3.00857 (best 3.00857), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 3.00571 (best 3.00571), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 3.00571 (best 3.00571), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached 2.93870 (best 2.93870), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 2.93870 (best 2.93870), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached 2.55505 (best 2.55505), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached 2.55505 (best 2.55505), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached 2.32262 (best 2.32262), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached 2.32262 (best 2.32262), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached 2.29382 (best 2.29382), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached 2.29382 (best 2.29382), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached 2.07727 (best 2.07727), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached 2.07727 (best 2.07727), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' reached 1.96267 (best 1.96267), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' reached 1.96267 (best 1.96267), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' reached 1.86521 (best 1.86521), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' reached 1.86521 (best 1.86521), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' reached 1.56302 (best 1.56302), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' reached 1.56302 (best 1.56302), saving model to '/content/lag-llama/lightning_logs/version_5/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=30` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=30` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5: MAE=41.69, RMSE=43.99\n",
            "[I 2025-11-25 02:37:47,372] Trial 5 finished with value: 41.689697265625 and parameters: {'context_length': 16, 'batch_size': 16, 'max_epochs': 30, 'learning_rate': 1.2315571723666024e-05, 'aug_prob': 0.0975990992289793}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.82101 (best 3.82101), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.82101 (best 3.82101), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.61441 (best 3.61441), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.61441 (best 3.61441), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 3.45652 (best 3.45652), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 3.45652 (best 3.45652), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 3.27819 (best 3.27819), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 3.27819 (best 3.27819), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 3.05274 (best 3.05274), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 3.05274 (best 3.05274), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 2.82386 (best 2.82386), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 2.82386 (best 2.82386), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 2.62544 (best 2.62544), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 2.62544 (best 2.62544), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 2.43555 (best 2.43555), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 2.43555 (best 2.43555), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached 2.27167 (best 2.27167), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 2.27167 (best 2.27167), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached 2.20531 (best 2.20531), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached 2.20531 (best 2.20531), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached 1.89571 (best 1.89571), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached 1.89571 (best 1.89571), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' reached 1.80110 (best 1.80110), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' reached 1.80110 (best 1.80110), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' reached 1.75120 (best 1.75120), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' reached 1.75120 (best 1.75120), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' reached 1.53248 (best 1.53248), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' reached 1.53248 (best 1.53248), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' reached 1.41976 (best 1.41976), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=52-step=2650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' reached 1.41976 (best 1.41976), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=52-step=2650.ckpt' as top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' reached 1.28270 (best 1.28270), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=54-step=2750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' reached 1.28270 (best 1.28270), saving model to '/content/lag-llama/lightning_logs/version_6/checkpoints/epoch=54-step=2750.ckpt' as top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 80, global step 4050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 80, global step 4050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 81, global step 4100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 81, global step 4100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 82, global step 4150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 82, global step 4150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 84, global step 4250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 84, global step 4250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 85, global step 4300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 85, global step 4300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 86, global step 4350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 86, global step 4350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 88, global step 4450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 88, global step 4450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 89, global step 4500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 89, global step 4500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=90` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=90` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 6: MAE=29.82, RMSE=37.29\n",
            "[I 2025-11-25 02:41:05,286] Trial 6 finished with value: 29.818601608276367 and parameters: {'context_length': 64, 'batch_size': 16, 'max_epochs': 90, 'learning_rate': 1.4096175149815848e-05, 'aug_prob': 0.2960660809801552}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.62349 (best 3.62349), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.62349 (best 3.62349), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 2.95359 (best 2.95359), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 2.95359 (best 2.95359), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.46261 (best 2.46261), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.46261 (best 2.46261), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 1.95128 (best 1.95128), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 1.95128 (best 1.95128), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 1.80535 (best 1.80535), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 1.80535 (best 1.80535), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 1.71056 (best 1.71056), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 1.71056 (best 1.71056), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 1.30974 (best 1.30974), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 1.30974 (best 1.30974), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached 1.09319 (best 1.09319), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached 1.09319 (best 1.09319), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached 1.07403 (best 1.07403), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached 1.07403 (best 1.07403), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached 1.00497 (best 1.00497), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached 1.00497 (best 1.00497), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached 0.58378 (best 0.58378), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached 0.58378 (best 0.58378), saving model to '/content/lag-llama/lightning_logs/version_7/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=20` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=20` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 7: MAE=21.43, RMSE=23.73\n",
            "[I 2025-11-25 02:41:59,646] Trial 7 finished with value: 21.429443359375 and parameters: {'context_length': 96, 'batch_size': 32, 'max_epochs': 20, 'learning_rate': 5.211124595788268e-05, 'aug_prob': 0.03476071785753891}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.70146 (best 3.70146), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.70146 (best 3.70146), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.16564 (best 3.16564), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.16564 (best 3.16564), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.81543 (best 2.81543), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.81543 (best 2.81543), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.56616 (best 2.56616), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.56616 (best 2.56616), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.47389 (best 2.47389), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.47389 (best 2.47389), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 2.43590 (best 2.43590), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 2.43590 (best 2.43590), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 2.25096 (best 2.25096), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 2.25096 (best 2.25096), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached 2.21725 (best 2.21725), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 2.21725 (best 2.21725), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached 2.21673 (best 2.21673), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached 2.21673 (best 2.21673), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached 2.09126 (best 2.09126), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached 2.09126 (best 2.09126), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached 1.77140 (best 1.77140), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached 1.77140 (best 1.77140), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' reached 1.74803 (best 1.74803), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' reached 1.74803 (best 1.74803), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' reached 1.70413 (best 1.70413), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' reached 1.70413 (best 1.70413), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' reached 1.48627 (best 1.48627), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' reached 1.48627 (best 1.48627), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' reached 1.36952 (best 1.36952), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' reached 1.36952 (best 1.36952), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' reached 1.14169 (best 1.14169), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' reached 1.14169 (best 1.14169), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' reached 1.12362 (best 1.12362), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' reached 1.12362 (best 1.12362), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' reached 1.07979 (best 1.07979), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=59-step=3000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' reached 1.07979 (best 1.07979), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=59-step=3000.ckpt' as top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' reached 1.04547 (best 1.04547), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=62-step=3150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' reached 1.04547 (best 1.04547), saving model to '/content/lag-llama/lightning_logs/version_8/checkpoints/epoch=62-step=3150.ckpt' as top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 8: MAE=69.77, RMSE=75.77\n",
            "[I 2025-11-25 02:44:53,541] Trial 8 finished with value: 69.77490234375 and parameters: {'context_length': 16, 'batch_size': 32, 'max_epochs': 70, 'learning_rate': 0.000594874681321977, 'aug_prob': 0.14166447754858477}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 4.18866 (best 4.18866), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 4.18866 (best 4.18866), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.75239 (best 3.75239), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.75239 (best 3.75239), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 3.47205 (best 3.47205), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 3.47205 (best 3.47205), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 3.29972 (best 3.29972), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 3.29972 (best 3.29972), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 3.12979 (best 3.12979), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 3.12979 (best 3.12979), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 3.02527 (best 3.02527), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 3.02527 (best 3.02527), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 2.77858 (best 2.77858), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 2.77858 (best 2.77858), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 2.62154 (best 2.62154), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 2.62154 (best 2.62154), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 2.52766 (best 2.52766), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 2.52766 (best 2.52766), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached 2.37456 (best 2.37456), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached 2.37456 (best 2.37456), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached 2.22406 (best 2.22406), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached 2.22406 (best 2.22406), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached 2.09415 (best 2.09415), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached 2.09415 (best 2.09415), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached 1.89900 (best 1.89900), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached 1.89900 (best 1.89900), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached 1.72939 (best 1.72939), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached 1.72939 (best 1.72939), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' reached 1.53952 (best 1.53952), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' reached 1.53952 (best 1.53952), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' reached 1.42945 (best 1.42945), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' reached 1.42945 (best 1.42945), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' reached 1.32660 (best 1.32660), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' reached 1.32660 (best 1.32660), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' reached 1.28394 (best 1.28394), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' reached 1.28394 (best 1.28394), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' reached 1.24887 (best 1.24887), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' reached 1.24887 (best 1.24887), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' reached 1.21488 (best 1.21488), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' reached 1.21488 (best 1.21488), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' reached 1.17988 (best 1.17988), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' reached 1.17988 (best 1.17988), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' reached 0.99087 (best 0.99087), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' reached 0.99087 (best 0.99087), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' reached 0.95894 (best 0.95894), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' reached 0.95894 (best 0.95894), saving model to '/content/lag-llama/lightning_logs/version_9/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=50` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=50` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 9: MAE=60.12, RMSE=61.55\n",
            "[I 2025-11-25 02:46:41,060] Trial 9 finished with value: 60.121036529541016 and parameters: {'context_length': 64, 'batch_size': 8, 'max_epochs': 50, 'learning_rate': 1.1241862095793047e-05, 'aug_prob': 0.032367428097991334}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.69143 (best 3.69143), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.69143 (best 3.69143), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.28048 (best 3.28048), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.28048 (best 3.28048), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.94722 (best 2.94722), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.94722 (best 2.94722), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.80117 (best 2.80117), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.80117 (best 2.80117), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.62030 (best 2.62030), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.62030 (best 2.62030), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 2.35586 (best 2.35586), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 2.35586 (best 2.35586), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 2.14616 (best 2.14616), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 2.14616 (best 2.14616), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 2.12673 (best 2.12673), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 2.12673 (best 2.12673), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached 1.96788 (best 1.96788), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 1.96788 (best 1.96788), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached 1.73873 (best 1.73873), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached 1.73873 (best 1.73873), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached 1.62373 (best 1.62373), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached 1.62373 (best 1.62373), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' reached 1.55550 (best 1.55550), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' reached 1.55550 (best 1.55550), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' reached 1.36155 (best 1.36155), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' reached 1.36155 (best 1.36155), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' reached 1.15421 (best 1.15421), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' reached 1.15421 (best 1.15421), saving model to '/content/lag-llama/lightning_logs/version_10/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=40` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=40` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10: MAE=21.99, RMSE=30.82\n",
            "[I 2025-11-25 02:48:21,114] Trial 10 finished with value: 21.990713119506836 and parameters: {'context_length': 32, 'batch_size': 32, 'max_epochs': 40, 'learning_rate': 4.939713749567097e-05, 'aug_prob': 0.2145508836590385}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.59737 (best 3.59737), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.59737 (best 3.59737), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.00819 (best 3.00819), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.00819 (best 3.00819), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.44648 (best 2.44648), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.44648 (best 2.44648), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.11351 (best 2.11351), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.11351 (best 2.11351), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 1.86275 (best 1.86275), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 1.86275 (best 1.86275), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 1.68321 (best 1.68321), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 1.68321 (best 1.68321), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 1.53995 (best 1.53995), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 1.53995 (best 1.53995), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached 1.51536 (best 1.51536), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached 1.51536 (best 1.51536), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached 1.41834 (best 1.41834), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached 1.41834 (best 1.41834), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached 1.41528 (best 1.41528), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached 1.41528 (best 1.41528), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached 1.32716 (best 1.32716), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached 1.32716 (best 1.32716), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached 1.00202 (best 1.00202), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached 1.00202 (best 1.00202), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached 0.76540 (best 0.76540), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached 0.76540 (best 0.76540), saving model to '/content/lag-llama/lightning_logs/version_11/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=20` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=20` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 11: MAE=25.74, RMSE=31.23\n",
            "[I 2025-11-25 02:49:15,117] Trial 11 finished with value: 25.735549926757812 and parameters: {'context_length': 96, 'batch_size': 32, 'max_epochs': 20, 'learning_rate': 4.606960732853615e-05, 'aug_prob': 0.0694505616460059}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.84531 (best 3.84531), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.84531 (best 3.84531), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.33789 (best 3.33789), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.33789 (best 3.33789), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.97857 (best 2.97857), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.97857 (best 2.97857), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.60916 (best 2.60916), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.60916 (best 2.60916), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.29029 (best 2.29029), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.29029 (best 2.29029), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 2.19944 (best 2.19944), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 2.19944 (best 2.19944), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 2.03190 (best 2.03190), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 2.03190 (best 2.03190), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 1.74002 (best 1.74002), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 1.74002 (best 1.74002), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached 1.66614 (best 1.66614), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached 1.66614 (best 1.66614), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached 1.52425 (best 1.52425), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached 1.52425 (best 1.52425), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' reached 1.44983 (best 1.44983), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' reached 1.44983 (best 1.44983), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached 1.36389 (best 1.36389), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached 1.36389 (best 1.36389), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' reached 1.22955 (best 1.22955), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' reached 1.22955 (best 1.22955), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' reached 1.13245 (best 1.13245), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' reached 1.13245 (best 1.13245), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' reached 0.93644 (best 0.93644), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' reached 0.93644 (best 0.93644), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' reached 0.91171 (best 0.91171), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' reached 0.91171 (best 0.91171), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' reached 0.84633 (best 0.84633), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' reached 0.84633 (best 0.84633), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' reached 0.66211 (best 0.66211), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' reached 0.66211 (best 0.66211), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' reached 0.57465 (best 0.57465), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=59-step=3000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' reached 0.57465 (best 0.57465), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=59-step=3000.ckpt' as top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 71, global step 3600: 'train_loss' reached 0.42745 (best 0.42745), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=71-step=3600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 71, global step 3600: 'train_loss' reached 0.42745 (best 0.42745), saving model to '/content/lag-llama/lightning_logs/version_12/checkpoints/epoch=71-step=3600.ckpt' as top 1\n",
            "INFO: Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=80` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=80` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 12: MAE=26.35, RMSE=31.74\n",
            "[I 2025-11-25 02:52:28,784] Trial 12 finished with value: 26.346765518188477 and parameters: {'context_length': 32, 'batch_size': 32, 'max_epochs': 80, 'learning_rate': 4.004168742993846e-05, 'aug_prob': 0.0936336456276716}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.77591 (best 3.77591), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.77591 (best 3.77591), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.30805 (best 3.30805), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.30805 (best 3.30805), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.70996 (best 2.70996), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.70996 (best 2.70996), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.23700 (best 2.23700), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.23700 (best 2.23700), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 1.95884 (best 1.95884), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 1.95884 (best 1.95884), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 1.71506 (best 1.71506), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 1.71506 (best 1.71506), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 1.59844 (best 1.59844), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 1.59844 (best 1.59844), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 1.56055 (best 1.56055), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 1.56055 (best 1.56055), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 1.40998 (best 1.40998), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 1.40998 (best 1.40998), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached 1.31692 (best 1.31692), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 1.31692 (best 1.31692), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached 1.22944 (best 1.22944), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached 1.22944 (best 1.22944), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached 1.14103 (best 1.14103), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached 1.14103 (best 1.14103), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached 1.04866 (best 1.04866), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached 1.04866 (best 1.04866), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached 0.95852 (best 0.95852), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached 0.95852 (best 0.95852), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached 0.95207 (best 0.95207), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached 0.95207 (best 0.95207), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached 0.90016 (best 0.90016), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached 0.90016 (best 0.90016), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached 0.79363 (best 0.79363), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached 0.79363 (best 0.79363), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached 0.78622 (best 0.78622), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached 0.78622 (best 0.78622), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' reached 0.61640 (best 0.61640), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' reached 0.61640 (best 0.61640), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' reached 0.60386 (best 0.60386), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' reached 0.60386 (best 0.60386), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' reached 0.57803 (best 0.57803), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' reached 0.57803 (best 0.57803), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' reached 0.40435 (best 0.40435), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' reached 0.40435 (best 0.40435), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' reached 0.30909 (best 0.30909), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' reached 0.30909 (best 0.30909), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' reached 0.30807 (best 0.30807), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' reached 0.30807 (best 0.30807), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' reached 0.30621 (best 0.30621), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' reached 0.30621 (best 0.30621), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' reached 0.25713 (best 0.25713), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' reached 0.25713 (best 0.25713), saving model to '/content/lag-llama/lightning_logs/version_13/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=40` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=40` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 13 failed: \n",
            "[I 2025-11-25 02:54:18,195] Trial 13 finished with value: inf and parameters: {'context_length': 96, 'batch_size': 32, 'max_epochs': 40, 'learning_rate': 2.8425946340833635e-05, 'aug_prob': 0.0015537523517797497}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.77300 (best 3.77300), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.77300 (best 3.77300), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.17395 (best 3.17395), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.17395 (best 3.17395), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.81675 (best 2.81675), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.81675 (best 2.81675), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.66664 (best 2.66664), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.66664 (best 2.66664), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.36276 (best 2.36276), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.36276 (best 2.36276), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 2.29519 (best 2.29519), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 2.29519 (best 2.29519), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 2.02316 (best 2.02316), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 2.02316 (best 2.02316), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 1.91565 (best 1.91565), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 1.91565 (best 1.91565), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached 1.77581 (best 1.77581), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached 1.77581 (best 1.77581), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached 1.77526 (best 1.77526), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached 1.77526 (best 1.77526), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached 1.62169 (best 1.62169), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached 1.62169 (best 1.62169), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached 1.59459 (best 1.59459), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached 1.59459 (best 1.59459), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' reached 1.54570 (best 1.54570), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' reached 1.54570 (best 1.54570), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' reached 1.47138 (best 1.47138), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' reached 1.47138 (best 1.47138), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' reached 1.19504 (best 1.19504), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' reached 1.19504 (best 1.19504), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' reached 1.18174 (best 1.18174), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' reached 1.18174 (best 1.18174), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' reached 0.97109 (best 0.97109), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' reached 0.97109 (best 0.97109), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' reached 0.94092 (best 0.94092), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=66-step=3350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' reached 0.94092 (best 0.94092), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=66-step=3350.ckpt' as top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 80, global step 4050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 80, global step 4050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 81, global step 4100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 81, global step 4100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 82, global step 4150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 82, global step 4150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 84, global step 4250: 'train_loss' reached 0.91702 (best 0.91702), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=84-step=4250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 84, global step 4250: 'train_loss' reached 0.91702 (best 0.91702), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=84-step=4250.ckpt' as top 1\n",
            "INFO: Epoch 85, global step 4300: 'train_loss' reached 0.67563 (best 0.67563), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=85-step=4300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 85, global step 4300: 'train_loss' reached 0.67563 (best 0.67563), saving model to '/content/lag-llama/lightning_logs/version_14/checkpoints/epoch=85-step=4300.ckpt' as top 1\n",
            "INFO: Epoch 86, global step 4350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 86, global step 4350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 88, global step 4450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 88, global step 4450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 89, global step 4500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 89, global step 4500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 90, global step 4550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 90, global step 4550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 91, global step 4600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 91, global step 4600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 92, global step 4650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 92, global step 4650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 93, global step 4700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 93, global step 4700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 94, global step 4750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 94, global step 4750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 95, global step 4800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 95, global step 4800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 96, global step 4850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 96, global step 4850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 97, global step 4900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 97, global step 4900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 98, global step 4950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 98, global step 4950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 99, global step 5000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 99, global step 5000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=100` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=100` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 14: MAE=27.39, RMSE=34.10\n",
            "[I 2025-11-25 02:58:39,294] Trial 14 finished with value: 27.389230728149414 and parameters: {'context_length': 32, 'batch_size': 32, 'max_epochs': 100, 'learning_rate': 7.41331819281987e-05, 'aug_prob': 0.18829288357678492}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.49543 (best 3.49543), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.49543 (best 3.49543), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 2.83528 (best 2.83528), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 2.83528 (best 2.83528), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.53157 (best 2.53157), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.53157 (best 2.53157), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.41309 (best 2.41309), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.41309 (best 2.41309), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.15024 (best 2.15024), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.15024 (best 2.15024), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 1.82228 (best 1.82228), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 1.82228 (best 1.82228), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached 1.54484 (best 1.54484), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 1.54484 (best 1.54484), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached 1.49013 (best 1.49013), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached 1.49013 (best 1.49013), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached 1.26842 (best 1.26842), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached 1.26842 (best 1.26842), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached 1.18743 (best 1.18743), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached 1.18743 (best 1.18743), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' reached 1.16486 (best 1.16486), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' reached 1.16486 (best 1.16486), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' reached 0.78887 (best 0.78887), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' reached 0.78887 (best 0.78887), saving model to '/content/lag-llama/lightning_logs/version_15/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=40` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=40` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 15 failed: \n",
            "[I 2025-11-25 03:00:28,916] Trial 15 finished with value: inf and parameters: {'context_length': 96, 'batch_size': 32, 'max_epochs': 40, 'learning_rate': 0.00044362128562461424, 'aug_prob': 0.09987244312691443}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.69296 (best 3.69296), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.69296 (best 3.69296), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.00217 (best 3.00217), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.00217 (best 3.00217), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.59313 (best 2.59313), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.59313 (best 2.59313), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.16829 (best 2.16829), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.16829 (best 2.16829), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 1.79407 (best 1.79407), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 1.79407 (best 1.79407), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 1.73144 (best 1.73144), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 1.73144 (best 1.73144), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 1.36282 (best 1.36282), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 1.36282 (best 1.36282), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached 1.32036 (best 1.32036), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached 1.32036 (best 1.32036), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached 1.28264 (best 1.28264), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached 1.28264 (best 1.28264), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached 1.12932 (best 1.12932), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached 1.12932 (best 1.12932), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached 1.12092 (best 1.12092), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached 1.12092 (best 1.12092), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' reached 0.83991 (best 0.83991), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' reached 0.83991 (best 0.83991), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' reached 0.64595 (best 0.64595), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' reached 0.64595 (best 0.64595), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' reached 0.51773 (best 0.51773), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' reached 0.51773 (best 0.51773), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' reached 0.50887 (best 0.50887), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=56-step=2850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' reached 0.50887 (best 0.50887), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=56-step=2850.ckpt' as top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' reached 0.50516 (best 0.50516), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=58-step=2950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' reached 0.50516 (best 0.50516), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=58-step=2950.ckpt' as top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' reached 0.49909 (best 0.49909), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=64-step=3250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' reached 0.49909 (best 0.49909), saving model to '/content/lag-llama/lightning_logs/version_16/checkpoints/epoch=64-step=3250.ckpt' as top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 16: MAE=21.99, RMSE=28.38\n",
            "[I 2025-11-25 03:03:34,237] Trial 16 finished with value: 21.990018844604492 and parameters: {'context_length': 32, 'batch_size': 32, 'max_epochs': 70, 'learning_rate': 8.524103170211804e-05, 'aug_prob': 0.052763110971239965}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.74829 (best 3.74829), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.74829 (best 3.74829), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.43027 (best 3.43027), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.43027 (best 3.43027), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 3.01564 (best 3.01564), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 3.01564 (best 3.01564), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.97678 (best 2.97678), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.97678 (best 2.97678), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.67781 (best 2.67781), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.67781 (best 2.67781), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 2.46333 (best 2.46333), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 2.46333 (best 2.46333), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 2.19529 (best 2.19529), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 2.19529 (best 2.19529), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 2.10344 (best 2.10344), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 2.10344 (best 2.10344), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached 2.00109 (best 2.00109), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 2.00109 (best 2.00109), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached 1.88476 (best 1.88476), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached 1.88476 (best 1.88476), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' reached 1.74468 (best 1.74468), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' reached 1.74468 (best 1.74468), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' reached 1.46718 (best 1.46718), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' reached 1.46718 (best 1.46718), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' reached 1.23386 (best 1.23386), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' reached 1.23386 (best 1.23386), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' reached 1.10680 (best 1.10680), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' reached 1.10680 (best 1.10680), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' reached 1.06014 (best 1.06014), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' reached 1.06014 (best 1.06014), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' reached 0.97180 (best 0.97180), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' reached 0.97180 (best 0.97180), saving model to '/content/lag-llama/lightning_logs/version_17/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=50` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=50` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 17: MAE=37.17, RMSE=40.12\n",
            "[I 2025-11-25 03:05:46,241] Trial 17 finished with value: 37.16595458984375 and parameters: {'context_length': 64, 'batch_size': 32, 'max_epochs': 50, 'learning_rate': 2.3470345283947275e-05, 'aug_prob': 0.17734732006831505}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.50810 (best 3.50810), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.50810 (best 3.50810), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 2.74421 (best 2.74421), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 2.74421 (best 2.74421), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.46454 (best 2.46454), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.46454 (best 2.46454), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.03343 (best 2.03343), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.03343 (best 2.03343), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 1.85010 (best 1.85010), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 1.85010 (best 1.85010), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 1.80351 (best 1.80351), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 1.80351 (best 1.80351), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 1.51621 (best 1.51621), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 1.51621 (best 1.51621), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached 1.18259 (best 1.18259), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached 1.18259 (best 1.18259), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' reached 1.10578 (best 1.10578), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' reached 1.10578 (best 1.10578), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' reached 1.09953 (best 1.09953), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' reached 1.09953 (best 1.09953), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' reached 1.05340 (best 1.05340), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' reached 1.05340 (best 1.05340), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' reached 0.93982 (best 0.93982), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' reached 0.93982 (best 0.93982), saving model to '/content/lag-llama/lightning_logs/version_18/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=30` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=30` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 18 failed: \n",
            "[I 2025-11-25 03:07:08,265] Trial 18 finished with value: inf and parameters: {'context_length': 96, 'batch_size': 32, 'max_epochs': 30, 'learning_rate': 0.0003376478673506706, 'aug_prob': 0.12179574408359187}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.90484 (best 3.90484), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.90484 (best 3.90484), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.41532 (best 3.41532), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.41532 (best 3.41532), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.89459 (best 2.89459), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.89459 (best 2.89459), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.64771 (best 2.64771), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.64771 (best 2.64771), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.40711 (best 2.40711), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.40711 (best 2.40711), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 2.10513 (best 2.10513), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 2.10513 (best 2.10513), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 2.05199 (best 2.05199), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 2.05199 (best 2.05199), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 2.02944 (best 2.02944), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 2.02944 (best 2.02944), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 1.82478 (best 1.82478), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 1.82478 (best 1.82478), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached 1.73067 (best 1.73067), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 1.73067 (best 1.73067), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached 1.54521 (best 1.54521), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached 1.54521 (best 1.54521), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached 1.50341 (best 1.50341), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached 1.50341 (best 1.50341), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached 1.34328 (best 1.34328), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached 1.34328 (best 1.34328), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' reached 1.25081 (best 1.25081), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' reached 1.25081 (best 1.25081), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' reached 1.17840 (best 1.17840), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' reached 1.17840 (best 1.17840), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' reached 1.11134 (best 1.11134), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' reached 1.11134 (best 1.11134), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' reached 1.05929 (best 1.05929), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' reached 1.05929 (best 1.05929), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' reached 0.90092 (best 0.90092), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' reached 0.90092 (best 0.90092), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' reached 0.80573 (best 0.80573), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' reached 0.80573 (best 0.80573), saving model to '/content/lag-llama/lightning_logs/version_19/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=50` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=50` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 19: MAE=33.84, RMSE=40.21\n",
            "[I 2025-11-25 03:09:03,386] Trial 19 finished with value: 33.83513259887695 and parameters: {'context_length': 32, 'batch_size': 8, 'max_epochs': 50, 'learning_rate': 6.11698378132036e-05, 'aug_prob': 0.04027015068790053}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.75276 (best 3.75276), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.75276 (best 3.75276), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 2.98387 (best 2.98387), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 2.98387 (best 2.98387), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.55731 (best 2.55731), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.55731 (best 2.55731), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.23711 (best 2.23711), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.23711 (best 2.23711), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.14277 (best 2.14277), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.14277 (best 2.14277), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 2.11500 (best 2.11500), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 2.11500 (best 2.11500), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 1.68655 (best 1.68655), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 1.68655 (best 1.68655), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 1.62829 (best 1.62829), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 1.62829 (best 1.62829), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached 1.44892 (best 1.44892), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached 1.44892 (best 1.44892), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached 1.38529 (best 1.38529), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached 1.38529 (best 1.38529), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached 1.36760 (best 1.36760), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached 1.36760 (best 1.36760), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' reached 1.32230 (best 1.32230), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' reached 1.32230 (best 1.32230), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' reached 1.19437 (best 1.19437), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' reached 1.19437 (best 1.19437), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' reached 1.14292 (best 1.14292), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' reached 1.14292 (best 1.14292), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' reached 0.91780 (best 0.91780), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' reached 0.91780 (best 0.91780), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' reached 0.90886 (best 0.90886), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' reached 0.90886 (best 0.90886), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' reached 0.62736 (best 0.62736), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=56-step=2850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' reached 0.62736 (best 0.62736), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=56-step=2850.ckpt' as top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' reached 0.54749 (best 0.54749), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=59-step=3000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' reached 0.54749 (best 0.54749), saving model to '/content/lag-llama/lightning_logs/version_20/checkpoints/epoch=59-step=3000.ckpt' as top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 20: MAE=30.82, RMSE=39.86\n",
            "[I 2025-11-25 03:12:13,565] Trial 20 finished with value: 30.824037551879883 and parameters: {'context_length': 96, 'batch_size': 32, 'max_epochs': 70, 'learning_rate': 0.0009006020499939714, 'aug_prob': 0.08772836189870192}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.56611 (best 3.56611), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.56611 (best 3.56611), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.09099 (best 3.09099), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.09099 (best 3.09099), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.42381 (best 2.42381), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.42381 (best 2.42381), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.32207 (best 2.32207), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.32207 (best 2.32207), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 1.98683 (best 1.98683), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 1.98683 (best 1.98683), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 1.52546 (best 1.52546), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 1.52546 (best 1.52546), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached 1.48321 (best 1.48321), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 1.48321 (best 1.48321), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached 1.36379 (best 1.36379), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached 1.36379 (best 1.36379), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached 1.35913 (best 1.35913), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached 1.35913 (best 1.35913), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' reached 1.14928 (best 1.14928), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' reached 1.14928 (best 1.14928), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' reached 0.95238 (best 0.95238), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' reached 0.95238 (best 0.95238), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' reached 0.93565 (best 0.93565), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' reached 0.93565 (best 0.93565), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' reached 0.92834 (best 0.92834), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' reached 0.92834 (best 0.92834), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' reached 0.87296 (best 0.87296), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' reached 0.87296 (best 0.87296), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' reached 0.83472 (best 0.83472), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' reached 0.83472 (best 0.83472), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' reached 0.82779 (best 0.82779), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' reached 0.82779 (best 0.82779), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' reached 0.72586 (best 0.72586), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' reached 0.72586 (best 0.72586), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' reached 0.54037 (best 0.54037), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' reached 0.54037 (best 0.54037), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' reached 0.51678 (best 0.51678), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=67-step=3400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' reached 0.51678 (best 0.51678), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=67-step=3400.ckpt' as top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' reached 0.51463 (best 0.51463), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=69-step=3500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' reached 0.51463 (best 0.51463), saving model to '/content/lag-llama/lightning_logs/version_21/checkpoints/epoch=69-step=3500.ckpt' as top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 21: MAE=24.35, RMSE=36.19\n",
            "[I 2025-11-25 03:15:17,104] Trial 21 finished with value: 24.3503360748291 and parameters: {'context_length': 32, 'batch_size': 32, 'max_epochs': 70, 'learning_rate': 9.029245888295042e-05, 'aug_prob': 0.061684071167344506}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.78463 (best 3.78463), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.78463 (best 3.78463), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.52765 (best 3.52765), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.52765 (best 3.52765), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 3.24376 (best 3.24376), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 3.24376 (best 3.24376), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.77392 (best 2.77392), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.77392 (best 2.77392), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.52567 (best 2.52567), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.52567 (best 2.52567), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 2.29702 (best 2.29702), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 2.29702 (best 2.29702), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 2.19067 (best 2.19067), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 2.19067 (best 2.19067), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 1.89011 (best 1.89011), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 1.89011 (best 1.89011), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached 1.63451 (best 1.63451), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 1.63451 (best 1.63451), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached 1.50073 (best 1.50073), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached 1.50073 (best 1.50073), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached 1.31139 (best 1.31139), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached 1.31139 (best 1.31139), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached 1.24822 (best 1.24822), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached 1.24822 (best 1.24822), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' reached 1.05074 (best 1.05074), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' reached 1.05074 (best 1.05074), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' reached 1.02888 (best 1.02888), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' reached 1.02888 (best 1.02888), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' reached 0.97674 (best 0.97674), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' reached 0.97674 (best 0.97674), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' reached 0.88107 (best 0.88107), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' reached 0.88107 (best 0.88107), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' reached 0.81319 (best 0.81319), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' reached 0.81319 (best 0.81319), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' reached 0.71564 (best 0.71564), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' reached 0.71564 (best 0.71564), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' reached 0.60155 (best 0.60155), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' reached 0.60155 (best 0.60155), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' reached 0.60054 (best 0.60054), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' reached 0.60054 (best 0.60054), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' reached 0.56720 (best 0.56720), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' reached 0.56720 (best 0.56720), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' reached 0.45019 (best 0.45019), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=57-step=2900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' reached 0.45019 (best 0.45019), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=57-step=2900.ckpt' as top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' reached 0.35741 (best 0.35741), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=62-step=3150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' reached 0.35741 (best 0.35741), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=62-step=3150.ckpt' as top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 71, global step 3600: 'train_loss' reached 0.32617 (best 0.32617), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=71-step=3600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 71, global step 3600: 'train_loss' reached 0.32617 (best 0.32617), saving model to '/content/lag-llama/lightning_logs/version_22/checkpoints/epoch=71-step=3600.ckpt' as top 1\n",
            "INFO: Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=80` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=80` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 22 failed: \n",
            "[I 2025-11-25 03:18:47,649] Trial 22 finished with value: inf and parameters: {'context_length': 32, 'batch_size': 32, 'max_epochs': 80, 'learning_rate': 2.670340676363997e-05, 'aug_prob': 0.029533799996809926}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.57637 (best 3.57637), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.57637 (best 3.57637), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 2.97430 (best 2.97430), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 2.97430 (best 2.97430), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.32335 (best 2.32335), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.32335 (best 2.32335), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.23821 (best 2.23821), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.23821 (best 2.23821), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 1.90107 (best 1.90107), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 1.90107 (best 1.90107), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 1.58543 (best 1.58543), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 1.58543 (best 1.58543), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 1.47314 (best 1.47314), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 1.47314 (best 1.47314), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached 1.44064 (best 1.44064), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached 1.44064 (best 1.44064), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached 1.29510 (best 1.29510), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached 1.29510 (best 1.29510), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached 1.18919 (best 1.18919), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached 1.18919 (best 1.18919), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' reached 1.12478 (best 1.12478), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' reached 1.12478 (best 1.12478), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' reached 1.05204 (best 1.05204), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' reached 1.05204 (best 1.05204), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' reached 0.92148 (best 0.92148), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' reached 0.92148 (best 0.92148), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' reached 0.71017 (best 0.71017), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' reached 0.71017 (best 0.71017), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' reached 0.60942 (best 0.60942), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=52-step=2650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' reached 0.60942 (best 0.60942), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=52-step=2650.ckpt' as top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' reached 0.48050 (best 0.48050), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=61-step=3100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' reached 0.48050 (best 0.48050), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=61-step=3100.ckpt' as top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 77, global step 3900: 'train_loss' reached 0.43631 (best 0.43631), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=77-step=3900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 77, global step 3900: 'train_loss' reached 0.43631 (best 0.43631), saving model to '/content/lag-llama/lightning_logs/version_23/checkpoints/epoch=77-step=3900.ckpt' as top 1\n",
            "INFO: Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=80` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=80` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 23: MAE=23.05, RMSE=32.74\n",
            "[I 2025-11-25 03:22:16,134] Trial 23 finished with value: 23.048948287963867 and parameters: {'context_length': 32, 'batch_size': 32, 'max_epochs': 80, 'learning_rate': 9.44417030838793e-05, 'aug_prob': 0.06804310817946392}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.62420 (best 3.62420), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.62420 (best 3.62420), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 2.76981 (best 2.76981), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 2.76981 (best 2.76981), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.25299 (best 2.25299), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.25299 (best 2.25299), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.18298 (best 2.18298), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.18298 (best 2.18298), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.14742 (best 2.14742), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.14742 (best 2.14742), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 1.67071 (best 1.67071), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 1.67071 (best 1.67071), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 1.58666 (best 1.58666), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 1.58666 (best 1.58666), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 1.57033 (best 1.57033), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 1.57033 (best 1.57033), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached 1.54770 (best 1.54770), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 1.54770 (best 1.54770), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached 1.29394 (best 1.29394), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached 1.29394 (best 1.29394), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached 1.20255 (best 1.20255), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached 1.20255 (best 1.20255), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached 1.16920 (best 1.16920), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached 1.16920 (best 1.16920), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' reached 0.98715 (best 0.98715), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' reached 0.98715 (best 0.98715), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' reached 0.95410 (best 0.95410), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' reached 0.95410 (best 0.95410), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' reached 0.92521 (best 0.92521), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' reached 0.92521 (best 0.92521), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' reached 0.80760 (best 0.80760), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' reached 0.80760 (best 0.80760), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' reached 0.80493 (best 0.80493), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' reached 0.80493 (best 0.80493), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' reached 0.76918 (best 0.76918), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' reached 0.76918 (best 0.76918), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' reached 0.65528 (best 0.65528), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' reached 0.65528 (best 0.65528), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' reached 0.57916 (best 0.57916), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=53-step=2700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' reached 0.57916 (best 0.57916), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=53-step=2700.ckpt' as top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' reached 0.35518 (best 0.35518), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=55-step=2800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' reached 0.35518 (best 0.35518), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=55-step=2800.ckpt' as top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 78, global step 3950: 'train_loss' reached 0.35434 (best 0.35434), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=78-step=3950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 78, global step 3950: 'train_loss' reached 0.35434 (best 0.35434), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=78-step=3950.ckpt' as top 1\n",
            "INFO: Epoch 79, global step 4000: 'train_loss' reached 0.30802 (best 0.30802), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=79-step=4000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 79, global step 4000: 'train_loss' reached 0.30802 (best 0.30802), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=79-step=4000.ckpt' as top 1\n",
            "INFO: Epoch 80, global step 4050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 80, global step 4050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 81, global step 4100: 'train_loss' reached 0.28019 (best 0.28019), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=81-step=4100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 81, global step 4100: 'train_loss' reached 0.28019 (best 0.28019), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=81-step=4100.ckpt' as top 1\n",
            "INFO: Epoch 82, global step 4150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 82, global step 4150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 84, global step 4250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 84, global step 4250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 85, global step 4300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 85, global step 4300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 86, global step 4350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 86, global step 4350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 88, global step 4450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 88, global step 4450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 89, global step 4500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 89, global step 4500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 90, global step 4550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 90, global step 4550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 91, global step 4600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 91, global step 4600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 92, global step 4650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 92, global step 4650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 93, global step 4700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 93, global step 4700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 94, global step 4750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 94, global step 4750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 95, global step 4800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 95, global step 4800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 96, global step 4850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 96, global step 4850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 97, global step 4900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 97, global step 4900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 98, global step 4950: 'train_loss' reached 0.25919 (best 0.25919), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=98-step=4950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 98, global step 4950: 'train_loss' reached 0.25919 (best 0.25919), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=98-step=4950.ckpt' as top 1\n",
            "INFO: Epoch 99, global step 5000: 'train_loss' reached 0.21508 (best 0.21508), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=99-step=5000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 99, global step 5000: 'train_loss' reached 0.21508 (best 0.21508), saving model to '/content/lag-llama/lightning_logs/version_24/checkpoints/epoch=99-step=5000.ckpt' as top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=100` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=100` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 24 failed: \n",
            "[I 2025-11-25 03:26:36,860] Trial 24 finished with value: inf and parameters: {'context_length': 32, 'batch_size': 32, 'max_epochs': 100, 'learning_rate': 0.00021656331922769736, 'aug_prob': 0.045892973278311974}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.78596 (best 3.78596), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.78596 (best 3.78596), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.35493 (best 3.35493), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.35493 (best 3.35493), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 3.07637 (best 3.07637), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 3.07637 (best 3.07637), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.59570 (best 2.59570), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.59570 (best 2.59570), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.45127 (best 2.45127), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.45127 (best 2.45127), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 2.31924 (best 2.31924), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 2.31924 (best 2.31924), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 2.28949 (best 2.28949), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 2.28949 (best 2.28949), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 1.88842 (best 1.88842), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 1.88842 (best 1.88842), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached 1.80499 (best 1.80499), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 1.80499 (best 1.80499), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached 1.64044 (best 1.64044), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached 1.64044 (best 1.64044), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached 1.59043 (best 1.59043), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached 1.59043 (best 1.59043), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' reached 1.51297 (best 1.51297), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' reached 1.51297 (best 1.51297), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' reached 1.46205 (best 1.46205), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' reached 1.46205 (best 1.46205), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' reached 1.28513 (best 1.28513), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' reached 1.28513 (best 1.28513), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' reached 1.14991 (best 1.14991), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' reached 1.14991 (best 1.14991), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' reached 1.09384 (best 1.09384), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' reached 1.09384 (best 1.09384), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' reached 1.08046 (best 1.08046), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' reached 1.08046 (best 1.08046), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' reached 0.85676 (best 0.85676), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' reached 0.85676 (best 0.85676), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' reached 0.79213 (best 0.79213), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=55-step=2800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' reached 0.79213 (best 0.79213), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=55-step=2800.ckpt' as top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' reached 0.68110 (best 0.68110), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=58-step=2950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' reached 0.68110 (best 0.68110), saving model to '/content/lag-llama/lightning_logs/version_25/checkpoints/epoch=58-step=2950.ckpt' as top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 25: MAE=19.38, RMSE=24.94\n",
            "[I 2025-11-25 03:29:14,090] Trial 25 finished with value: 19.376888275146484 and parameters: {'context_length': 32, 'batch_size': 32, 'max_epochs': 60, 'learning_rate': 3.664979070205263e-05, 'aug_prob': 0.11677684458585307}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.91762 (best 3.91762), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.91762 (best 3.91762), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.57060 (best 3.57060), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.57060 (best 3.57060), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 3.33254 (best 3.33254), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 3.33254 (best 3.33254), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.98866 (best 2.98866), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.98866 (best 2.98866), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.67433 (best 2.67433), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.67433 (best 2.67433), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 2.54536 (best 2.54536), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 2.54536 (best 2.54536), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 2.50705 (best 2.50705), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 2.50705 (best 2.50705), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 2.30588 (best 2.30588), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 2.30588 (best 2.30588), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 2.22868 (best 2.22868), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 2.22868 (best 2.22868), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached 2.21321 (best 2.21321), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached 2.21321 (best 2.21321), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached 1.84601 (best 1.84601), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached 1.84601 (best 1.84601), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached 1.80417 (best 1.80417), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached 1.80417 (best 1.80417), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' reached 1.75653 (best 1.75653), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' reached 1.75653 (best 1.75653), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' reached 1.71932 (best 1.71932), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' reached 1.71932 (best 1.71932), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' reached 1.39883 (best 1.39883), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' reached 1.39883 (best 1.39883), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' reached 1.17484 (best 1.17484), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' reached 1.17484 (best 1.17484), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' reached 1.13076 (best 1.13076), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' reached 1.13076 (best 1.13076), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' reached 1.06680 (best 1.06680), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=56-step=2850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' reached 1.06680 (best 1.06680), saving model to '/content/lag-llama/lightning_logs/version_26/checkpoints/epoch=56-step=2850.ckpt' as top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 26 failed: \n",
            "[I 2025-11-25 03:31:49,396] Trial 26 finished with value: inf and parameters: {'context_length': 16, 'batch_size': 32, 'max_epochs': 60, 'learning_rate': 3.411455732393064e-05, 'aug_prob': 0.16349499187843877}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.74039 (best 3.74039), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.74039 (best 3.74039), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.54575 (best 3.54575), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.54575 (best 3.54575), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 3.17307 (best 3.17307), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 3.17307 (best 3.17307), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.90803 (best 2.90803), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.90803 (best 2.90803), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.64616 (best 2.64616), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.64616 (best 2.64616), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 2.40930 (best 2.40930), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 2.40930 (best 2.40930), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 2.15384 (best 2.15384), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 2.15384 (best 2.15384), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 2.09320 (best 2.09320), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 2.09320 (best 2.09320), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached 2.04374 (best 2.04374), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 2.04374 (best 2.04374), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached 1.87822 (best 1.87822), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached 1.87822 (best 1.87822), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached 1.85831 (best 1.85831), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached 1.85831 (best 1.85831), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached 1.54380 (best 1.54380), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached 1.54380 (best 1.54380), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' reached 1.23042 (best 1.23042), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' reached 1.23042 (best 1.23042), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' reached 1.17298 (best 1.17298), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' reached 1.17298 (best 1.17298), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' reached 1.00465 (best 1.00465), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' reached 1.00465 (best 1.00465), saving model to '/content/lag-llama/lightning_logs/version_27/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=30` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=30` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 27 failed: \n",
            "[I 2025-11-25 03:33:07,519] Trial 27 finished with value: inf and parameters: {'context_length': 64, 'batch_size': 32, 'max_epochs': 30, 'learning_rate': 1.8462890349923244e-05, 'aug_prob': 0.11160199810084238}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.55162 (best 3.55162), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.55162 (best 3.55162), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.28014 (best 3.28014), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.28014 (best 3.28014), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 3.19502 (best 3.19502), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 3.19502 (best 3.19502), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.62232 (best 2.62232), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.62232 (best 2.62232), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.44996 (best 2.44996), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.44996 (best 2.44996), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 2.28625 (best 2.28625), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 2.28625 (best 2.28625), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 2.13510 (best 2.13510), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 2.13510 (best 2.13510), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 2.10566 (best 2.10566), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 2.10566 (best 2.10566), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 1.96340 (best 1.96340), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 1.96340 (best 1.96340), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached 1.78936 (best 1.78936), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached 1.78936 (best 1.78936), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached 1.57807 (best 1.57807), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached 1.57807 (best 1.57807), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached 1.52261 (best 1.52261), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached 1.52261 (best 1.52261), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached 1.47020 (best 1.47020), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached 1.47020 (best 1.47020), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached 1.41502 (best 1.41502), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached 1.41502 (best 1.41502), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' reached 1.18011 (best 1.18011), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' reached 1.18011 (best 1.18011), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' reached 1.16206 (best 1.16206), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' reached 1.16206 (best 1.16206), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' reached 1.06262 (best 1.06262), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' reached 1.06262 (best 1.06262), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' reached 1.04797 (best 1.04797), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' reached 1.04797 (best 1.04797), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' reached 0.90895 (best 0.90895), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' reached 0.90895 (best 0.90895), saving model to '/content/lag-llama/lightning_logs/version_28/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=50` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=50` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 28: MAE=34.46, RMSE=38.31\n",
            "[I 2025-11-25 03:35:00,013] Trial 28 finished with value: 34.45512008666992 and parameters: {'context_length': 32, 'batch_size': 8, 'max_epochs': 50, 'learning_rate': 6.267974241522302e-05, 'aug_prob': 0.07895386229364781}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 4.00401 (best 4.00401), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 4.00401 (best 4.00401), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.74160 (best 3.74160), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.74160 (best 3.74160), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 3.57158 (best 3.57158), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 3.57158 (best 3.57158), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 3.31449 (best 3.31449), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 3.31449 (best 3.31449), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 3.23387 (best 3.23387), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 3.23387 (best 3.23387), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 2.96124 (best 2.96124), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 2.96124 (best 2.96124), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 2.87012 (best 2.87012), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 2.87012 (best 2.87012), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 2.60284 (best 2.60284), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 2.60284 (best 2.60284), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 2.50371 (best 2.50371), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 2.50371 (best 2.50371), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached 2.49122 (best 2.49122), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 2.49122 (best 2.49122), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached 2.31386 (best 2.31386), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached 2.31386 (best 2.31386), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached 2.30797 (best 2.30797), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached 2.30797 (best 2.30797), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached 2.27669 (best 2.27669), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached 2.27669 (best 2.27669), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' reached 2.14467 (best 2.14467), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' reached 2.14467 (best 2.14467), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached 2.03975 (best 2.03975), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached 2.03975 (best 2.03975), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' reached 1.88174 (best 1.88174), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' reached 1.88174 (best 1.88174), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' reached 1.77856 (best 1.77856), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' reached 1.77856 (best 1.77856), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' reached 1.71759 (best 1.71759), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' reached 1.71759 (best 1.71759), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' reached 1.61426 (best 1.61426), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' reached 1.61426 (best 1.61426), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' reached 1.49560 (best 1.49560), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' reached 1.49560 (best 1.49560), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' reached 1.40965 (best 1.40965), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' reached 1.40965 (best 1.40965), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' reached 1.27341 (best 1.27341), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' reached 1.27341 (best 1.27341), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 76, global step 3850: 'train_loss' reached 1.24968 (best 1.24968), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=76-step=3850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 76, global step 3850: 'train_loss' reached 1.24968 (best 1.24968), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=76-step=3850.ckpt' as top 1\n",
            "INFO: Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 80, global step 4050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 80, global step 4050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 81, global step 4100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 81, global step 4100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 82, global step 4150: 'train_loss' reached 1.02864 (best 1.02864), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=82-step=4150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 82, global step 4150: 'train_loss' reached 1.02864 (best 1.02864), saving model to '/content/lag-llama/lightning_logs/version_29/checkpoints/epoch=82-step=4150.ckpt' as top 1\n",
            "INFO: Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 84, global step 4250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 84, global step 4250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 85, global step 4300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 85, global step 4300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 86, global step 4350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 86, global step 4350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 88, global step 4450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 88, global step 4450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 89, global step 4500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 89, global step 4500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=90` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=90` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 29: MAE=41.88, RMSE=45.32\n",
            "[I 2025-11-25 03:38:32,430] Trial 29 finished with value: 41.878231048583984 and parameters: {'context_length': 32, 'batch_size': 16, 'max_epochs': 90, 'learning_rate': 1.8552067455486527e-05, 'aug_prob': 0.2325684837502812}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.65084 (best 3.65084), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.65084 (best 3.65084), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 2.94331 (best 2.94331), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 2.94331 (best 2.94331), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.39980 (best 2.39980), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.39980 (best 2.39980), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.28831 (best 2.28831), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.28831 (best 2.28831), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.13744 (best 2.13744), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.13744 (best 2.13744), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 2.13713 (best 2.13713), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 2.13713 (best 2.13713), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 2.05563 (best 2.05563), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 2.05563 (best 2.05563), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 1.99437 (best 1.99437), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 1.99437 (best 1.99437), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 1.81343 (best 1.81343), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 1.81343 (best 1.81343), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached 1.51168 (best 1.51168), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached 1.51168 (best 1.51168), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached 1.42056 (best 1.42056), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached 1.42056 (best 1.42056), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' reached 1.29460 (best 1.29460), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' reached 1.29460 (best 1.29460), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached 1.27456 (best 1.27456), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached 1.27456 (best 1.27456), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' reached 1.27294 (best 1.27294), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' reached 1.27294 (best 1.27294), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' reached 1.10562 (best 1.10562), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' reached 1.10562 (best 1.10562), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' reached 1.06206 (best 1.06206), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' reached 1.06206 (best 1.06206), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' reached 0.99879 (best 0.99879), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' reached 0.99879 (best 0.99879), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' reached 0.90953 (best 0.90953), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' reached 0.90953 (best 0.90953), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' reached 0.67707 (best 0.67707), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' reached 0.67707 (best 0.67707), saving model to '/content/lag-llama/lightning_logs/version_30/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 failed: \n",
            "[I 2025-11-25 03:40:47,292] Trial 30 finished with value: inf and parameters: {'context_length': 96, 'batch_size': 8, 'max_epochs': 60, 'learning_rate': 0.00012314703255228099, 'aug_prob': 0.15276458551685493}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.60341 (best 3.60341), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.60341 (best 3.60341), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.09933 (best 3.09933), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.09933 (best 3.09933), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.44235 (best 2.44235), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.44235 (best 2.44235), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.13783 (best 2.13783), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.13783 (best 2.13783), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 1.88858 (best 1.88858), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 1.88858 (best 1.88858), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 1.65434 (best 1.65434), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 1.65434 (best 1.65434), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 1.61725 (best 1.61725), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 1.61725 (best 1.61725), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 1.47538 (best 1.47538), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 1.47538 (best 1.47538), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached 1.28266 (best 1.28266), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 1.28266 (best 1.28266), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached 1.24451 (best 1.24451), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached 1.24451 (best 1.24451), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached 1.23074 (best 1.23074), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached 1.23074 (best 1.23074), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached 1.03834 (best 1.03834), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached 1.03834 (best 1.03834), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached 1.03320 (best 1.03320), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached 1.03320 (best 1.03320), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached 0.87162 (best 0.87162), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached 0.87162 (best 0.87162), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached 0.80671 (best 0.80671), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached 0.80671 (best 0.80671), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' reached 0.78837 (best 0.78837), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' reached 0.78837 (best 0.78837), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' reached 0.70847 (best 0.70847), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' reached 0.70847 (best 0.70847), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' reached 0.65834 (best 0.65834), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' reached 0.65834 (best 0.65834), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' reached 0.58764 (best 0.58764), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' reached 0.58764 (best 0.58764), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' reached 0.55801 (best 0.55801), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' reached 0.55801 (best 0.55801), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' reached 0.48862 (best 0.48862), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' reached 0.48862 (best 0.48862), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' reached 0.40766 (best 0.40766), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' reached 0.40766 (best 0.40766), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' reached 0.37770 (best 0.37770), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' reached 0.37770 (best 0.37770), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' reached 0.28108 (best 0.28108), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=50-step=2550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' reached 0.28108 (best 0.28108), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=50-step=2550.ckpt' as top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' reached 0.21117 (best 0.21117), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=56-step=2850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' reached 0.21117 (best 0.21117), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=56-step=2850.ckpt' as top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' reached 0.19097 (best 0.19097), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=68-step=3450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' reached 0.19097 (best 0.19097), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=68-step=3450.ckpt' as top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' reached 0.17701 (best 0.17701), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=69-step=3500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' reached 0.17701 (best 0.17701), saving model to '/content/lag-llama/lightning_logs/version_31/checkpoints/epoch=69-step=3500.ckpt' as top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 31 failed: \n",
            "[I 2025-11-25 03:43:43,473] Trial 31 finished with value: inf and parameters: {'context_length': 32, 'batch_size': 32, 'max_epochs': 70, 'learning_rate': 7.30872532393187e-05, 'aug_prob': 0.006325049455132781}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.69609 (best 3.69609), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.69609 (best 3.69609), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.14474 (best 3.14474), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.14474 (best 3.14474), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.69857 (best 2.69857), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.69857 (best 2.69857), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.52997 (best 2.52997), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.52997 (best 2.52997), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.08379 (best 2.08379), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.08379 (best 2.08379), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 1.92662 (best 1.92662), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 1.92662 (best 1.92662), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 1.90961 (best 1.90961), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 1.90961 (best 1.90961), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 1.73055 (best 1.73055), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 1.73055 (best 1.73055), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 1.51899 (best 1.51899), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 1.51899 (best 1.51899), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached 1.34124 (best 1.34124), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached 1.34124 (best 1.34124), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached 1.13889 (best 1.13889), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached 1.13889 (best 1.13889), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' reached 1.12550 (best 1.12550), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' reached 1.12550 (best 1.12550), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' reached 0.92525 (best 0.92525), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' reached 0.92525 (best 0.92525), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' reached 0.88023 (best 0.88023), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' reached 0.88023 (best 0.88023), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' reached 0.74889 (best 0.74889), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' reached 0.74889 (best 0.74889), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' reached 0.74724 (best 0.74724), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' reached 0.74724 (best 0.74724), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' reached 0.64170 (best 0.64170), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' reached 0.64170 (best 0.64170), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' reached 0.57342 (best 0.57342), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' reached 0.57342 (best 0.57342), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' reached 0.40837 (best 0.40837), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' reached 0.40837 (best 0.40837), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' reached 0.38359 (best 0.38359), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' reached 0.38359 (best 0.38359), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' reached 0.28114 (best 0.28114), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=61-step=3100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' reached 0.28114 (best 0.28114), saving model to '/content/lag-llama/lightning_logs/version_32/checkpoints/epoch=61-step=3100.ckpt' as top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=80` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=80` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 32 failed: \n",
            "[I 2025-11-25 03:47:05,205] Trial 32 finished with value: inf and parameters: {'context_length': 32, 'batch_size': 32, 'max_epochs': 80, 'learning_rate': 5.3076318282328375e-05, 'aug_prob': 0.019614246367019444}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.61514 (best 3.61514), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.61514 (best 3.61514), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 2.96762 (best 2.96762), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 2.96762 (best 2.96762), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.74929 (best 2.74929), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.74929 (best 2.74929), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.40208 (best 2.40208), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.40208 (best 2.40208), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.10480 (best 2.10480), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.10480 (best 2.10480), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 1.98663 (best 1.98663), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 1.98663 (best 1.98663), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 1.84191 (best 1.84191), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 1.84191 (best 1.84191), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached 1.72307 (best 1.72307), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 1.72307 (best 1.72307), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached 1.48930 (best 1.48930), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached 1.48930 (best 1.48930), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached 1.47212 (best 1.47212), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached 1.47212 (best 1.47212), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached 1.30531 (best 1.30531), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached 1.30531 (best 1.30531), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached 1.00766 (best 1.00766), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached 1.00766 (best 1.00766), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' reached 0.90103 (best 0.90103), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' reached 0.90103 (best 0.90103), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' reached 0.86918 (best 0.86918), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' reached 0.86918 (best 0.86918), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' reached 0.71800 (best 0.71800), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' reached 0.71800 (best 0.71800), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' reached 0.60965 (best 0.60965), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=59-step=3000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' reached 0.60965 (best 0.60965), saving model to '/content/lag-llama/lightning_logs/version_33/checkpoints/epoch=59-step=3000.ckpt' as top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 33 failed: \n",
            "[I 2025-11-25 03:49:34,501] Trial 33 finished with value: inf and parameters: {'context_length': 32, 'batch_size': 32, 'max_epochs': 60, 'learning_rate': 0.00015056307906182278, 'aug_prob': 0.1096334072109419}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.58024 (best 3.58024), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.58024 (best 3.58024), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 2.80264 (best 2.80264), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 2.80264 (best 2.80264), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.50768 (best 2.50768), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.50768 (best 2.50768), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.14232 (best 2.14232), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.14232 (best 2.14232), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 1.93736 (best 1.93736), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 1.93736 (best 1.93736), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 1.79853 (best 1.79853), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 1.79853 (best 1.79853), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 1.67576 (best 1.67576), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 1.67576 (best 1.67576), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached 1.23400 (best 1.23400), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached 1.23400 (best 1.23400), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached 1.06655 (best 1.06655), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached 1.06655 (best 1.06655), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' reached 1.03687 (best 1.03687), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' reached 1.03687 (best 1.03687), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' reached 0.94791 (best 0.94791), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' reached 0.94791 (best 0.94791), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' reached 0.80590 (best 0.80590), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' reached 0.80590 (best 0.80590), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' reached 0.78618 (best 0.78618), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' reached 0.78618 (best 0.78618), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' reached 0.74265 (best 0.74265), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' reached 0.74265 (best 0.74265), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' reached 0.54942 (best 0.54942), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' reached 0.54942 (best 0.54942), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' reached 0.44925 (best 0.44925), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=54-step=2750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' reached 0.44925 (best 0.44925), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=54-step=2750.ckpt' as top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' reached 0.41492 (best 0.41492), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=60-step=3050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' reached 0.41492 (best 0.41492), saving model to '/content/lag-llama/lightning_logs/version_34/checkpoints/epoch=60-step=3050.ckpt' as top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 34: MAE=24.82, RMSE=33.06\n",
            "[I 2025-11-25 03:52:30,184] Trial 34 finished with value: 24.819143295288086 and parameters: {'context_length': 32, 'batch_size': 32, 'max_epochs': 70, 'learning_rate': 0.000209339263546694, 'aug_prob': 0.048805137751065916}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.93290 (best 3.93290), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.93290 (best 3.93290), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.46751 (best 3.46751), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.46751 (best 3.46751), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 3.07453 (best 3.07453), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 3.07453 (best 3.07453), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.86671 (best 2.86671), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.86671 (best 2.86671), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 2.72952 (best 2.72952), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 2.72952 (best 2.72952), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 2.44685 (best 2.44685), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 2.44685 (best 2.44685), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 2.38023 (best 2.38023), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 2.38023 (best 2.38023), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached 2.15943 (best 2.15943), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 2.15943 (best 2.15943), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached 2.02906 (best 2.02906), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached 2.02906 (best 2.02906), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached 1.80607 (best 1.80607), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached 1.80607 (best 1.80607), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached 1.70678 (best 1.70678), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached 1.70678 (best 1.70678), saving model to '/content/lag-llama/lightning_logs/version_35/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=20` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=20` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 35 failed: \n",
            "[I 2025-11-25 03:53:17,980] Trial 35 finished with value: inf and parameters: {'context_length': 16, 'batch_size': 16, 'max_epochs': 20, 'learning_rate': 3.564470796659714e-05, 'aug_prob': 0.12760473244205206}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.53508 (best 3.53508), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.53508 (best 3.53508), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 2.68751 (best 2.68751), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 2.68751 (best 2.68751), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.24997 (best 2.24997), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.24997 (best 2.24997), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 1.67324 (best 1.67324), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 1.67324 (best 1.67324), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 1.42327 (best 1.42327), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 1.42327 (best 1.42327), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 1.10899 (best 1.10899), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 1.10899 (best 1.10899), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached 0.78334 (best 0.78334), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached 0.78334 (best 0.78334), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached 0.70574 (best 0.70574), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached 0.70574 (best 0.70574), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached 0.63716 (best 0.63716), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached 0.63716 (best 0.63716), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' reached 0.57275 (best 0.57275), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' reached 0.57275 (best 0.57275), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' reached 0.51940 (best 0.51940), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' reached 0.51940 (best 0.51940), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' reached 0.44376 (best 0.44376), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' reached 0.44376 (best 0.44376), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' reached 0.29326 (best 0.29326), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' reached 0.29326 (best 0.29326), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' reached 0.23010 (best 0.23010), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' reached 0.23010 (best 0.23010), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' reached 0.21954 (best 0.21954), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' reached 0.21954 (best 0.21954), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' reached 0.12863 (best 0.12863), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' reached 0.12863 (best 0.12863), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' reached 0.07872 (best 0.07872), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=56-step=2850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' reached 0.07872 (best 0.07872), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=56-step=2850.ckpt' as top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' reached 0.06836 (best 0.06836), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=57-step=2900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' reached 0.06836 (best 0.06836), saving model to '/content/lag-llama/lightning_logs/version_36/checkpoints/epoch=57-step=2900.ckpt' as top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 36 failed: \n",
            "[I 2025-11-25 03:55:59,513] Trial 36 finished with value: inf and parameters: {'context_length': 96, 'batch_size': 32, 'max_epochs': 60, 'learning_rate': 0.00011890927423969165, 'aug_prob': 0.021368040437049263}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.66214 (best 3.66214), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.66214 (best 3.66214), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.33015 (best 3.33015), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.33015 (best 3.33015), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.75536 (best 2.75536), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.75536 (best 2.75536), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.59571 (best 2.59571), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.59571 (best 2.59571), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.29832 (best 2.29832), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.29832 (best 2.29832), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 2.23527 (best 2.23527), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 2.23527 (best 2.23527), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 2.05416 (best 2.05416), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 2.05416 (best 2.05416), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 2.03832 (best 2.03832), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 2.03832 (best 2.03832), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 1.76080 (best 1.76080), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 1.76080 (best 1.76080), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached 1.67881 (best 1.67881), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 1.67881 (best 1.67881), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached 1.49584 (best 1.49584), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached 1.49584 (best 1.49584), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached 1.31010 (best 1.31010), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached 1.31010 (best 1.31010), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' reached 1.22549 (best 1.22549), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' reached 1.22549 (best 1.22549), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' reached 0.94448 (best 0.94448), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' reached 0.94448 (best 0.94448), saving model to '/content/lag-llama/lightning_logs/version_37/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=40` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=40` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 37: MAE=34.46, RMSE=36.74\n",
            "[I 2025-11-25 03:57:30,723] Trial 37 finished with value: 34.45994567871094 and parameters: {'context_length': 32, 'batch_size': 16, 'max_epochs': 40, 'learning_rate': 7.636193682866064e-05, 'aug_prob': 0.07817541617289822}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 4.02436 (best 4.02436), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 4.02436 (best 4.02436), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.31702 (best 3.31702), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.31702 (best 3.31702), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.95905 (best 2.95905), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.95905 (best 2.95905), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.91999 (best 2.91999), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.91999 (best 2.91999), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.68266 (best 2.68266), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.68266 (best 2.68266), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 2.48132 (best 2.48132), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 2.48132 (best 2.48132), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 2.18154 (best 2.18154), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 2.18154 (best 2.18154), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 1.98666 (best 1.98666), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 1.98666 (best 1.98666), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached 1.92508 (best 1.92508), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached 1.92508 (best 1.92508), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached 1.85158 (best 1.85158), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached 1.85158 (best 1.85158), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached 1.67953 (best 1.67953), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached 1.67953 (best 1.67953), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' reached 1.60010 (best 1.60010), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' reached 1.60010 (best 1.60010), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' reached 1.54919 (best 1.54919), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' reached 1.54919 (best 1.54919), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' reached 1.44815 (best 1.44815), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' reached 1.44815 (best 1.44815), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' reached 1.36664 (best 1.36664), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' reached 1.36664 (best 1.36664), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' reached 1.34650 (best 1.34650), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' reached 1.34650 (best 1.34650), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' reached 1.25989 (best 1.25989), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=51-step=2600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' reached 1.25989 (best 1.25989), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=51-step=2600.ckpt' as top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' reached 1.15678 (best 1.15678), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=54-step=2750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' reached 1.15678 (best 1.15678), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=54-step=2750.ckpt' as top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' reached 1.12318 (best 1.12318), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=61-step=3100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' reached 1.12318 (best 1.12318), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=61-step=3100.ckpt' as top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' reached 1.01931 (best 1.01931), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=65-step=3300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' reached 1.01931 (best 1.01931), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=65-step=3300.ckpt' as top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 75, global step 3800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 80, global step 4050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 80, global step 4050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 81, global step 4100: 'train_loss' reached 0.79971 (best 0.79971), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=81-step=4100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 81, global step 4100: 'train_loss' reached 0.79971 (best 0.79971), saving model to '/content/lag-llama/lightning_logs/version_38/checkpoints/epoch=81-step=4100.ckpt' as top 1\n",
            "INFO: Epoch 82, global step 4150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 82, global step 4150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 84, global step 4250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 84, global step 4250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 85, global step 4300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 85, global step 4300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 86, global step 4350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 86, global step 4350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 88, global step 4450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 88, global step 4450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 89, global step 4500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 89, global step 4500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=90` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=90` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 38: MAE=28.44, RMSE=33.11\n",
            "[I 2025-11-25 04:00:38,810] Trial 38 finished with value: 28.43659019470215 and parameters: {'context_length': 16, 'batch_size': 8, 'max_epochs': 90, 'learning_rate': 0.00016347610200287164, 'aug_prob': 0.050058165713788044}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.65771 (best 3.65771), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.65771 (best 3.65771), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.25092 (best 3.25092), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.25092 (best 3.25092), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.91863 (best 2.91863), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.91863 (best 2.91863), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.58888 (best 2.58888), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.58888 (best 2.58888), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.43057 (best 2.43057), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.43057 (best 2.43057), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 2.34672 (best 2.34672), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 2.34672 (best 2.34672), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 2.29624 (best 2.29624), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 2.29624 (best 2.29624), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 2.17669 (best 2.17669), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 2.17669 (best 2.17669), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 2.14358 (best 2.14358), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 2.14358 (best 2.14358), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached 2.09251 (best 2.09251), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 2.09251 (best 2.09251), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached 2.03210 (best 2.03210), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached 2.03210 (best 2.03210), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' reached 1.88452 (best 1.88452), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' reached 1.88452 (best 1.88452), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached 1.78881 (best 1.78881), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached 1.78881 (best 1.78881), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' reached 1.67842 (best 1.67842), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' reached 1.67842 (best 1.67842), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' reached 1.52653 (best 1.52653), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' reached 1.52653 (best 1.52653), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' reached 1.45249 (best 1.45249), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' reached 1.45249 (best 1.45249), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' reached 1.31720 (best 1.31720), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' reached 1.31720 (best 1.31720), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' reached 1.26025 (best 1.26025), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' reached 1.26025 (best 1.26025), saving model to '/content/lag-llama/lightning_logs/version_39/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 39: MAE=21.55, RMSE=26.99\n",
            "[I 2025-11-25 04:03:10,295] Trial 39 finished with value: 21.546293258666992 and parameters: {'context_length': 64, 'batch_size': 32, 'max_epochs': 60, 'learning_rate': 4.0268186212682e-05, 'aug_prob': 0.29729329913604613}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.70596 (best 3.70596), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.70596 (best 3.70596), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.44898 (best 3.44898), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.44898 (best 3.44898), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 3.23067 (best 3.23067), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 3.23067 (best 3.23067), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.99522 (best 2.99522), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.99522 (best 2.99522), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.82608 (best 2.82608), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.82608 (best 2.82608), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 2.75216 (best 2.75216), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 2.75216 (best 2.75216), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 2.46438 (best 2.46438), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 2.46438 (best 2.46438), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 2.37984 (best 2.37984), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 2.37984 (best 2.37984), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 2.22138 (best 2.22138), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 2.22138 (best 2.22138), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached 1.89977 (best 1.89977), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached 1.89977 (best 1.89977), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached 1.81315 (best 1.81315), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached 1.81315 (best 1.81315), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached 1.74901 (best 1.74901), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached 1.74901 (best 1.74901), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' reached 1.73959 (best 1.73959), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' reached 1.73959 (best 1.73959), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' reached 1.58502 (best 1.58502), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' reached 1.58502 (best 1.58502), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' reached 1.48868 (best 1.48868), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' reached 1.48868 (best 1.48868), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' reached 1.26095 (best 1.26095), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' reached 1.26095 (best 1.26095), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' reached 1.23472 (best 1.23472), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' reached 1.23472 (best 1.23472), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' reached 0.86583 (best 0.86583), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' reached 0.86583 (best 0.86583), saving model to '/content/lag-llama/lightning_logs/version_40/checkpoints/epoch=42-step=2150.ckpt' as top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=50` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=50` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 40 failed: \n",
            "[I 2025-11-25 04:05:09,785] Trial 40 finished with value: inf and parameters: {'context_length': 64, 'batch_size': 16, 'max_epochs': 50, 'learning_rate': 2.0566912274383635e-05, 'aug_prob': 0.20504040208350746}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.68342 (best 3.68342), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.68342 (best 3.68342), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.24175 (best 3.24175), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.24175 (best 3.24175), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.89065 (best 2.89065), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.89065 (best 2.89065), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.67462 (best 2.67462), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.67462 (best 2.67462), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.47336 (best 2.47336), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.47336 (best 2.47336), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 2.39913 (best 2.39913), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 2.39913 (best 2.39913), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 2.36463 (best 2.36463), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 2.36463 (best 2.36463), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 2.08361 (best 2.08361), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 2.08361 (best 2.08361), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached 2.00127 (best 2.00127), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached 2.00127 (best 2.00127), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached 1.83793 (best 1.83793), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached 1.83793 (best 1.83793), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' reached 1.64476 (best 1.64476), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' reached 1.64476 (best 1.64476), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached 1.39614 (best 1.39614), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached 1.39614 (best 1.39614), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' reached 1.32467 (best 1.32467), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' reached 1.32467 (best 1.32467), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' reached 1.27949 (best 1.27949), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' reached 1.27949 (best 1.27949), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' reached 1.21585 (best 1.21585), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=51-step=2600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' reached 1.21585 (best 1.21585), saving model to '/content/lag-llama/lightning_logs/version_41/checkpoints/epoch=51-step=2600.ckpt' as top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 41: MAE=16.62, RMSE=20.27\n",
            "[I 2025-11-25 04:07:38,636] Trial 41 finished with value: 16.62433433532715 and parameters: {'context_length': 64, 'batch_size': 32, 'max_epochs': 60, 'learning_rate': 4.174023889656426e-05, 'aug_prob': 0.29366949486817573}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.69181 (best 3.69181), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.69181 (best 3.69181), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.19998 (best 3.19998), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.19998 (best 3.19998), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.87316 (best 2.87316), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.87316 (best 2.87316), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.71667 (best 2.71667), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.71667 (best 2.71667), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.61361 (best 2.61361), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.61361 (best 2.61361), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 2.35823 (best 2.35823), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 2.35823 (best 2.35823), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 2.06333 (best 2.06333), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 2.06333 (best 2.06333), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached 1.92214 (best 1.92214), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached 1.92214 (best 1.92214), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached 1.81868 (best 1.81868), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached 1.81868 (best 1.81868), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached 1.68895 (best 1.68895), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached 1.68895 (best 1.68895), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' reached 1.61156 (best 1.61156), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' reached 1.61156 (best 1.61156), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' reached 1.41469 (best 1.41469), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' reached 1.41469 (best 1.41469), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' reached 1.32865 (best 1.32865), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' reached 1.32865 (best 1.32865), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' reached 1.24881 (best 1.24881), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' reached 1.24881 (best 1.24881), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' reached 1.23682 (best 1.23682), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' reached 1.23682 (best 1.23682), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' reached 1.08804 (best 1.08804), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' reached 1.08804 (best 1.08804), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' reached 1.01379 (best 1.01379), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' reached 1.01379 (best 1.01379), saving model to '/content/lag-llama/lightning_logs/version_42/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 42 failed: \n",
            "[I 2025-11-25 04:10:09,441] Trial 42 finished with value: inf and parameters: {'context_length': 64, 'batch_size': 32, 'max_epochs': 60, 'learning_rate': 4.1683653135878695e-05, 'aug_prob': 0.29350101377430343}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.72474 (best 3.72474), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.72474 (best 3.72474), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.41127 (best 3.41127), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.41127 (best 3.41127), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 3.03168 (best 3.03168), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 3.03168 (best 3.03168), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.74339 (best 2.74339), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.74339 (best 2.74339), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.69799 (best 2.69799), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.69799 (best 2.69799), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 2.43359 (best 2.43359), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 2.43359 (best 2.43359), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 2.40504 (best 2.40504), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 2.40504 (best 2.40504), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 2.02656 (best 2.02656), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 2.02656 (best 2.02656), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached 2.00625 (best 2.00625), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 2.00625 (best 2.00625), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached 1.80785 (best 1.80785), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached 1.80785 (best 1.80785), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached 1.79978 (best 1.79978), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached 1.79978 (best 1.79978), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' reached 1.76776 (best 1.76776), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' reached 1.76776 (best 1.76776), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' reached 1.73088 (best 1.73088), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' reached 1.73088 (best 1.73088), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' reached 1.58224 (best 1.58224), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' reached 1.58224 (best 1.58224), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' reached 1.54513 (best 1.54513), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' reached 1.54513 (best 1.54513), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' reached 1.42316 (best 1.42316), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' reached 1.42316 (best 1.42316), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' reached 1.39505 (best 1.39505), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' reached 1.39505 (best 1.39505), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' reached 1.39088 (best 1.39088), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' reached 1.39088 (best 1.39088), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' reached 1.28911 (best 1.28911), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' reached 1.28911 (best 1.28911), saving model to '/content/lag-llama/lightning_logs/version_43/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=50` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=50` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 43: MAE=21.65, RMSE=31.99\n",
            "[I 2025-11-25 04:12:15,304] Trial 43 finished with value: 21.648757934570312 and parameters: {'context_length': 64, 'batch_size': 32, 'max_epochs': 50, 'learning_rate': 3.121517012041313e-05, 'aug_prob': 0.2630827389117155}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.61047 (best 3.61047), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.61047 (best 3.61047), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.12294 (best 3.12294), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.12294 (best 3.12294), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.74652 (best 2.74652), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.74652 (best 2.74652), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.65455 (best 2.65455), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.65455 (best 2.65455), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.43971 (best 2.43971), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.43971 (best 2.43971), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 2.39631 (best 2.39631), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 2.39631 (best 2.39631), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 2.24259 (best 2.24259), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 2.24259 (best 2.24259), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 2.12205 (best 2.12205), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 2.12205 (best 2.12205), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached 1.74987 (best 1.74987), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 1.74987 (best 1.74987), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' reached 1.55532 (best 1.55532), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' reached 1.55532 (best 1.55532), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached 1.54803 (best 1.54803), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached 1.54803 (best 1.54803), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' reached 1.54161 (best 1.54161), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' reached 1.54161 (best 1.54161), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' reached 1.43562 (best 1.43562), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' reached 1.43562 (best 1.43562), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' reached 1.40652 (best 1.40652), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' reached 1.40652 (best 1.40652), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' reached 1.31782 (best 1.31782), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' reached 1.31782 (best 1.31782), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' reached 1.22027 (best 1.22027), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' reached 1.22027 (best 1.22027), saving model to '/content/lag-llama/lightning_logs/version_44/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 44 failed: \n",
            "[I 2025-11-25 04:14:45,754] Trial 44 finished with value: inf and parameters: {'context_length': 64, 'batch_size': 32, 'max_epochs': 60, 'learning_rate': 5.396484713760524e-05, 'aug_prob': 0.276346446152465}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.76060 (best 3.76060), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.76060 (best 3.76060), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.28072 (best 3.28072), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.28072 (best 3.28072), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.88062 (best 2.88062), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.88062 (best 2.88062), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.74023 (best 2.74023), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.74023 (best 2.74023), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.50195 (best 2.50195), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.50195 (best 2.50195), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 2.15815 (best 2.15815), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 2.15815 (best 2.15815), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 1.91087 (best 1.91087), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 1.91087 (best 1.91087), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached 1.80464 (best 1.80464), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 1.80464 (best 1.80464), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached 1.61948 (best 1.61948), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached 1.61948 (best 1.61948), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached 1.45852 (best 1.45852), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached 1.45852 (best 1.45852), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' reached 1.44361 (best 1.44361), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' reached 1.44361 (best 1.44361), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' reached 1.15084 (best 1.15084), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' reached 1.15084 (best 1.15084), saving model to '/content/lag-llama/lightning_logs/version_45/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=40` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=40` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 45 failed: \n",
            "[I 2025-11-25 04:16:24,120] Trial 45 finished with value: inf and parameters: {'context_length': 64, 'batch_size': 32, 'max_epochs': 40, 'learning_rate': 3.818383511672767e-05, 'aug_prob': 0.24048728528408186}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.78881 (best 3.78881), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.78881 (best 3.78881), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.59791 (best 3.59791), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.59791 (best 3.59791), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 3.36779 (best 3.36779), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 3.36779 (best 3.36779), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 3.18260 (best 3.18260), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 3.18260 (best 3.18260), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.97709 (best 2.97709), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.97709 (best 2.97709), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 2.71226 (best 2.71226), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 2.71226 (best 2.71226), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 2.67895 (best 2.67895), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 2.67895 (best 2.67895), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 2.59686 (best 2.59686), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 2.59686 (best 2.59686), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached 2.25844 (best 2.25844), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 2.25844 (best 2.25844), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached 2.24149 (best 2.24149), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached 2.24149 (best 2.24149), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached 2.11298 (best 2.11298), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached 2.11298 (best 2.11298), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached 2.09984 (best 2.09984), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached 2.09984 (best 2.09984), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached 1.95814 (best 1.95814), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached 1.95814 (best 1.95814), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' reached 1.82380 (best 1.82380), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' reached 1.82380 (best 1.82380), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' reached 1.78703 (best 1.78703), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' reached 1.78703 (best 1.78703), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' reached 1.38878 (best 1.38878), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' reached 1.38878 (best 1.38878), saving model to '/content/lag-llama/lightning_logs/version_46/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=30` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=30` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 46: MAE=41.61, RMSE=44.94\n",
            "[I 2025-11-25 04:17:36,979] Trial 46 finished with value: 41.608821868896484 and parameters: {'context_length': 64, 'batch_size': 32, 'max_epochs': 30, 'learning_rate': 1.4230683711110762e-05, 'aug_prob': 0.2704579011576317}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.58729 (best 3.58729), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.58729 (best 3.58729), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.27070 (best 3.27070), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.27070 (best 3.27070), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.77508 (best 2.77508), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.77508 (best 2.77508), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.70320 (best 2.70320), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.70320 (best 2.70320), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.42490 (best 2.42490), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.42490 (best 2.42490), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 2.21657 (best 2.21657), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 2.21657 (best 2.21657), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 2.06299 (best 2.06299), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 2.06299 (best 2.06299), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached 2.02259 (best 2.02259), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 2.02259 (best 2.02259), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached 1.85237 (best 1.85237), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached 1.85237 (best 1.85237), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached 1.81288 (best 1.81288), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached 1.81288 (best 1.81288), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' reached 1.77816 (best 1.77816), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' reached 1.77816 (best 1.77816), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' reached 1.66402 (best 1.66402), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' reached 1.66402 (best 1.66402), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' reached 1.65281 (best 1.65281), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' reached 1.65281 (best 1.65281), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' reached 1.54352 (best 1.54352), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' reached 1.54352 (best 1.54352), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=31-step=1600.ckpt' as top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' reached 1.49627 (best 1.49627), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' reached 1.49627 (best 1.49627), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=32-step=1650.ckpt' as top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' reached 1.34635 (best 1.34635), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' reached 1.34635 (best 1.34635), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' reached 1.26930 (best 1.26930), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' reached 1.26930 (best 1.26930), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' reached 1.20127 (best 1.20127), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=51-step=2600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' reached 1.20127 (best 1.20127), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=51-step=2600.ckpt' as top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' reached 1.07145 (best 1.07145), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=53-step=2700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' reached 1.07145 (best 1.07145), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=53-step=2700.ckpt' as top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 61, global step 3100: 'train_loss' reached 1.06802 (best 1.06802), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=61-step=3100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 61, global step 3100: 'train_loss' reached 1.06802 (best 1.06802), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=61-step=3100.ckpt' as top 1\n",
            "INFO: Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 67, global step 3400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 69, global step 3500: 'train_loss' reached 0.82540 (best 0.82540), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=69-step=3500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 69, global step 3500: 'train_loss' reached 0.82540 (best 0.82540), saving model to '/content/lag-llama/lightning_logs/version_47/checkpoints/epoch=69-step=3500.ckpt' as top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=70` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 47: MAE=24.36, RMSE=29.99\n",
            "[I 2025-11-25 04:20:37,313] Trial 47 finished with value: 24.3590145111084 and parameters: {'context_length': 64, 'batch_size': 32, 'max_epochs': 70, 'learning_rate': 4.384159948267646e-05, 'aug_prob': 0.29749063667847636}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.56615 (best 3.56615), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.56615 (best 3.56615), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 2.99648 (best 2.99648), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 2.99648 (best 2.99648), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.69375 (best 2.69375), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.69375 (best 2.69375), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.37835 (best 2.37835), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.37835 (best 2.37835), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 2.20225 (best 2.20225), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 2.20225 (best 2.20225), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 2.07359 (best 2.07359), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 2.07359 (best 2.07359), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 1.89675 (best 1.89675), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 1.89675 (best 1.89675), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 1.85291 (best 1.85291), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 1.85291 (best 1.85291), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached 1.71253 (best 1.71253), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached 1.71253 (best 1.71253), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' reached 1.70081 (best 1.70081), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' reached 1.70081 (best 1.70081), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' reached 1.50070 (best 1.50070), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' reached 1.50070 (best 1.50070), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' reached 1.35328 (best 1.35328), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' reached 1.35328 (best 1.35328), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' reached 1.14732 (best 1.14732), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' reached 1.14732 (best 1.14732), saving model to '/content/lag-llama/lightning_logs/version_48/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=50` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=50` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 48: MAE=24.07, RMSE=28.75\n",
            "[I 2025-11-25 04:22:57,496] Trial 48 finished with value: 24.07074737548828 and parameters: {'context_length': 96, 'batch_size': 32, 'max_epochs': 50, 'learning_rate': 6.470543193387183e-05, 'aug_prob': 0.25468010781439926}. Best is trial 1 with value: 14.996456146240234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.74529 (best 3.74529), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.74529 (best 3.74529), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.35269 (best 3.35269), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.35269 (best 3.35269), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.86018 (best 2.86018), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.86018 (best 2.86018), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.63028 (best 2.63028), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.63028 (best 2.63028), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.41412 (best 2.41412), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.41412 (best 2.41412), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 2.40672 (best 2.40672), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 2.40672 (best 2.40672), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 2.10037 (best 2.10037), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 2.10037 (best 2.10037), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 2.07943 (best 2.07943), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 2.07943 (best 2.07943), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached 1.70690 (best 1.70690), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 1.70690 (best 1.70690), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached 1.66985 (best 1.66985), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached 1.66985 (best 1.66985), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached 1.37146 (best 1.37146), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached 1.37146 (best 1.37146), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached 1.22742 (best 1.22742), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached 1.22742 (best 1.22742), saving model to '/content/lag-llama/lightning_logs/version_49/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=20` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=20` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 49 failed: \n",
            "[I 2025-11-25 04:23:53,608] Trial 49 finished with value: inf and parameters: {'context_length': 64, 'batch_size': 32, 'max_epochs': 20, 'learning_rate': 2.892869211359967e-05, 'aug_prob': 0.14432563195491632}. Best is trial 1 with value: 14.996456146240234.\n",
            "\n",
            "======================================================================\n",
            "✅ OPTIMIZATION COMPLETE!\n",
            "======================================================================\n",
            "\n",
            "🏆 BEST HYPERPARAMETERS:\n",
            "--------------------------------------------------\n",
            "  • context_length: 32\n",
            "  • batch_size: 32\n",
            "  • max_epochs: 60\n",
            "  • learning_rate: 7.309539835912905e-05\n",
            "  • aug_prob: 0.08736874205941257\n",
            "\n",
            "📊 BEST VALIDATION MAE: 15.00\n",
            "📈 Total trials completed: 50\n",
            "✓ Completed: 50\n",
            "✗ Pruned: 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "🎯 TRAINING FINAL MODEL WITH BEST HYPERPARAMETERS\n",
            "======================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3cf9c66dcd38460899b6b5c398790069"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 3.71038 (best 3.71038), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 3.71038 (best 3.71038), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.20628 (best 3.20628), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.20628 (best 3.20628), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 2.77056 (best 2.77056), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 2.77056 (best 2.77056), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.48380 (best 2.48380), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.48380 (best 2.48380), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.09667 (best 2.09667), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.09667 (best 2.09667), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 1.77150 (best 1.77150), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 1.77150 (best 1.77150), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 1.67583 (best 1.67583), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 1.67583 (best 1.67583), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 1.58661 (best 1.58661), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 1.58661 (best 1.58661), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached 1.56245 (best 1.56245), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached 1.56245 (best 1.56245), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached 1.54436 (best 1.54436), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached 1.54436 (best 1.54436), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached 1.52082 (best 1.52082), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached 1.52082 (best 1.52082), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' reached 1.30421 (best 1.30421), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' reached 1.30421 (best 1.30421), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' reached 1.28154 (best 1.28154), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' reached 1.28154 (best 1.28154), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' reached 1.10584 (best 1.10584), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' reached 1.10584 (best 1.10584), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' reached 0.98230 (best 0.98230), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' reached 0.98230 (best 0.98230), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' reached 0.94810 (best 0.94810), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' reached 0.94810 (best 0.94810), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' reached 0.90076 (best 0.90076), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' reached 0.90076 (best 0.90076), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' reached 0.87225 (best 0.87225), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=55-step=2800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' reached 0.87225 (best 0.87225), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=55-step=2800.ckpt' as top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' reached 0.71836 (best 0.71836), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=59-step=3000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' reached 0.71836 (best 0.71836), saving model to '/content/lag-llama/lightning_logs/version_50/checkpoints/epoch=59-step=3000.ckpt' as top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "✅ FINAL MODEL EVALUATION (TEST SET)\n",
            "======================================================================\n",
            "\n",
            "📊 ACCURACY METRICS:\n",
            "  • MAE (Mean Absolute Error):        45.81\n",
            "  • RMSE (Root Mean Squared Error):   56.20\n",
            "  • MAPE (Mean Absolute % Error):     57.3%\n",
            "\n",
            "🏆 BEST HYPERPARAMETERS USED:\n",
            "  • context_length: 32\n",
            "  • batch_size: 32\n",
            "  • max_epochs: 60\n",
            "  • learning_rate: 7.309539835912905e-05\n",
            "  • aug_prob: 0.08736874205941257\n",
            "\n",
            "📋 WEEK-BY-WEEK COMPARISON:\n",
            "Week   Actual     Forecast   Error      % Error   \n",
            "--------------------------------------------------\n",
            "1      76.67      187.35     110.68     144.4     %\n",
            "2      86.00      166.37     80.37      93.5      %\n",
            "3      92.00      146.06     54.06      58.8      %\n",
            "4      81.33      148.46     67.13      82.5      %\n",
            "5      83.00      145.31     62.31      75.1      %\n",
            "6      75.00      140.44     65.44      87.3      %\n",
            "7      77.00      119.13     42.13      54.7      %\n",
            "8      68.33      106.46     38.13      55.8      %\n",
            "9      78.33      95.66      17.33      22.1      %\n",
            "10     84.67      92.57      7.91       9.3       %\n",
            "11     95.33      92.47      -2.86      -3.0      %\n",
            "12     89.33      90.64      1.31       1.5       %\n",
            "\n",
            "======================================================================\n",
            "\n",
            "💾 Best hyperparameters saved to 'best_hyperparameters.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# CRITICAL FIX: Patch torch.load ONCE at module level\n",
        "# ---------------------------------------------------------------------------\n",
        "import torch.serialization\n",
        "\n",
        "if not hasattr(torch.serialization, '_original_torch_load_backup'):\n",
        "    torch.serialization._original_torch_load_backup = torch.serialization.load\n",
        "\n",
        "def safe_torch_load(*args, **kwargs):\n",
        "    \"\"\"Wrapper that adds weights_only=False by default\"\"\"\n",
        "    if 'weights_only' not in kwargs:\n",
        "        kwargs['weights_only'] = False\n",
        "    return torch.serialization._original_torch_load_backup(*args, **kwargs)\n",
        "\n",
        "# Apply the patch\n",
        "torch.load = safe_torch_load\n",
        "torch.serialization.load = safe_torch_load\n",
        "\n",
        "print(\"✓ torch.load patched successfully\")\n",
        "\n",
        "# GluonTS imports\n",
        "from gluonts.dataset.pandas import PandasDataset\n",
        "from gluonts.evaluation import make_evaluation_predictions, Evaluator\n",
        "from lag_llama.gluon.estimator import LagLlamaEstimator\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 1. LOAD AND PREPROCESS DATA\n",
        "# ---------------------------------------------------------------------------\n",
        "filename = '/content/macro_index_Tax_Clinic_only.csv'\n",
        "\n",
        "if not os.path.exists(filename):\n",
        "    filename = 'macro_index_Tax_Clinic_only.csv'\n",
        "\n",
        "if not os.path.exists(filename):\n",
        "    print(f\"❌ Error: {filename} not found. Please upload your CSV file.\")\n",
        "    raise FileNotFoundError(\"Please upload macro_index_Tax_Clinic_only.csv\")\n",
        "\n",
        "df = pd.read_csv(filename)\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df.set_index('date', inplace=True)\n",
        "df = df.asfreq('W-SUN')\n",
        "df = df.ffill().bfill()\n",
        "\n",
        "# CRITICAL: Convert all numeric data to float32\n",
        "num_cols = df.select_dtypes(include=[np.number]).columns\n",
        "df[num_cols] = df[num_cols].astype('float32')\n",
        "\n",
        "print(f\"✓ Data Loaded. Shape: {df.shape}\")\n",
        "print(f\"✓ Date range: {df.index[0]} to {df.index[-1]}\")\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 2. FEATURE SELECTION\n",
        "# ---------------------------------------------------------------------------\n",
        "target_col = 'Tax Clinic'\n",
        "\n",
        "# OPTION: Use NO exogenous features (univariate forecasting)\n",
        "use_exogenous = True\n",
        "\n",
        "if use_exogenous:\n",
        "    selected_features = [\n",
        "        'FXUSDCAD', 'FXEURCAD', 'CPIAUCSL', 'DTWEXBGS', 'DGS10',\n",
        "        'woodgreen_seniors_care_text_information',\n",
        "        'woodgreen_employment_text_information',\n",
        "        'goc_avg_over10y', 'DFF', 'spread_10y_5y',\n",
        "        'goc_long_benchmark', 'goc_long_benchmark1'\n",
        "    ]\n",
        "    selected_features = [f for f in selected_features if f in df.columns]\n",
        "    print(f\"\\n✓ Using {len(selected_features)} exogenous features\")\n",
        "else:\n",
        "    selected_features = []\n",
        "    print(f\"\\n✓ Using UNIVARIATE forecasting (no exogenous features)\")\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 3. PROPER TRAIN/TEST SPLIT\n",
        "# ---------------------------------------------------------------------------\n",
        "prediction_length = 12\n",
        "context_length = 32\n",
        "\n",
        "# Split data properly - reserve last 12 weeks for testing\n",
        "split_point = len(df) - prediction_length\n",
        "\n",
        "train_df = df.iloc[:split_point]\n",
        "test_df = df.iloc[:split_point]  # TEST DATASET SHOULD NOT INCLUDE FUTURE DATA\n",
        "\n",
        "print(f\"\\n✓ Train dataset: {len(train_df)} weeks (up to {train_df.index[-1]})\")\n",
        "print(f\"✓ Holdout period: {prediction_length} weeks (from {df.index[split_point]})\")\n",
        "print(f\"✓ Last actual value in training: {train_df[target_col].iloc[-1]:.2f}\")\n",
        "\n",
        "# Create datasets\n",
        "if selected_features:\n",
        "    train_ds = PandasDataset(train_df, target=target_col, feat_dynamic_real=selected_features, freq=\"W-SUN\")\n",
        "    test_ds = PandasDataset(test_df, target=target_col, feat_dynamic_real=selected_features, freq=\"W-SUN\")\n",
        "else:\n",
        "    train_ds = PandasDataset(train_df, target=target_col, freq=\"W-SUN\")\n",
        "    test_ds = PandasDataset(test_df, target=target_col, freq=\"W-SUN\")\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 4. LOAD AND FINE-TUNE MODEL\n",
        "# ---------------------------------------------------------------------------\n",
        "print(\"\\nDownloading Lag-Llama checkpoint...\")\n",
        "!huggingface-cli download time-series-foundation-models/Lag-Llama lag-llama.ckpt --local-dir .\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"✓ Using device: {device}\")\n",
        "\n",
        "ckpt_path = \"lag-llama.ckpt\"\n",
        "ckpt = torch.load(ckpt_path, map_location=device)\n",
        "estimator_args = ckpt[\"hyper_parameters\"][\"model_kwargs\"]\n",
        "\n",
        "estimator = LagLlamaEstimator(\n",
        "    ckpt_path=ckpt_path,\n",
        "    prediction_length=prediction_length,\n",
        "    context_length=context_length,\n",
        "    n_layer=estimator_args[\"n_layer\"],\n",
        "    n_embd_per_head=estimator_args[\"n_embd_per_head\"],\n",
        "    n_head=estimator_args[\"n_head\"],\n",
        "    scaling=estimator_args[\"scaling\"],\n",
        "    time_feat=estimator_args[\"time_feat\"],\n",
        "    aug_prob=0.08736874205941257,  # Disable augmentations\n",
        "    lr=7.309539835912905e-05,\n",
        "    batch_size=16,  # Reduced for stability\n",
        "    num_parallel_samples=100,\n",
        "    trainer_kwargs={\n",
        "        \"accelerator\": device,\n",
        "        \"max_epochs\": 60,  # Reduced to prevent overfitting\n",
        "    },\n",
        ")\n",
        "\n",
        "print(\"\\n🚀 Starting Fine-Tuning...\")\n",
        "predictor = estimator.train(\n",
        "    training_data=train_ds,\n",
        "    cache_data=True,\n",
        "    shuffle_buffer_length=1000\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 5. PREDICT AND EVALUATE\n",
        "# ---------------------------------------------------------------------------\n",
        "print(\"\\n📊 Generating Forecasts...\")\n",
        "forecast_it, ts_it = make_evaluation_predictions(\n",
        "    dataset=test_ds,\n",
        "    predictor=predictor,\n",
        "    num_samples=100\n",
        ")\n",
        "\n",
        "forecasts = list(forecast_it)\n",
        "tss = list(ts_it)\n",
        "\n",
        "# Get actual values for the forecast period\n",
        "actual_values = df[target_col].iloc[split_point:split_point + prediction_length].values\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 6. CALCULATE METRICS\n",
        "# ---------------------------------------------------------------------------\n",
        "ts_entry = tss[0]\n",
        "forecast_entry = forecasts[0]\n",
        "forecast_mean = forecast_entry.mean\n",
        "\n",
        "# Calculate errors\n",
        "mae = np.mean(np.abs(forecast_mean - actual_values))\n",
        "rmse = np.sqrt(np.mean((forecast_mean - actual_values) ** 2))\n",
        "mape = np.mean(np.abs((actual_values - forecast_mean) / actual_values)) * 100\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 7. PLOT RESULTS\n",
        "# ---------------------------------------------------------------------------\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
        "\n",
        "# ========== PLOT 1: FORECAST WITH HISTORICAL CONTEXT ==========\n",
        "ts_index = ts_entry[-100:].index.to_timestamp()\n",
        "ts_values = ts_entry[-100:].values\n",
        "\n",
        "ax1.plot(ts_index, ts_values, label=\"Historical Data\", linewidth=2,\n",
        "         color='#2E86AB', marker='o', markersize=3, alpha=0.8)\n",
        "\n",
        "forecast_index = forecast_entry.index.to_timestamp()\n",
        "\n",
        "# Plot actual values in forecast period\n",
        "actual_index = df.index[split_point:split_point + prediction_length]\n",
        "ax1.plot(actual_index, actual_values, label=\"Actual (Holdout)\",\n",
        "         linewidth=2.5, color='#E63946', marker='o', markersize=5)\n",
        "\n",
        "# Plot forecast\n",
        "ax1.plot(forecast_index, forecast_mean, label=\"Forecast Mean\",\n",
        "         linewidth=2.5, color='#06A77D', marker='s', markersize=4, linestyle='--')\n",
        "\n",
        "# Prediction intervals\n",
        "q05 = forecast_entry.quantile('0.05')\n",
        "q95 = forecast_entry.quantile('0.95')\n",
        "ax1.fill_between(forecast_index, q05, q95, alpha=0.2, color='#06A77D',\n",
        "                 label='90% Prediction Interval')\n",
        "\n",
        "ax1.axvline(x=forecast_index[0], color='red', linestyle='--',\n",
        "           linewidth=1.5, alpha=0.7, label='Forecast Start')\n",
        "\n",
        "ax1.set_title(f\"Weekly Intake Forecast vs Actual\\n\"\n",
        "             f\"MAE: {mae:.2f} | RMSE: {rmse:.2f} | MAPE: {mape:.1f}%\",\n",
        "             fontsize=14, fontweight='bold', pad=15)\n",
        "ax1.set_xlabel(\"Date\", fontsize=12, fontweight='bold')\n",
        "ax1.set_ylabel(\"Number of People\", fontsize=12, fontweight='bold')\n",
        "ax1.legend(fontsize=9, loc='best', framealpha=0.9)\n",
        "ax1.grid(True, alpha=0.3, linestyle='--')\n",
        "ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%b'))\n",
        "plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
        "\n",
        "# ========== PLOT 2: FORECAST ERROR ANALYSIS ==========\n",
        "errors = forecast_mean - actual_values\n",
        "weeks = np.arange(1, prediction_length + 1)\n",
        "\n",
        "ax2.bar(weeks, errors, color=['#06A77D' if e >= 0 else '#E63946' for e in errors],\n",
        "       alpha=0.7, edgecolor='black', linewidth=1.5)\n",
        "ax2.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
        "ax2.set_title(\"Forecast Error by Week\", fontsize=14, fontweight='bold', pad=15)\n",
        "ax2.set_xlabel(\"Week Ahead\", fontsize=12, fontweight='bold')\n",
        "ax2.set_ylabel(\"Error (Forecast - Actual)\", fontsize=12, fontweight='bold')\n",
        "ax2.grid(True, alpha=0.3, axis='y', linestyle='--')\n",
        "ax2.set_xticks(weeks)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 8. PRINT DETAILED SUMMARY\n",
        "# ---------------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✅ FORECAST EVALUATION COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\n📊 ACCURACY METRICS:\")\n",
        "print(f\"  • MAE (Mean Absolute Error):        {mae:.2f}\")\n",
        "print(f\"  • RMSE (Root Mean Squared Error):   {rmse:.2f}\")\n",
        "print(f\"  • MAPE (Mean Absolute % Error):     {mape:.1f}%\")\n",
        "\n",
        "print(f\"\\n📈 FORECAST SUMMARY (Next {prediction_length} weeks):\")\n",
        "print(f\"  • Mean Forecast:     {forecast_mean.mean():.2f}\")\n",
        "print(f\"  • Median Forecast:   {np.median(forecast_mean):.2f}\")\n",
        "print(f\"  • Min Forecast:      {forecast_mean.min():.2f}\")\n",
        "print(f\"  • Max Forecast:      {forecast_mean.max():.2f}\")\n",
        "print(f\"  • Std Deviation:     {forecast_mean.std():.2f}\")\n",
        "\n",
        "print(f\"\\n📉 ACTUAL VALUES (Holdout Period):\")\n",
        "print(f\"  • Mean Actual:       {actual_values.mean():.2f}\")\n",
        "print(f\"  • Min Actual:        {actual_values.min():.2f}\")\n",
        "print(f\"  • Max Actual:        {actual_values.max():.2f}\")\n",
        "\n",
        "print(f\"\\n📋 WEEK-BY-WEEK COMPARISON:\")\n",
        "print(f\"{'Week':<6} {'Actual':<10} {'Forecast':<10} {'Error':<10} {'% Error':<10}\")\n",
        "print(\"-\" * 50)\n",
        "for i, (actual, pred) in enumerate(zip(actual_values, forecast_mean), 1):\n",
        "    error = pred - actual\n",
        "    pct_error = (error / actual) * 100\n",
        "    print(f\"{i:<6} {actual:<10.2f} {pred:<10.2f} {error:<10.2f} {pct_error:<10.1f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)"
      ],
      "metadata": {
        "id": "l8R9IPHnl_zo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d6b835c8de694146b1817cf61cc400cf",
            "b0e11eb858af44609bb07b183b93d2a3",
            "22dc010b5ef7496e99c803dd7e0efc1f",
            "96b767983c9c47988567239857e360f5",
            "86403585daea4c879d48e804c7e4014f",
            "c06c7f03c8594a4eafd76f5a14211066",
            "fef5de66a31a4af48f23bfbe36812adc",
            "9307d42d0e8d4b4a94c753f57e1c8411",
            "02b7c751662b4c46b4f317a40bc2579a",
            "8868881bdd464449966e9051ebcc5337",
            "438122338e744e15afe12615fc3a518d"
          ]
        },
        "outputId": "ea296527-b041-4729-a88e-49182a9b21f2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ torch.load patched successfully\n",
            "✓ Data Loaded. Shape: (242, 45)\n",
            "✓ Date range: 2021-03-07 00:00:00 to 2025-10-19 00:00:00\n",
            "\n",
            "✓ Using 12 exogenous features\n",
            "\n",
            "✓ Train dataset: 230 weeks (up to 2025-07-27 00:00:00)\n",
            "✓ Holdout period: 12 weeks (from 2025-08-03 00:00:00)\n",
            "✓ Last actual value in training: 62.00\n",
            "\n",
            "Downloading Lag-Llama checkpoint...\n",
            "\u001b[33m⚠️  Warning: 'huggingface-cli download' is deprecated. Use 'hf download' instead.\u001b[0m\n",
            "lag-llama.ckpt\n",
            "✓ Using device: cuda\n",
            "\n",
            "🚀 Starting Fine-Tuning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d6b835c8de694146b1817cf61cc400cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n",
            "INFO: Epoch 0, global step 50: 'train_loss' reached 4.61009 (best 4.61009), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 4.61009 (best 4.61009), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 3.78786 (best 3.78786), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 3.78786 (best 3.78786), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 3.16032 (best 3.16032), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 3.16032 (best 3.16032), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 2.90585 (best 2.90585), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 2.90585 (best 2.90585), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 2.41401 (best 2.41401), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 2.41401 (best 2.41401), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' reached 2.08129 (best 2.08129), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' reached 2.08129 (best 2.08129), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 2.05356 (best 2.05356), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 2.05356 (best 2.05356), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached 1.86194 (best 1.86194), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached 1.86194 (best 1.86194), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached 1.75889 (best 1.75889), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached 1.75889 (best 1.75889), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached 1.62072 (best 1.62072), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached 1.62072 (best 1.62072), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' reached 1.51786 (best 1.51786), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' reached 1.51786 (best 1.51786), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' reached 1.33960 (best 1.33960), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' reached 1.33960 (best 1.33960), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' reached 1.31362 (best 1.31362), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' reached 1.31362 (best 1.31362), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=30-step=1550.ckpt' as top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' reached 1.16154 (best 1.16154), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' reached 1.16154 (best 1.16154), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' reached 1.01346 (best 1.01346), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' reached 1.01346 (best 1.01346), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' reached 0.96914 (best 0.96914), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' reached 0.96914 (best 0.96914), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=46-step=2350.ckpt' as top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 50, global step 2550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 59, global step 3000: 'train_loss' reached 0.96688 (best 0.96688), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=59-step=3000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 59, global step 3000: 'train_loss' reached 0.96688 (best 0.96688), saving model to '/content/lag-llama/lightning_logs/version_51/checkpoints/epoch=59-step=3000.ckpt' as top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=60` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=60` reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Generating Forecasts...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gluonts/torch/util.py:205: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
            "  return a[idx]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x1000 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABW0AAAPeCAYAAAB3GThSAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzs3Xd4U2X7B/Dvyehumu7SlraUKXuIWvYSBAQFZCggIK8LeQVB5AfKUhRB5ZVXxclQREBeAQVUENkCiiIbWVJ2oTtdmef8/qg9JG3TJl1p0+/nunqRnPk8J3dOy50n9yNIkiSBiIiIiIiIiIiIiKoFhasbQERERERERERERER3MGlLREREREREREREVI0waUtERERERERERERUjTBpS0RERERERERERFSNMGlLREREREREREREVI0waUtERERERERERERUjTBpS0RERERERERERFSNMGlLREREREREREREVI0waUtERERERERERERUjTBpS0REROSkuLg4CIIAQRAwd+5ch/Yp2F4QBKxcubJS21dTrFy50ua6EJHr8P1IRERUvTBpS0RERFVq8+bNNomB3377zWb9xYsXbdY//vjjRY4xYMAAef29995bVU2vEbp16yZfm7i4uAo55ty5cyv8mNWF9fUq6ScxMdHVTa0xdu/e7RbXzmAwIDg42KYvd999d4Udn0lSIiIiKgmTtkRERFSlOnXqBIXizp8ge/futVm/b9++Ep+Looj9+/fLz7t06VIJrSSi2u67775DWlqazbI//vgDJ0+edFGLiIiIqDZRuboBREREVLsEBgaiefPmOH78OID8pO2LL74ory+cxE1MTMS1a9cQHR0NADh+/DgyMjLk9Z07d678RlOtEBgYiJkzZxa7LigoqNLOm5OTA29vb5sPM8j17JUxWblyJd5+++2qbQwRERHVOvzLkIiIiKqc9ejYX375BZIkyc8LRtbWqVNHXmadyLV+LAgCOnXqJD8XRRGrVq1C7969ERYWBg8PD4SGhqJ///74/vvv7bbn2LFjeOKJJ1C/fn14e3vDz88Pbdq0wRtvvIGcnByH+/XXX38hIiLC5qvUhUfqWZszZ468bd26dSGKos36U6dO2Xx9+tdff3W4LcWxLgUwduxYnD9/Ho8++ihCQkLg5eWFtm3b4ttvv5W3L/ia+7x58+Rlly9fLrY+76VLlzB58mR07twZdevWha+vLzw9PREVFYUBAwZg8+bNTrV18uTJ8jmUSiWWL18ur7t16xZmzpyJ1q1bw9/fH15eXmjQoAGee+45XLlypczXR6PR4MUXXyz2R6PR2Gz7888/45FHHkF0dDQ8PT2h0WjQtm1bzJkzp9jXvHAd5P3796NXr14ICAiAn58fdDqdvG1Z4jEnJwfvvvsuunbtiuDgYHh4eCAiIgJdu3bFBx98IG9nNpsxa9Ys9OvXD/Xr14dWq4VarUZwcDA6d+6M9957DyaTqcjx9+3bh0GDBiEqKgoeHh7w8/NDXFwc+vbti7lz5yIzMxNA/nuye/fuNvvWq1fPJu5KMnr0aHnbbt26FVn/ww8/2MTF1atXAQApKSl48cUX0axZM/j6+sr9v+eeezBx4kQcOnSoxPMWdvPmTWzbtk1+3qhRI/nxl19+CbPZbHffw4cPY9y4cWjQoAF8fHzg5+eHRo0aYdy4cbh48SISExMhCALGjRtns5/1+6qgVnZJpUkKjlPws3v3bnldRb8fiYiIyAUkIiIioir29ddfSwDkn+PHj0uSJEk3b96Ul7322muSt7e3BEB65pln5H2HDBkib9O8eXN5eW5urtSrVy+b4xb+mTJlSpG2LF26VFKpVHb3adq0qXTz5k2bfWJjY+X1c+bMkSRJks6fPy9FRkbKyxMSEqSMjAx5H+tjrlixQpIkSbpx44akVqvl5Vu3brU5z+zZs23a4YiuXbvK+8TGxtpd17JlS8nf379IfwVBkHbs2CFJkiTt2rWrxOtp3ZfNmzeXuu28efNs2rNixQqb9QWmTZsmL1MqldLq1avldQcOHJBCQkLsniMgIEDau3evQ9eqtOtlz5QpU0rsZ1RUlHTy5EmbfaxjJiEhQVIqlTb7pKenS5JUtni8ePGi1LBhQ7v7tGrVSt42Kyur1NepV69ektlslvfZsWNHkfYW/jlz5owkSVKpxx4zZkyJ1/bnn3+Wt1UoFNK1a9ds1o8ePVpe37t3b0mSJCkvL09q3LhxieedPn26Q69tgYULF8r7enl5Sfv377c53nfffVfsfvPmzZMEQbDbjo0bN0qXLl0q9ToV3FfmzJljNz4LH2fXrl3yuop8PxIREZFrsDwCERERVbnCdWj37t2LFi1a2Iyi7dWrF37++Wfs3r3bZrl1jVvr47zwwgvYsWMHAMDDwwMjRoxAw4YNceLECaxfvx6SJGHx4sVo164dHnvsMQDAgQMHMHHiRHmE63333YcHHngAWVlZ+Pzzz5GSkoLTp0/j8ccfx/bt2+32JzExET169MCNGzfkdm3duhV+fn4lXoc6depgyJAhWLt2LQDgs88+Q79+/eT169evlx8XHpVXXsePH0dgYCBeeOEF5OXl4dNPP4XFYoEkSXjrrbfQs2dP1K9fH2+99Ra2b9+On376CUDREgLt27cHAKhUKrRu3Rp33303QkNDodFokJOTg19++QW7du0CALz22msYP348oqKi7LZr1qxZeOuttwAAarUaa9aswZAhQwAAOp0ODz/8MFJSUgAAsbGxGD58OLy9vfG///0Pp06dQmZmJoYMGYLz588jICDAqWui0+mK/dp73bp1MXz4cADAqlWrsHjxYnlds2bNMGjQINy4cQOff/45LBYLrl+/jsGDB+PUqVNQqYr+uX3w4EH4+Phg1KhRiIqKwp9//gmlUlmmeLRYLHj44Ydx/vx5+fjt27dHz549YbFY8Ouvv9qM4hUEAfHx8bjvvvsQFRWFwMBAmEwm/PXXX1i/fj3MZjN27NiBb775BsOGDQMAfPLJJ7BYLACAJk2aYOjQoVCpVLhy5QqOHj2KI0eOyMd/6623cPHiRXz00UfyspkzZyIwMBAA0Lx58xJfg+7duyMuLg6JiYkQRRFr167F1KlTAQB5eXnYtGmTvG3Be2LXrl04e/YsAMDLy0uOsaSkJFy4cAF79uwp8ZzF+fzzz+XH/fr1Q8eOHXHXXXfhzJkzAPJLJAwYMMBmn/Xr12POnDnycx8fH4wYMQKxsbG4dOmSPLo1KCgIb731Fn7//XesW7dO3r4g7gGgQ4cOTrfZWkW9H4mIiMiFXJ01JiIiotqpUaNG8oiuYcOGSZIkSRMnTpQASD4+PpLRaJRHmQmCIKWkpEhnzpyxGQm2Zs0aSZIkKTU11WZ04vLly23ONWHCBHldmzZt5OWDBg2Sl3fr1k2yWCzyut9++83mXMeOHZPXWY+afOKJJ6S4uDj5+f333y/l5OQU6a/1sQpGp0qSJP3yyy/ycrVaLSUlJUmSJEknTpyQl6tUKnl5aRwdaSsIgnTkyBF53eTJk+V1QUFBNvuVNNqvsLNnz0pr166V3nvvPentt9+W3nrrLcnHx0fe/4svvpC3LTyy77XXXpMfe3p6Sps3b7Y59pIlS+T1gYGBUmpqqrwuOztbCg0NldcvWbLE6etl76dr167y9q1atZKXx8XFSbm5ufK6pUuXFhlVWcA6ZpRKpfTHH38UaUtZ4vG7776zWf7UU09JoijaHPfixYtFznXr1i3p22+/lZYuXSq/Ts2bN7eJ6wIDBw4s8p6zdvPmTZuYLzxC+9KlS/ZfgGLMnTtX3rddu3bycusR+oGBgZJer5ckSZI2bNggL+/Tp0+R4+n1+iIjdkvy66+/2rR//fr1kiRJ0quvviov8/DwkFJSUmz2a9u2rbze19dXOnv2rM367Oxs6datW/JzR0a2lnWkbYHyvB+JiIjItTjSloiIiFyiS5cuOHfuHIA7o2cL/r3vvvugVqvlkbSSJGH//v24deuWzTEKJiH79ddfbWpMPvHEE3jiiSeKPe/Ro0eRm5sLHx8f/PLLL/Ly3bt3Q6lU2m3vgQMH0LJlyyLLrWut9u/fH9988w08PT3td7yQDh06oG3btjhy5AhMJhNWrlyJ6dOn24yy7devH8LDwx0+piMSEhLQpk0b+Xnjxo3lx+np6U4fLzExESNHjsSBAwdK3O7atWt2182aNQsA4O3tjU2bNqF37942661fr/T0dAQHB9s91oEDB/D888870nSH5ebmyhPoAcDQoUPh7e0tP3/88ccxYcIE+fnBgwfx8MMPFzlO37590bZt2yLLyxKP+/fvt1n+2muvQRAEm2Xx8fHy47y8PEyYMAFffPFFkRrK1qxfp86dO+O7774DAIwdOxYff/wxGjVqhMaNG6Njx4645557ipyzPMaOHYt58+ZBkiT88ccfOH/+PBo2bIg1a9bI2zz66KPy+6x9+/bw9PSEwWDAtm3b0KxZM7Rs2RKNGjVCmzZt0LNnT6dGk1pPQObv74/+/fsDAEaMGIHZs2cDAIxGI1avXi3HWG5uLv788095v8cff9ymDi4A+Pr6wtfX17mLUUYV8X4kIiIi1+JEZEREROQS1qUNbt68id9//x0nTpwAcCcZm5CQALVaDSC/hIL115zj4+PlRExJk30VJkkSUlNTnd4vOTm51G2ioqKcStgWsE4uLlu2DIBtaQR7CejyKDypkXW7JauJ4Rz18MMPl5ogAgCDwVDqNt7e3sUm2Sr69SosNjYWkiQV+SmY4Ck9Pd3m2hROpPv6+tqUxLCX/G7SpEmxy8vSP+t9fHx8EBYWVuJ+M2bMwMqVK0tM2AK2r9PkyZMxevRoKJVKGAwG7N69G5988gmmTp2K++67Dy1btsTNmzcdbntpYmNj0aNHD/n5V199hczMTJvJBK3fE9HR0Vi5ciVCQkIAAKdPn8batWvx6quvYtCgQYiMjJRLkJTGYDDYJIcHDhwoJ+YbNmyIdu3ayeusk7uFY6NevXoO9tZxhd+XJb2XKvL9SERERK7BkbZERETkEoXr2i5YsEBOJBUkbb29vdG+fXscOHAA+/btQ1JSkrx9wTZAfo1Iay+88AIiIyPtnrug1mlQUBBu374NAOjUqRMeeughu/vYqzHZpEkT/PXXXwDya38GBARg0aJFdo9TnBEjRmDatGlITk7G+fPn8f7778u1M8PCwuSRfhWpIBleoDwjJc+ePYtjx47Jzx977DEsWrQIkZGREAQBYWFhDiVRC65lWloa7r//fuzbtw/169eX11u/znXq1MGUKVPsHqtu3bpl7I19gYGBEARBTp4VHvmdk5OD7Oxsm+2LY2+0ZVni0fqa5Obm4vbt2yUmbq1rqLZo0QJr1qxB48aNoVKpMGzYMJsPCwqoVCp88cUXeOedd3DgwAGcPXsWZ8+excaNG5Geno6TJ0/i//7v/2zqwJbXuHHj8PPPPwMA1qxZg5iYGDnB2LJlS5vkKZD/HhoyZAh+++03nDhxAufPn8euXbvw559/Ijs7G+PHj8eDDz5Yap3pTZs2ISMjQ36+evVqrF69utht//zzT5w4cQItWrQoEhuXLl0qa9dtKBR3xtjk5eXZrLOuY2ytot6PRERE5FpM2hIREZFLxMbGIiYmBleuXAEAbNy4EUB+MvG+++6Tt+vSpQsOHDiA33//3WakmXXS995774VSqZQnS1Kr1XjxxReLnDMxMRFnz56FRqMBkJ/4KpjYKCkpCU899ZS8rkBeXh7Wr19vN2k7fPhwWCwWzJ8/H0D+ZEL+/v7yV/0d4enpiSeffBJvvPEGAGDatGnyutGjRxc7mVVVsk7w5ubmFllfMHK5wCOPPCKPlN29e7fDCaJt27ahQ4cOuH79Om7evImePXti//79iI6OBpD/en399dcA8kea9u7du0jJCkmS8PPPP9skeyuKj48PWrVqhaNHjwLIHw09b948eSTmF198YbO9s5NJlSUeO3XqZPMhwZw5c7B06VKbJPzly5cRGxsLwPa16t69O5o1awYg/3oWjCgu7OzZs6hbty5CQ0NtEsnNmzeXE+fWk5EV/kCguJgpzeDBgxEQEIDMzEycPXsWr732mryu8KR8aWlpyMrKQmxsLDp27IiOHTsCyB/9WpDUzs3NxdmzZ4skewuzHj3riBUrVmDx4sXw8fFBmzZt5OuwatUqTJkyBQ0aNJC3zcvLQ1ZWlpxUL+46+fj42CzTarXy4+TkZFy8eBH169eHwWAodtI8oOLej0RERORaTNoSERGRy3Tp0gVffvklgDtf/W3btq3NSMSuXbvizTffLPLV4MIjbZ944gl8+umnAIBFixbh999/R4cOHeDl5YXr16/j0KFD+PPPPzFmzBj06dMHADB16lR8++23kCQJFy5cQPPmzTF48GCEh4cjMzMTJ06cwJ49e5CTk4PHH3/cbj9ee+01JCUl4bPPPgMAzJ49GxqNBpMmTXL4Wjz77LNYtGgRzGYz9Hq9vLxwgsoVrEsVJCcnY9y4cWjatCkEQcBzzz2HBg0aQKFQyCOlJ02ahKNHjyI1NRUrVqxw+DwxMTH48ccf0blzZ2RkZODy5cvo1asX9u7di7CwMIwdOxbz589HSkoKzGYzOnbsiKFDh6JBgwYwGAw4e/Ysdu/ejVu3bmHXrl2V8hX1qVOnYvTo0QDyPwRo3749Bg0ahBs3btiMNG3UqJHTI6TLEo/9+vVDixYt5NIiH330Ef7880/06NEDkiThyJEjuH37tlxvtXHjxjh58iQA4NNPP4VCoYCPjw9WrVplN5n3n//8B6tWrULPnj1Rr149hIeHIy0tzSZJbZ1cLFza4rnnnkOfPn2gUqkwcODAIrVei+Pt7Y0RI0bg448/BnBn5KparcbIkSNttj137hwSEhLQvn17tGrVCpGRkVCpVPjxxx9ttrNuY3GuX7+O7du3y8+bN28uJ7WtHTp0CJcvXwaQPxJ30aJFUKlU+L//+z8MGzYMAJCdnY3WrVtjxIgRiI2NxdWrV7FlyxYsXbpUrnNc+Do99thj6NChAxQKBUaPHo3w8HC0b9/eZpuOHTuia9euOHLkCC5cuFBsPyrq/UhEREQuVqXTnhERERFZ+eSTT2xmKwcgvfjiizbb6HQ6SalU2mwTERFR5Fg5OTlSr169ihyv8M+YMWNs9vvggw8klUpV6n7WYmNj5eVz5syRJEmSzGaz9NBDD8nLBUGQli9fLu9jfawVK1YUez0eeeQRm+3at2/v9DXt2rWr3dnmrdcVvg4lzRx/8+ZNmxnnrX+Sk5MlSZKkZ555ptj1PXv2lKKioopcr5LOuXfvXsnLy0te3qpVKyk9PV2SJEn65ZdfpJCQkFJfr127dpX7etkzZcqUEs8dGRkpnTx50maf4mKmOGWJx4sXL0oNGjSwu22rVq3kbdesWVPsNnXq1JHuv/9++XnXrl3lfZ5++ukS26JQKKSNGzfatKlNmzbFbrt+/XqHrrEkSdKvv/5aZP/BgwcX2e7gwYOlXq/i9itswYIFNvvs37+/2O2WLVtms92mTZvkdXPnzpUEQbDbDuvrpNfrpTp16hS73eHDh+XtOnfuXOw2/fr1sxvzFfl+JCIiItfgRGRERETkMoXr2gK2I2iB/Nnb27RpU+I2QP5X17dt24avvvoK/fr1Q3h4OFQqFby9vVG/fn088sgj+OSTT7B48WKb/SZMmIA///wTTz31FBo1agQfHx+oVCqEh4eja9eumDVrlk19SHuUSiXWrl2LTp06AQAkScKTTz5ZbI1Qe6wnJAMqZwKysoiIiMDmzZvRsWNHu/VY33vvPbz66quIjY2FWq1GTEwMpk2bhs2bNztd3qFz585Yu3YtlEolAODYsWPo168fcnJy0KFDB5w6dQqzZs1Cu3btoNFooFQqodVq0a5dO0ycOBE//fRTsbFVUd555x389NNPGDJkCCIjI6FWq+Hn54fWrVtj1qxZOH78eLEjNB1RlniMj4/H0aNHsXjxYnTq1AmBgYFQqVQICQlBx44d8a9//UvedsSIEfj666/RqlUrqNVqBAcHY/jw4Th06JDdOtDjx4/H9OnT0aVLF9StWxdeXl7w8PBA3bp1MXToUOzZs0cePVpgw4YNGDRoEIKCgspcL/mee+4pch2LG3neuHFjvPPOOxg8eDAaNWqEgIAAKJVKBAYGomPHjliyZIlDE5FZj5Ru3LixXGahsGHDhtm8D6xLKsyZMweHDh3CmDFjEB8fDy8vL/j4+CA+Ph6jR49G8+bN5W09PT3x/fffo3fv3kXKYFj77rvv8K9//QuhoaHw9PREy5Yt8dlnn+H999+3u09Fvh+JiIjINQRJKsP0wERERERU4W7evImoqChIkgRvb2/cuHGj1K90ExERERGR++HHrEREREQutnv3buTk5GDJkiVy7d6RI0cyYUtEREREVEtxpC0RERGRixX++nhgYCCOHz+O6OhoF7WIiIiIiIhciTVtiYiIiKqJwMBA9OvXD3v27GHCloiIiIioFmN5BCIiIiIX4xefiIiIiIjIGkfaEhEREREREREREVUjTNoSERERERERERERVSNM2hIRERHVcGPHjoUgCJg7d66rm0K1yMqVKyEIArp16+bqphARERG5HSZtiYiIaqDdu3dDEASbn4EDBxa77bZt24psO3bsWLvHfvvtt4tsv2XLFrvbd+vWrcj2xf0kJiaWs9d3bN26FYMHD0ZMTAy8vLzg4eGB8PBw9OjRAx988AGMRmORfRxp47Vr15xqR0Uc8/Dhw1CpVDb77N6926l2lMXcuXOLba+HhwfCwsLQtWtXLFmyBHq93qF9Fy9eXOx5ZsyYUWTblStXFtlu27ZtGDRoEKKiouDh4QF/f3/ExsaiQ4cOePbZZ7Fu3Tqb7RMTEx26/hWZUDSZTPjggw/QsWNHaLVaeHp6IiYmBmPHjsXp06ft7qfX67Fo0SK0a9cOGo0Gvr6+aN68OV555RVkZmY61Ya0tDSsWLECY8aMQevWrREREQG1Wo2goCB06tQJ7733XrHx78j1Uqkqf7qLmnDvUqlUCAsLQ+/evfHFF18UqTld8CFJaT8V9T4+c+YMXnnlFTzwwAMICQkp9b1k7dy5cxg/fjzi4uLg6emJkJAQ3H///fj666+LbFuQhHfkp7TzFubsPfvmzZt44oknEBsbC19fX7Rs2RJLly6FxWIpcuy1a9dCEATcd999EEXRqXYRERFVaxIRERHVOLt27ZIA2PwoFArp4sWLRbbt27dvkW3HjBlj99jNmjUrsv2QIUPsbt+1a9ci2xf3c+nSpQrouSS9/PLLpZ6rS5cukslkstnPkTZevXrVqbaU95h6vV5q2rRpkX127drlVDvGjBkjAZDmzJnj8D5z5sxxqP1dunSRzGZzqfvGx8dLFovFZrvc3FwpODi4yLYrVqyw2W7WrFmltqNVq1Y2+1y6dMmh9nft2tWJK2mfTqeTOnToYPc8Hh4e0jfffFNkv5SUFKlNmzZ294uLi5P+/vtvh9uxZs2aUvt8zz33SFlZWTb7OXK9lEqlU9dkxYoVTl/jmnjv6t+/v2Q0GuX9Ct5vpf04+z625z//+Y/dcxR+L1nbunWr5OXlZXffMWPGSKIoytsXvJ6O/KxcudLh9jt7z87KypJiY2MlAJJarZYiIyPl7V588UWbY6enp0vh4eGSSqWSjh075tyFJSIiquYq/+N0IiIiqhKiKOL999+3GfF47tw5/Pjjjw4f4/Dhwzh16lSR5Zs3b0ZaWhqCgoJK3D8wMBAzZ84sdl1p+zri1q1bWLBggfy8Tp06GDNmDDw9PfHVV1/h/PnzAIC9e/di+/bt6Nevn1Nt1Gq1ZWpXWY85e/bsEkdoVqWZM2dCq9UiKSkJX375JW7fvg0g/1pu3brV7mjIAn///Te2bNlis93q1auRmppa4n6nT5/G/Pnz5eeNGzfGQw89hMDAQKSlpeHYsWPYv39/qe2///770bt37yLL69atW+q+jpg+fToOHDgAIH+E9aOPPopGjRph69atOHz4MIxGIx5//HG0bdsWcXFx8n5PPfUU/vzzTwCAt7c3nn76aXh5eeHTTz9FamoqEhMTMWLECBw8eBAKheNfggsMDETfvn1x11134datW1i1apU8ave3337Dm2++aXNdrcXHx+PZZ58tstyZ81ek6nbvKriet27dApA/SnTp0qWYNGlSsfu+9dZbxS6vX7++w+0vTWBgINq2bYv69evjk08+KXX769ev49FHH5VHyjdt2hQjRozA6dOnsXbtWgDA559/jvbt2+O5554DALRv395uX9atW4fff/8dAKBWq9GrVy+H2l2We/bGjRtx+fJlKBQK/P7772jZsiVefPFFvPPOO/jggw/w+uuvw8PDAwDw0ksv4datW5g+fTpatmzpUJuIiIhqDFdnjYmIiMh5hUerKRQKCYAUEBAgZWdny9tNnDjRZhQdrEZYFWfChAnyNjExMTajtN57771i97EerRYbG+tQ+wuP+itptJi1gwcP2uz3v//9T173+++/lzgSzNk2OqI8xzx06JD8mjz88MPlGqFXESNtrUdC//DDDzbrFixYUOK+BfHXs2dPm+1atGhRJPYKv95LliyRl/v6+trEb4Hc3Fxp586dNssKx5CjfS/cdkeYTCbJz89P3mfUqFHyupycHJvRxM8//7y87tSpUzbn+uSTT+R127dvt1n3/fffO9SWn376SXrvvfek3Nxcm+VnzpyRPD095eO1bdvWZr319aqo0ccVMdK2ut67zp07JwmCIK/v3LmzvK7wSFtHlSVeJUmyea0dvXdOmzZN3sbf319KTU2V1z322GPyusjIyCIj6QvLzs6WAgMDS30NilOWe/b8+fMlAFJ4eLi8rfU96fr165IkSdK+ffskQRCk+Pj4Iu8HIiIid8CatkRERG6gYHRjZmYmPv/8cwCATqeTH7dp0wbR0dElHsNgMGDNmjXy81GjRqFv377y8xUrVlR0s53WoEEDeYQVAGzZsgWpqanIzs7Gxo0b5eVeXl7o2rVrscdISkpC3bp1oVarERgYiM6dO+PDDz+E2Wwuc7ucPaZer8fYsWNhsVjQtWtXPP/882U+d2WIioqyeR4SElLi9gXx9/PPP8sjh3ft2oUTJ07YrC+O9TUyGo04c+ZMkW28vb3RvXt3xxpfCZKTk5GdnS0/b9WqlfzYx8fHZkTl1q1b5cffffedzXGGDBkiP+7Vqxc0Go3dbe3p1asXJk6cCG9vb5vlTZo0QfPmzeXnxdW1LXDkyBG5Fm5oaCjuv/9+m/d+Vaqu966GDRsiODhYfp6UlOT0MSpK4dfaEdbx1K1bN5uRxtZxeOPGDXkErT2fffYZ0tPTAeSPMn/xxRcdbkdZ7tkxMTEA8t93x48fBwDs2LEDQP61CAkJgdFoxFNPPQVJkvDRRx+V6RoRERFVd0zaEhERuYGRI0fKibX3338fQH6iIisrCwAcSgp+++238n/MAWDEiBEYMWKE/PzIkSNyEs4enU6Ht99+u8hP4UmkyiokJAQLFiyAIAgA8ifOCQkJgb+/P15//XUA+cmW7777zuYr6tYMBgOuXbsGs9mMjIwM7N+/HxMmTEDPnj2Rl5dXpnY5e8xZs2bhr7/+gq+vL1asWCH3x9UkScLNmzdtviLt7e2NBx98sMT9rL82/t///tfmX4VCgYkTJ9rdt23btvJjk8mE9u3bo1mzZhg3bhzef//9UmOuwIEDB4qNveK+Mu8sf39/m9fIuk15eXm4ePGi/PzixYvya16QcAKAgIAAm8SZIAioV6+e/Nx627IwGAw2k/3dc889drfNysrCrVu3YDabkZKSgh07duCxxx7DiBEjqnwip+py7yrs3LlzNqU9IiIi7G5bXNx9+umnTp2vIhkMBpw7d05+Hh8fb7O+8POSYs9sNuM///mP/Lxv3742Hw6Upiz37EGDBiE2NhaiKKJ9+/aIiorCO++8AwB47rnn4OHhgYULF+LMmTMYNWoU7r//fofbQ0REVJOwpi0REZEb8PLywlNPPYU33ngDZ86cwbZt2+QESGhoKB599FHMnTu3xGNYzwberFkztGjRAg0aNICfn588ynDlypXyf56Lk56ejmnTphVZ3rVrVwwfPtz5jhVjypQpiI+Px+OPPy4ndgp4e3vj0UcfRYcOHYrdt2XLlrjvvvsQHR2NpKQkfPXVV8jIyACQX1Nx9uzZdms62uPsMQ8ePCjX7ly0aBHq1auHy5cvO3XOymCdQCwQGRmJzz//vMSEFQDcfffd6NChAw4cOIAvv/wSTz/9tDzSr3///kWSRNa6deuGhx9+GJs2bZKXnT59GqdPn5ZjsmXLlnj33XdLHG37008/4aeffiqyPCQkBM2aNSux/aXx8/ND9+7dsXPnTgDAqlWrIIoiGjZsiO+//75I3d6MjAx4e3sjLS1NXmY9qraAv7+//Li02r+leeGFF+RjeHt7F/s+FAQB9957L9q2bYuIiAgkJiZizZo1cpJ53bp16Ny5s1zjtCpUl3tXwQdOAHD79m2sWrUKkiTJ6wcPHmx33+KudWxsLJ588skS211Z0tPTbdpeOPas4w4oOfbWr19vc38qrq+lcfae7efnh4MHD+Lll1/Gjh07kJqaiubNm+OZZ57BM888g/Pnz+P1119HUFAQFi9eDL1ej7Vr1+LIkSNQKpXo0KEDBg8eDKVS6XRbiYiIqhXXVmcgIiKisihcF3Lz5s3StWvXJJVKJQGQoqKi5HUvv/yyJEmSPBs3iqlJeOPGDZu6ka+99pq8zrr+YVhYmDzDdwFHZmCvqBqakpQ/k3pBW4OCgqSpU6dKL7/8shQTEyOfr127dpLBYLDZ78yZM0WOdf36dSk0NFTeLzQ01GY29dI4e8zc3FypUaNGcv3XguWFX09X1LQt/KNSqaRFixYVez0K75uVlSWtW7dOfm4dfz/99FOpdTiNRqO0cOFCKS4uzm57vLy8bK534WPa+3G0XnJpTp8+bVO7tqSflJQUSZIkqU+fPvKy6OjoIsfs2LGjvL5x48ZlapfRaJSeeOIJ+ThqtVratGlTke1yc3Oly5cvF1l+7Ngxm/qv7dq1c/jcFVHTtrrfuwBIffr0kYxGo7xf4Zq2xf1UZO1sa47UtL1586bNNq+88orN+vPnz9usL1yz2lrbtm3l7e6+++4ytbms92x7evToIQGQli9fLqWlpUnNmzcvcv27d+/u8PGIiIiqK5ZHICIichNRUVFyrcLr168DyJ/le8KECaXu+8UXX8BiscjPrb9a/Oijj8qPb9++je+//97ucWJjYyFJUpGf3bt3O9udYh0/fhxTpkyR27px40a8/fbbmD9/Pvbs2SN/BfePP/7AF198YbNvkyZNihwvMjLSpr5jcnIyUlJSHG6Ps8d89913ce7cOfj7+2PZsmXVpiwCAMycORPz5s2T67WazWa89NJLePXVVx3af/DgwXLt0YL4a9asmUOzzKvVarz00ku4dOkSzp8/j1WrVuHpp59GaGiovI1er8fSpUvtHmPOnDnFxt7YsWMdan9p7rrrLhw9ehTPPPMMYmNjoVarER0djaFDh+Lpp5+Wt/Py8kJgYCAA2NRELTzCsPCy0uoGFycjIwMPPPAAli9fDiC/vu7GjRvx0EMPFdnW29tbrhVqrWXLlujWrZv8vLiawpWtOty7rCmVSoSEhKBnz55Yvnw5vv/+e6jVarvbFxd31qUqqlpgYKDNvaVw7BV+bi/2du7ciSNHjsjPX3rpJafbUp57dnE+//xz7Ny5E927d8e4ceMwf/58nDx5ElFRUbh48SL++OMP+Pr6YteuXfj444+dbi8REVF1wqQtERGRG7GuLQrkTzgTGRlZ6n4Fk/4UaNiwIQRBgCAIGDBggM06668iV7Vdu3bZfO23ffv28uO4uDib5MPRo0fLdI7KSKQWHPPWrVsA8pMmcXFx8jUu/LX/7t27QxCECkt2O+LJJ5/E7NmzcfDgQbRu3Vpe/sYbb9jUbLVHpVIVSbL9+9//drodDRo0wKhRo/DRRx/h3LlzNonP8+fPO328ihQdHY0PP/wQiYmJMBqNuHr1Kr7++mtcu3ZN3ubee++FQpH/J3bLli3l5ZmZmTZfQxdFEZcuXZKft2jRwqm2/P3330hISJBLNoSHh2P37t3o379/mfpWwFUfJLj63mX9gZPZbEZycjJ27NiBcePGya9nTeHp6YnGjRvLz//++2+b9YXfz/Ziz7qsS/369UssEWFPRd6zU1JSMHXqVHh6euKjjz4CkD/5IZAfL/Hx8Wjbti169uwJAPJ7g4iIqKaqWX+BEBERUYkSEhJs/lPsyCQ+v/76q1Oj67Zs2eLUaNTiJCYmyokVQRAcTgRbj6gDgMOHD9sc07pd1rOJf/rpp9i6datN8gDInzn9m2++kZ/XqVPHJkk4d+5cuY2FJzYr6zGrO29vb5uJh4xGI+bPn+/Qvk899ZR83QMDAzF69OhS9/n++++xaNEiJCcnF1nn5eUFlerOFAxardahdpTE+jV1JkGp1+uRm5tbZPmaNWuwdetW+fm4cePkx4WThhs2bJAfb9u2zWbEo/Xo2N27d9u0sfCozV9++QX33nsv/vrrLwBA06ZN8euvv9q89wtbtGgR9u/fX2T5iRMnbD4ccDZ5XFFqyr2rPKxf09Lq9JbXwIED5ce7d++2qa+8fv16+XFUVBTuvvvuIvufPHkSP/74o/x8ypQpdmvEFr6fW8dTWe/ZxZk6dSpSU1PxyiuvoFGjRgAg12P28PCQtyt4XNaJJYmIiKoLTkRGRETkZr744gv89ddfUKvVSEhIKHX7FStWyI8FQcDQoUOLJLOys7PlxJTJZMLq1auLjIwDbCfzKaxv377lnhCqa9euNs8HDx6McePGwdPTs8jEQX369JEfnzp1Ck899RTi4+PRu3dv1K1bF9evX8eaNWtsZp1/9tlnHU7kleWYrVu3timdUCA5ORl79+6Vn3fp0gWhoaE25QGqUrdu3eSJxQDgyy+/xNy5cxEbG1vifsHBwdi+fTtSUlJQp04d+Pj4lHqu27dvY/r06Xj55ZeRkJCAdu3aISwsDDqdDps3b5ZHJwPAAw88YPc4Bw4csBt7L774YqntKM2FCxeQkJCAvn37ygmjw4cPY/v27fI2CQkJGDlypPy8adOmGDJkiJzEnzRpEs6cOQMvLy+br27fc8896N27t0PtOHDgAHr27AmDwQAgP0E1aNAgm0RcAet+HzhwANOnT0fz5s3Ro0cPhIWF4e+//8aaNWug1+vl7RwpSVBZXHnvKg97cdehQwe7kyI64/fff8fatWsB5N9jra1btw4nT54EkD+KtWDCx+effx4fffQRdDodsrKy0LlzZ4wYMQKnT5/G119/Le8/Y8aMYpOx1n0KCQmx+TDCGWW9Zxe2c+dOfPHFF2jatKlNmYZmzZrh3Llz+OGHHzBv3jzk5uZiz5498joiIqIarQrr5xIREVEFKW4yn9IUN5lPXl6epNVq5eW9evUqdl9RFG32b926tbzO0cl8rCfMcWQyHXsmTZpU6rnGjRvn9D7Dhg0rMlGR9YRbhScWKusxi1MdJiK7dOmSzfotW7bYrH/22Wft7puVlVXiuUp6vQsmsyrtp2/fvpLZbLZ7zJJ+Suq3o06cOFHiOdq3by8lJSUV2S8lJUVq3bq13f1iY2Olixcv2uxTOB6sXxtHr1fhvj300EOlbv/CCy84fD2s21LeichKUxX3LmcmDnNkIrLi3o8lrSuJo6954UnatmzZInl6epa4fXETDV67dk1Sq9XydnPnzi2xfYXfi4XvX2W5Z1vLy8uTGjZsKAmCIO3fv99m3YEDB+RJ7LRareTr6ysBkPz9/aW///675AtLRERUzbE8AhERUS22adMmZGRkyM+feOKJYrcTBAFjxoyRnx89ehTHjh2r7OYV691338V3332HQYMGITo6Gh4eHlCr1ahTpw769++Pr7/+Wp6YqcCMGTPw8ccfY+DAgWjUqBECAgLkfQYMGIANGzZg3bp1Nl/FL01lHLM66d+/vzwpGQAsX74cN2/erPDzDBs2DFu3bsWUKVPQoUMH1KtXD76+vlCr1QgPD8f999+P5cuXY8uWLXa/nl0VIiMjMWnSJLRp0wYhISFQqVTyZFWfffYZDhw4gPDw8CL7BQcH48CBA3jzzTfRpk0b+Pr6wtvbG02bNsXMmTNx9OhRxMfHV3r7lyxZgnfffRd9+vRB/fr14efnBw8PD9StWxfDhw/Hzp07sXjx4kpvR0Wpifeuqta/f38cP34c48aNQ926deHh4YHAwED06NED69atw8qVK4v9ZsGSJUtgMpkA5JcseO6558rVjrLcs63Nnz8f58+fx1NPPYWOHTvarEtISMC2bdvQsWNHecR47969sWfPHtSrV69c7SYiInI1QZIKFWIjIiIiohpl7Nix+PzzzzFnzpxKr5VJVGDlypUYN24cunbtWqWT5hERERHVBhxpS0RERERERERERFSNMGlLREREREREREREVI0waUtERERERERERERUjTBpS0RERERERERERFSNcCIyIiIiIiIiIiIiomqEI22JiIiIiIiIiIiIqhEmbYmIiIiIiIiIiIiqESZtiYiIiIiIiIiIiKoRJm2JiIiIiIiIiIiIqhEmbYmIiIiIiIiIiIiqESZtiYiIiIiIiIiIiKoRJm2JiIiIiIiIiIiIqhEmbYmIiIiIiIiIiIiqESZtiYiIiIiIiIiIiKoRJm2JiIiIiIiIiIiIqhEmbYmIiIiIiIiIiIiqESZtiYiIiIiIiIiIiKoRJm2JiIiIiIiIiIiIqhEmbYmIiIiIiIiIiIiqEZWrG1AdiaKIGzduwN/fH4IguLo5RERERERERERE5AYkSUJWVhYiIyOhUNgfT8ukbTFu3LiBunXruroZRERERERERERE5IauXr2K6Ohou+uZtC2Gv78/gPyLp9FoXNwacoYoikhOTkZoaGiJn1YQAYwXcgzjhBzFWCFnMF7IGYwXKo3bxIgkAQZD/mNPT4DffK1QbhMnVCUYL5VHp9Ohbt26cv7RHiZti1FQEkGj0TBpW8OIogi9Xg+NRsObCpWK8UKOYJyQoxgr5AzGCzmD8UKlcZsY0euBUaPyH69fD3h5ubY9bsZt4oSqBOOl8pVWkpVXnYiIiIiIiIiIiKgaYdKW3IogCAgMDOQEcuQQxgs5gnFCjmKskDMYL+QMxguVhjFCjmCckDMYL67H8ghlIIoiDAV1dqha0uv1rm6C2/Dw8IBSqXR1MyqFIAjw9PR0dTOommOckKMYK+QMxgs5g/FCpWGMkCMYJ+QMxovrMWnrJIPBgPPnz0MURVc3hYohSRIkSYIgCPw0qAIFBQUhKirK7a4pC6uTIxgn5CjGCjmD8ULOYLxQaRgj5AjGCTmD8eJ6TNo6QZIkXLt2DUqlEvXq1WPQVkOSJEEURSgUCrdLMLqCKIrIyclBUlISACA6OtrFLap4kiS5uglUAzBOyFGMFXIG44WcwXih0jBGyBGME3IG48W1mLR1gtlsRk5ODmJiYuDr6+vq5lAxmLSteAWxnpSUhDp16rhtqQQiIiIiIiIiouqCSVsnmM1mAPk1Polqk4LErdFohLe3t4tbQ0REREREbkmhADp2vPOYiKgWY9K2DDiCs3pj2YqK567XVBAEBAcH8z1NJWKckKMYK+QMxgs5g/FCpXGbGPHwAP7v/1zdCrflNnFCVYLx4nrumYmhUr3xxht49NFHq+x8zZo1w5YtW8p9nLFjx2Ly5Ml21xfcTHhTIUcIggClUsl4oRIxTshRjBVyBuOFnMF4odIwRsgRjBNyBuPF9Zi0dUPdunXDu+++W2S5IAg4evQoAGDmzJlYs2ZNqceaO3cuHn744XK36dSpU3jwwQfLfZzSCIIAX19faDQaBAUFISEhAe+++y5MJpPDx7B3/cj9iKKI27dvQxRFVzeFqjHGCTmKsULOYLyQMxgvVBrGCDmCcULOYLy4HpO2VKnMZnOVzza4b98+ZGZm4tatW3jzzTfx+eefY8CAAZz1kIiIiIiIqDrT64EBA/J/9HpXt4aIyKWYtK1iqTl6nLqZhtQc1/4Csh5BK0kSpk+fjoiICGg0GjRq1AhbtmzBpk2b8MYbb2DLli3w8/ODn58fAMBkMmHGjBmIiYlBaGgohg8fjuTkZPnYgiDg/fffR/PmzeHr64vs7GzExcVh06ZN8jY//fQT7r33Xmi1WtSpUwcLFiwAAFy5cgX3338/QkNDERgYiP79+yMxMbFMfVSr1ejatSs2bNiAPXv24IcffgAA/Pnnn+jUqROCgoIQGhqKRx99FKmpqQCAqVOnYt++fZg+fTr8/PzQt29fAMDixYvRsGFD+Pv7o379+nj//ffL1CYiIiIiIiIiIqLSMGlbhXadu4Hxq/fghW8OYvzqPdh17oarmwQgP4H61Vdf4ciRI9DpdNixYwcaNWqEhx9+GDNnzsSDDz6I7OxsZGdnAwAWLFiALVu2YP/+/bh06RIEQcDIkSNtjvnVV19h+/bt0Ol08PX1tVn3559/4qGHHsJLL72E5ORk/PXXX+jevTuA/OH3U6ZMwdWrV3H58mX4+PjgySefLFf/6tWrh3bt2mHPnj0A8ifVevPNN3Hr1i2cPHkS169fx//9U+z+nXfeQefOnbFw4UJkZ2fLid7Y2Fjs3LkTOp0On332GaZNm4ZffvmlXO0iIiIiIiIiIiIqjsrVDajpZn73GzLzjKVuZ7RYcOJGGiyiBJVCQHquATO++xUtIoPgoVQ6dK4Abw+8MfAeh7adMWMG5s6d69C2arUaer0ep06dQmhoKGJiYkrcftWqVZg/f7683eLFixEVFYUbN24gMjISAPDSSy/Jjwv75JNPMGLECAwZMiS/XwEBuO+++wAAcXFxiIuLAwB4eXnh5Zdfxn333QdRFKFQOPYZg0KhKFIoOyoqCmlpaQCAVq1aycvDw8MxZcoUTJs2rcRjFrQVALp3744+ffpg9+7d6Nixo0NtoupJoVAgLCzM4dii2olxQo5irJAzGC/kDMYLlcbdYiTPYkKeIRdBXl6ubopbcbc4ocrFeHE9XvlyyswzIi3XUOpPcrYeJosIAYAoAQIAk0VEcrbeof3Tcg0OJYcLLFiwABkZGTY/9nTv3h3z5s3DrFmzEBISgiFDhuDSpUt2t7927ZqcWAWAyMhIeHp64tq1a/KykhK/ly9fRsOGDYtdl5ycjMceewx169aFRqNBly5dYDAYkJWVZb+zxShcv/b69esICgoCAFy4cAEPPfQQIiMjodFoMGrUKKSkpJR4vNWrV6Nt27YICgqCVqvF999/X+o+VP1JkgSLxcJ6x1Qixgk5irFCzmC8kDMYL1Qad4sRkyhCZzK4uhlux93ihCoX48X1mLQtpwBvDwT5eJb6E+rnBbVSAQmAQgAkAGqlAqF+Xg7tH+TjiQBvj0rrx4QJE3Do0CFcuXIFnp6eeP755wGg2E9UoqOjberMJiUlwWAwIDo6Wl5W0icxsbGxuHDhQrHrZsyYgdzcXLlUw969ewEUTcKWpPDMhomJifjjjz/QrVs3AMAzzzyDqKgonD59GjqdDl9++aXN8Qu3/cqVKxgzZgwWLVqE27dvIyMjA/369eONyw1IkoTU1FS+llQixgk5irFCzmC8kDMYL1Qad4sRCRL0ZpOrm+F23C1OqHIxXlyP5RHKydFyBUB+Tdslu08g12iGj4cKk7q1QPdGxZcQqEqHDx+GyWTC3XffDW9vb/j6+iIvLw9AfvmAy5cvw2w2Q6XKD5dRo0bhjTfeQIcOHRAYGIgpU6agV69edsshFPbkk0+iU6dOePDBBzFgwADk5OTgzJkzuO+++6DT6eDj4wOtVovU1FTMmzevzP0ymUw4dOgQJk+ejK5du+KBBx4AAOh0Ovj7+0Oj0eDq1at46623bPYLDw/HxYsX5efZ2dmQJEn+WsD333+P7du346mnnipz24iIiIiIiMi+HIvj3zQlInJHHGlbhbo3isSykV3x7pAOWDaya7VI2AL5ScwJEyYgODgYERERuHHjBpYsWQIAGDp0KDQaDUJDQ6HVagHkj4bt06cPEhISEBcXB5PJhC+//NLh87Vt2xbffPMNXn/9dQQFBeGuu+6SJwmbN28eLly4gMDAQHTs2BF9+/Z1uj+dO3eGRqNBWFgYpk2bhlGjRmHz5s1yndvFixdjy5Yt0Gg0eOihh2zq1QLA5MmTsWPHDmi1Wjz44INo2rQpXn75ZfTo0QPBwcFYt24dBg4c6HS7iIiIiIiIqAQKBXD33chr3Qp5osgRfkRUqwkS74JF6HQ6BAQEIDMzExqNRl6el5eH8+fPo2HDhvD29nZhC8keSZLkScsKT0ZGZeeusS+KIpKTkxEaGsri6mQX44QcxVghZzBeyBmMFyqNu8XIsfSbSDXkonNYHNQKxybuptK5W5xQ5WK8VB57ecfCWB6B3IogCFAq+UudHKNQKBAeHu7qZlA1xzghRzFWyBmMF3IG44VK444xYpIsMIoWJm0rkDvGCVUexovrMVVObkWSJPmHqDSSJMFgMDBeqESME3IUY4WcwXghZzBeqDTuGCMmiwijaHF1M9yKO8YJVR7Gi+sxaUtuRxRFVzeBaghJkpCens5fQlQixgk5irFCzmC8kDMYL1Qat4kRvR545BHEjnkSlrw8Jm0rmNvECVUJxovrsTwCEREREREREVUPBgMEkwFm0QITk7ZEVItxpC0RERERERERVStmSBxpS0S1GpO2RFSrqVT8wgGVjnFCjmKskDMYL+QMxguVxt1iRIKEPLPJ1c1wO+4WJ1S5GC+uxatPbkUQBCiVnF2UHKNQKBASEuLqZlA1xzghRzFWyBmMF3IG44VK464xkmM2uroJbsVd44QqB+PF9TjSltyKJEkQRZGFsskhkiQhNzeX8UIlYpyQoxgr5AzGCzmD8UKlcccYESAgz2Jyqz65mjvGCVUexovrMWlLlSoxMRGCICAjI8PuNpcvX0ajRo1gMBgq5JySJKF79+5499137W7z8MMPY+7cuRVyvuL07t0bO3bsqLTjU8WQJAk6nY6/hKhEjBNyFGOFnMF4IWcwXqg07hgjakEBkyRyMrIK5I5xQpWH8eJ6TNq6sSeeeAKCIODMmTMO7zN27FhMnjy58hpVjNmzZ+Pf//43PD09S2xDXFwcNm3aVKVtc0S3bt2KJIhffvllTJs2zTUNIiIiIiIiqokUCqB5c+jvagKVUgmzKHIyMiKqtZi0rULmq9eh+3A50mcvgO7D5TBfvV5p58rKysLXX3+NoKAgLFu2rNLOU16pqanYsGEDRo4c6eqmVKguXbogIyMDv/zyi6ubQkREREREVDN4eAALFiBp9kwovbxgYtKWiGoxJm2rSO6WbUh+dDxyvloP/c49yPlqPZIfHY/crdsr5Xzr1q2Dr68vFi5ciFWrVsFkujPrpiiK+O9//4smTZrA398fDRs2xI8//oj//ve/WL16NZYuXQo/Pz80a9YMQNERrps2bUJcXJz8fPHixWjYsCH8/f1Rv359vP/++w63c9u2bbjrrrsQFBTkdB+//PJL3HXXXdBqtejUqROOHDkCIH8yssK++eYbNGjQAAEBAXjyySdhNptt1m/fvh1t2rRBQEAA2rZta1PaoPBI2qNHj8rnmDp1Kvbt24fp06fDz88Pffv2ldvQo0cPfPfdd073i6qOIAjw8PAoNmaICjBOyFGMFXIG44WcwXih0rhjjCgEBURITNpWIHeME6o8jBfXU7m6ATWZmJ0D88VLpW5nuZ2MzAX/ASQJQEEtkPx/M99YDMHDA8owx2bkU9WvB4Wfb6nbLVu2DCNHjsSIESMwefJkbN68GYMHDwYAvP/++3j33Xexfv16tG3bFlevXkVOTg4eeOABHDlyBFqttsR6sIXFxsZi586diI6Oxu7du9GvXz+0adMGHTt2LHXfo0ePokmTJg6fq8DevXvx7LPPYuvWrUhISMAHH3yABx54AOfPn0dAQIDNtufOncNjjz2G//3vf+jbty8+++wzTJw4EXfffTcA4MKFC3jooYewevVqDBw4EJs2bcLAgQNx6tQp1KtXr8R2vPPOO/jjjz/w8MMPFynp0LRpU2zfXjlJeaoYgiCU6QMDql0YJ+Qoxgo5g/FCzmC8UGncNUYEgEnbCuSucUKVg/HiekzaloP54iWkPju1fAeRJGTMWeDw5sEfvgOPVs1L3Ob06dM4dOgQPvroI/j5+WHQoEFYtmyZnLT98MMPMXfuXLRr1w4AEBMTU/b2AxgyZIj8uHv37ujTpw92797tUNI2PT0dGo2myPIPP/wQK1eutFmm0+nkx6tWrcKoUaPQpUsXAMDkyZPx4YcfYsuWLXj00Udt9lu3bh169uyJAQMGAACeeeYZLFmyxGZ9t27d5OvzyCOP4JNPPsGaNWswc+bMUvtgj0ajQXp6epn3p8onSRKys7Ph5+fHTw/JLsYJOYqxQs5gvJAzGC9UGreJEb0eGD8eMcY8JC2cB3ioYBJFV7fKbbhNnFCVYLy4HssjuKFly5ahVatWaNWqFQBgzJgx2LZtG65fz6+he/nyZTRs2LDCzrd69Wq0bdsWQUFB0Gq1+P7775GSkuLQvoGBgTbJ2ALPPvssMjIybH6sk8vXrl2zKdEAAPXq1cO1a9eKzGx448YNxMbG2iyzfl7cseLj43Ht2jWH+mCPTqdDYGBguY5BlUuSJOTk5HA2TCoR44QcxVghZzBeyBmMFyqNW8WITgdFVhYAQCkokGsxurhB7sOt4oQqHePF9Zi0dTMmkwmrVq3CuXPnEBERgYiICIwcORIWi0UeuRobG4sLFy4Uu79CUTQk/Pz8kJubKz+/efOm/PjKlSsYM2YMFi1ahNu3byMjIwP9+vVz+E3dunVr/PXXX070MF90dDQSExNtliUmJiI6OrrItpGRkbh8+bLNsitXrjh8rJL6DxR/zYD8Ec+tW7curStERERERERUDLVCgVyzqfQNiYjcEMsjlIOqfj0Ef/hOqdtZbicjY+7Cf2raFiII0M79P6dq2pbku+++g06nw9GjR6HVauXlS5cuxfLlyzFz5kw8/fTTmDdvHlq0aIFWrVrJNW3vuusuhIeH49SpU5AkSR7+3rZtW6xZswaDBw/GjRs38MEHH8jHzc7OhiRJCAsLg0KhwPfff4/t27fjqaeecqg/vXv3xtNPP4309HSnRqWOGjUKAwYMwKhRo3Dvvffiww8/RGpqKvr161dk22HDhmH+/PnYunUr+vTpgxUrVuDcuXPy+uHDh2P+/Pn49ttv0b9/f3z33XfYu3cvli5dKvd/w4YNeO6552AwGLBo0SKb44eHh+PixYtFzrtr1y58/vnnDveJiIiIiIiI7lALSuRZTBAlEQqBY86IqHZh0rYcFH6+pdaXLSAZTchcsBgQhDtzkUFCwIwp8L6/W4W1admyZXj00UeLTO71/PPP46233sKuXbvw/PPPw2KxYNiwYbhx4wYiIyPx3nvv4a677sK//vUvDBs2DEFBQahbty6OHz+O+fPnY+TIkQgNDUWzZs3w+OOPywnNpk2b4uWXX0aPHj1gsVgwcOBADBw40OH2hoSEYNCgQVi9ejUmTpzo8H5du3bFe++9h/Hjx+PmzZto3rw5fvjhB2i12iKjfBs3boxVq1bh+eefR0pKCoYOHYoHHnhAXt+gQQNs2LABM2bMwOjRoxEfH4+NGzciPj4eAPDCCy/gzz//RN26dRETE4OJEydi9+7d8v6TJ0/G2LFjodVq0alTJ2zZsgX79u2DRqNB586dHe4TVT1BEODt7c36PFQixgk5irFCzmC8kDMYL1Qad40RlUIBvWiGSRThqWTStrzcNU6ocjBeXE+QWJyiCJ1Oh4CAAGRmZtpMkpWXl4fz58+jYcOG8Pb2dvq45mvXkbt5Gyw3b0FZJxw+A/pAFR1VkU2vkRITE9G7d2+cOHECnp6erm5OhejTpw9efPFF3H///a5uSoUob+wTERERERGVSq8Hhg5FpkmPQ0sXI0CjRboxD51CY+Gvdo//KxIR2cs7FsaRtlVIFR0FzbNPuLoZ1U5cXJxNuYLykCRJLu3gyk+Dtm3b5rJzk+MkSYJOp4NGo+Gnh2QX44QcxVghZzBeyBmMFyqNu8aISlDALFpgFC2ubopbcNc4ocrBeHE9fr+A3A4Hj5OjJElCXl4eY4ZKxDghRzFWyBmMF3IG44VK4zYxolAADRvCGB8PSSFAIQgQITFpW0HcJk6oSjBeXI8jbYmIiIiIiIjI9Tw8gMWLcSP9JqS8LACAADBpS0S1UrUdafvmm29CEARMnjxZXqbX6/Hcc88hODgYfn5+GDJkCG7dumWz35UrV9C/f3/4+PggLCwM06ZNg9lsruLWExEREREREVH5CTBa+H96Iqp9qmXS9vDhw/j444/RsmVLm+UvvPACNm/ejPXr12PPnj24ceMGBg8eLK+3WCzo378/jEYjDhw4gM8//xwrV67E7Nmzq7oL5EKstUKOEgQBvr6+jBkqEeOEHMVYIWcwXsgZjBcqjTvHiFqhRJ7F5OpmuAV3jhOqeIwX16t2Sdvs7GyMHDkSn376KQIDA+XlmZmZWLZsGRYvXowePXqgXbt2WLFiBQ4cOIBDhw4BALZv347Tp0/jyy+/ROvWrdG3b1+89tpr+OCDD2A0Gl3VJapCgiBAoVDwpkIOEQQB/v7+jBcqEeOEHMVYIWcwXsgZjBcqjdvEiMEAjB+P6H9PgcKQ/394laBAjpn/n68IbhMnVCUYL65X7ZK2zz33HPr3749evXrZLP/jjz9gMplsljdp0gQxMTE4ePAgAODgwYNo0aIFwsPD5W369OkDnU6HU6dOVU0HyKUkSYIoiiyUTQ6RJAlpaWmMFyoR44QcxVghZzBeyBmMFyqN28SIJAG3b0OVkpL/GIBKoYDeYoFFFF3cuJrPbeKEqgTjxfWq1URka9euxZEjR3D48OEi65KSkuDh4QGtVmuzPDw8HElJSfI21gnbgvUF6+wxGAwwGAzyc51OBwAQRRHiP78YrD9ZkCTJJmgFQSg2iCtieWUe21XLK/uckiRV+Xmr0/WtqOXWywpivuD9UPg9AAAKhaLY90bBcSpiuVjoDzVnlxduoyiKMBgMNv2s6X0qy3L2qeTlkiTBYDDAYrFAoVC4RZ/c8XWqDn0q6Z5SU/tUnrazTyUvL4gXi8UClUrlFn0qa9vZJ8fabv27yB365I6vkyv7VNo9pcb0CUDBkoL1Kiigl0wwWMzwskph1Jg+VaPYkyQJRqPR5u/amt4nd3ydqkufyvO3bXXtU3mWV2SfCq+zp9okba9evYpJkybhp59+gpeXV5Wee8GCBZg3b16R5cnJydDr9QAAb29veHh4yBfXOpnrzItacGO09+I5ur1SqbS7vKoDtbr1CSg+sV6T++Tq16lg9HJ6ejp8fX1hNBqRnp4ub6tSqRASEoK8vDz5Qw8A8PDwQFBQELKzs5GTkyMv9/b2RkBAAHQ6HfLy8uTlvr6+8Pf3R3p6uk1JE41GAx8fH6SlpdlMLBgYGAhPT08kJyfbXIPg4GAolUrcvn3bpk9hYWGwWCxITU2V+6bT6RAeHu42fQLyY4B9qrg+eXl5ISsrC5Ikye+Lmt4nd3ydqkOfRFFETk4OwsPD3aZPgPu9TtWlT6IoIjMzE5IkISIiwi365I6vU3XpU0ZGBjIyMuTfRe7QJ3d8nVzZp4J7ilKpRFhYWM3tU0AARFGExWiCpMuGXlRBUgAmLyWy83Kgy70z2KrG9KkaxV5AQACA/FxHwf+da3qf3PF1qi59EkVR7oe79AmoHq9TVlYWHCFIhdPTLrJp0yYMGjRITnIB+ROLCUJ+jdJt27ahV69eSE9PtxltGxsbi8mTJ+OFF17A7Nmz8d133+Ho0aPy+kuXLiE+Ph5HjhxBmzZtij13cSNt69ati/T0dGg0GgD5waHX63H+/Hk0aNAA3t7e8vYFibPCKmJ5ZR7bVcsr+5yiKNp8algV561O17eillsvy8vLk2Pf19fXLT7ZAvJjJTk5GeHh4cVeg5rYp7IsZ59KXi5JEm7duoXQ0FCOtGWfSlxe0j2lpvapPG1nn0ofaZucnIzQ0FCOtGWfSl1usVhw+/Zt+XeRO/TJHV8nV/aptHtKjemT0Qhp6FDoTHoc/OAdhGqDIUkSbuizkBBSF8EePjWvT9Uo9iRJQnJyMkJCQjjSln0qtY3l+du2uvapPMsrsk86nQ6BgYHIzMyU847FqTYjbXv27IkTJ07YLBs3bhyaNGmC6dOno27dulCr1fj5558xZMgQAMDZs2dx5coVJCQkAAASEhLw+uuv4/bt2wgLCwMA/PTTT9BoNGjatKndc3t6esLT07PIcoVCYTf5JwhCkWXFKVh+JScDqYbcIuuDPX0Q46st8TilHbuw7t274+DBg1Cr1fKyRYsWYcKECU4dpzKXl7Rtt27d8PDDD2Py5Ml2t+/WrRv27NmDn376yabO8aJFizB9+nQ8//zzWLJkSaW03d5yV1zHyl5esKwg5gsnrIrbvjKXF/d+dHa59bEFQUBAQIC8zB36VB2Wu2OfAgICoFQqi6yryX1yx9fJ1X2qjHuKq/tUGcvZJ8hJt4J7iyvbztepZvRJoVAU+7uoJvfJHV+niupTep4RSbpcRGh8EOzr5dA5q/qeUqmvU6H1giBAkgCTZH9wTrXvUzWJPUmSoNFoiv27trjtXdn22vw6lWV5ZbSx4L5i/V509DjVtU/lWV6RfbK3T2HVJmnr7++P5s2b2yzz9fVFcHCwvHz8+PGYMmUKgoKCoNFo8O9//xsJCQm47777AAC9e/dG06ZNMXr0aCxatAhJSUl45ZVX8NxzzxWblK0qV3Iy0Hzrf2EQzUXWeSpUONn/eZvEbUVYuHChTdKzLEwmk03it7pp3LgxVqxYYZO0XblyJZo0aVLsG4yoMEEQ4OPjU/qGVKsxTshRjBVyBuOFnMF4qT12nbuBxTuPIVNvQoCXB6b0aInujSJL3c/dY0QAYLRYXN2MGs/d44QqFuPF9RxL7VYT//nPf/Dggw9iyJAh6NKlCyIiIrBhwwZ5vVKpxJYtW6BUKpGQkIBRo0bh8ccfx6uvvlqp7bqSk4Ffki/b/fk56WKxCVsAMIhmeQSu0WK2e4wrORkV0tbt27ejTZs2CAgIQNu2bbFjxw553dixYzF+/HgMGzYMGo0GH330EUwmE2bPno369esjODgYAwcOxI0bN+R9kpKSMGrUKNSpUwdarRZdunSRa4K89NJLiI2Nhb+/P5o2bYr169fL+6WlpWHQoEEIDAyEVqtFu3btcPnyZUydOhX79u3D9OnT4efnh759+9rty4gRI/DDDz8gMzMTAPDrr78CAO655x6boewXL17EgAEDEBoaitjYWMyfP18epn7lyhXcf//9CA0NRWBgIPr374/ExESba/Lkk09ixIgR8Pf3R+PGjbF79+6yvwBUrYiiiJSUFIeLgFPtxDghRzFWyBmMF3IG46V2SM3RY8nuE7iVpYfeaMbt7Dws2X0CqTn6Uvd1mxgRBKBuXZiiovIfy4sFGESTCxvmHtwmTqhKMF5cr9qMtC1O4eSYl5cXPvjgA3zwwQd294mNjcX3339fyS2z9fnfRzD/1O5yHyfVmIcePy8rdt0rzbphVose5Tr+hQsX8NBDD2H16tUYOHAgNm3ahIEDB+LUqVOoV68eAGDNmjXYuHEj1q5dC71ej5dffhl//PEH9u/fj+DgYMycORMjRozA3r17IYoiBgwYgGbNmuH06dPw9/fHoUOH5GHerVq1wosvvojg4GCsX78eo0ePxt1334169erh7bffhtlsxvXr1+Hp6YkTJ07A398f77zzDv74448i5RGKo9Vq8cADD2DNmjV45plnsHz5cowdOxanTp2St8nNzUXPnj0xefJkfPPNN0hKSkK/fv1Qp04djB8/HqIoYsqUKejevTuMRiPGjx+PJ598Ej/99JN8jHXr1uG7777D6tWrsWDBAowdO9YmsUs1m3UhcSJ7GCfkKMYKOYPxQs5gvLi/JF0ucgwmQJL+KQkgIddoxi1dnlwmoSRuESOensDSpbiefhNi3p2JetQKBfLcoX/VgFvECVUZxotr1aiRtuS4GTNmQKvVyj85OTlYt24dunXrhsGDB0OlUuGRRx5Bp06dsGbNGnm/3r17o0+fPlAoFPD29sbSpUuxePFi1KlTBx4eHpg/fz5++eUXXL16FYcPH8aZM2fw4YcfIjAwECqVCp06dZJLUYwcORJhYWFQKpUYMWIEmjRpggMHDgAA1Go1UlNTcf78eSiVSrRu3RpBQUFO93PcuHFYsWIF8vLy8M0332D06NE267du3YrAwEBMnjwZHh4eiImJwaRJk/DVV18BAOLi4tC3b194eXlBo9Hg5Zdfxr59+2w+SerXrx+6desGpVKJcePG4fLlyzYzGBIRERERkXtJzdHj1M00h0a5VpQIjQ9USgUs/0xUYxEleKgUCNd4l76zm1MJSuRYONKWiGqXaj3SlspuwYIFRUaqXrt2DXFxcTbL4uPjce3aNfl5TEyM/DglJQU5OTno0qWLTY1YDw8PXL16FdeuXUNUVBS8vYv/I+I///kPPvvsM1y7dg2CICA7OxspKSkAgGnTpkGv12PYsGHIzMzE8OHD8eabb9o9lj09e/bE+PHj8dprryEhIQERERE26xMTE3Hy5ElotVp5mSiKqFu3LgAgOTkZkyZNwr59++QyCwaDAVlZWQgICAAAm2P6+voCALKyshAcHOxUW4mIiIiIqPpb9es5fHLgDFQKBQK8PTCpWwuH6sqWV7CvF3o1jsLaPy7CIklQCAIebhHn0Chbd6dSKGC0WGAWLVAplK5uDhFRlWDStgKMiW+LHhH17a4/p0vBM4e/LfU4wR7e2NlzfLHr6voElLl9BaKjo7F//36bZYmJiejSpYv83HoGu+DgYPj4+ODXX39FkyZNihzv119/xfXr16HX6+HlZfuHxP79+zF37lzs3LkTbdq0gUKhQOvWreVas35+fli4cCEWLlyIS5cuYcCAAVi6dCmmTp3q8Cx6Be0dM2YMXn/9dfzvf/8DAJsEc926ddGuXTscOnSo2P1nzJiB3NxcHDlyBKGhoTh69CjatGljUxOX3JcgCAgMDOTEdVQixgk5irFCzmC8kDMYL1UnNUePD/efhsFsgYdKCaXBhCW7T6BlVFCVJE/9PNWIC/KHSRShVigQrnFsEiC3iRGDAXjhBUQZcpH0yovAP5dcLSiQIxphZNK2XNwmTqhKMF5cj+URKkCMrxYdQ2Pt/vSMqA9PRfH5cU+FCsGe+b+IPZQqu8eI8dWWu53Dhw/H7t278e2338JsNmPDhg3Yu3cvRowYUez2CoUCzzzzDKZOnYqrV68CAFJTU7Fu3ToAQPv27dG4cWNMmDABGRkZMJvN2L9/PwwGA3Q6HZRKJUJDQyGKIpYvX46TJ0/Kx96yZQvOnTsHURSh0WigVquhUuVfo/DwcFy8eNHhfr3wwgvYvn07BgwYIN9MCv598MEHcevWLSxduhR6vR4WiwVnz56V6yXrdDr4+PhAq9UiNTUV8+bNc+6iUo0mCAI8PT35S4hKxDghRzFWyBmMF3IG46XqJOlyYbSIUAoCRFFCgLeHXFe2KlxOy4ZKqYC3WgWVUoHrGTkO7ec2MSJJwNWrUF+/nv/4H2qFAiZRhIkTIpWL28QJVQnGi+sxaVsFYny1ONn/eRzq/UyRn5P9n6+QhKwjGjRogA0bNmDOnDkICgrCq6++io0bNyI+Pt7uPgsWLEBCQgJ69OgBf39/tGvXDtu3bweQn9TdvHkzcnNz0bhxY4SEhOCVV16BKIp44IEH8Mgjj6BFixaIjIzEqVOn0LFjR/m4Fy5cwAMPPAB/f380bdoUCQkJePbZZwEAkydPxo4dO6DVavHggw+W2q+goCD06tULarUa0j/1n6xH9O7YsQM///wz4uLiEBwcjMceewxJSUkAgHnz5uHChQsIDAxEx44d0bdv3zJfX6p5RFHErVu3OBsmlYhxQo5irJAzGC/kDMZL1Qny8YIAyHVl03MN8PFQVUldWYso4VpGts2yaw4mbd09RlQKJSySCKNocXVTajR3jxOqWIwX1xMkfg+8CJ1Oh4CAAGRmZkKj0cjL8/LycP78eTRs2NDp2qtUNSRJgiiKUCgU/DSoArlr7IuiiNu3byMsLMypshxUuzBOyFGMFXIG44WcwXipOsnZeRi3ajduZeVBlCSE+3tjWq/WVVLT9lp6NqZt+tVmmZdaieUju5b6fxu3iRG9Hhg6FJkmPQ4tXYxQ7Z15RK7lZqBdUDSifDQlHIBK4jZxQlWC8VJ57OUdC2NNWyIiIiIiIiIAOr0J/l4e8FarYBJFPNelaZUkbAEgMS2ryDK9yYK0XAMnI/sHR9oSUW3CVDkRERERERERgMw8IwDIdWXNVfit4Mtpd0ojRGnvTEB2IzO36hpRjSmggN5scnUziIiqDJO25HY4bJ8cJQgCgoODWUqDSsQ4IUcxVsgZjBdyBuOl6uj0RpvnaTn6Kju3ddK2Q70I+bEjk5HVhhhRKRTIsRhL35Dsqg1xQhWH8eJ6zG6RWym4mfCmQo4QBAFKpZLxQiVinJCjGCvkDMYLOYPxUnV0ebZJwfRcQ5WcV5IkXP6nPILGS41mdQLldY4mbd0iRgQBCAuDOSQk/7EVtUKJPIvZRQ1zD24TJ1QlGC+ux6QtuZWCicg4vx45oqCwOmfDpJIwTshRjBVyBuOFnMF4qTqZhUfaVlHSNiPPCJ0+/6v/sUH+iNL6yuuuZ5aetHWbGPH0BJYtw7X3FkP09LBZpRIUMIkWmFjXtszcJk6oSjBeXI9JWyIiIiIiIiJATpwWqKqRtpetJiGLDfKDn6caGi81AMdG2tYGaoUCJsnCyciIqNZg0paIiIiIiIgIdyYiK5Cea6iSb/ElWtWzjQ3yAwB5tK1Ob0K2gRNwqQQlTBaRSVsiqjWYtCUiIiIiIiJC0YnIDGYReabKTxJesRppGxfkDwC2JRJqy2hboxGYMgWRL8+FYLR9LVQKBSySyPIIRFRrMGlbAYwWM3LNxkr9MbLgumzy5MkYO3YsAODKlSvw8/NDZmYmgPxC2QqFwuFC2X379sXSpUsrq6k1ysqVK9G6dWtXN6NKKRQKhIWFQaHgrZDsY5yQoxgr5AzGCzmD8VJ1Co+0BYC0HH2ln7dgpK1aKaBOQH6yNirgTtL2WilJW7eJEVEEzp+Hx99/QxCLjnBWCAJH2paD28QJVQnGi+upXN2Ams5oMeNw2nVkmyu31pGfyhPtg6LgoSz9Jbt48SImTpyIQ4cOwcfHB5MmTcJLL70kr9fpdHjmmWewZcsWeHt7Y+LEiZg1a5a8ftq0aVi2bBnq1q2LNWvWoGnTpgCAv//+G4MHD8ahQ4fg5eVl9/xxcXG4desWlEolvLy8kJCQgHfffRf169cvxxUoXkxMDLKz73yVqOCrS5IkFUncjh07FlqtFu+++6687IcffqjwNpV0Pnt2796Nhx9+GBkZGZXWHipKkiRYLBYIgsAZMckuxgk5irFCzmC8kDMYL1VDlKQiI22B/MnIogP9Ku28epMFSZm5AIBorR+UivzX2JnJyGpLjEgAk7blUFvihCoG48X1mC4vJ7MkIttsgIdCBX+VZ6X8eChUyDYbYJZKn7HPYrFg4MCBaNu2LW7fvo2dO3fi/fffx1dffSVv8+9//xtpaWm4cuUK9u3bh08//RRffPEFAODw4cPYtGkTEhMTMX78eEyfPl3eb8KECVi8eHGJCdsCa9asQXZ2Nv7++2/4+Pjg8ccfL/76mSt+BHFtndnQZGKdK2dJkoTU1NQqqVNGNRfjhBzFWCFnMF7IGYyXqpFrNKOYwZ2VPhnZ1YxsFJy2oJ4tYJu0vZGRW+IxakuMKAUBeWb+v6esakucUMVgvLgek7YVxFOhhJdSXSk/ngqlw+04e/Yszp49izlz5kCtVqNx48YYP348PvnkEwBAbm4u1q5di/nz50Or1aJRo0b497//jWXLlgHIH0179913Q6PRoHfv3rh48SIA4KuvvkJERAR69Ojh1HXRaDQYPXo0jh8/DgDo1q0bXnrpJfTu3Ru+vr744YcfkJ2djYkTJyImJgZhYWF4/PHH5XIHALB37160aNECfn5+GDx4MLKy7tR7SkxMhCAI8ghVURTx3nvv4a677oK/vz8aNmyIH3/8Ef/973+xevVqLF26FH5+fmjWrJncHuuRsNu3b0ebNm0QEBCAtm3bYseOHfK6sWPH4sknn8SIESPg7++Pxo0bY/fu3Q5dh4J2rlq1Cg0aNIBWq8XYsWNhMpmQmpqKvn37IjMzE35+fvDz88O+ffsAADt27MA999wDrVaLZs2a4bvvvrNpz/jx4zFs2DBoNBq88cYb8PDwwOXLl+VtDAYDAgMDcfDgQQDAqFGjEBkZCY1Gg3bt2mHXrl0OtZ+IiIiIyN1Zl0bwUt/5P1haJSdtL9tMQuYvPw709oD3P+0obaRtbaESlMgxFx0NTUTkjpi0dTMFo0ytPwkRRVFOmp49exZGo9Gmdmnr1q3l9c2bN8fvv/+OjIwM7NixAy1atEB6ejreeOMNvPPOO063JyMjA1988QXatm0rL1u5ciXmz5+P7Oxs9OrVC0888QTS0tJw/PhxXLp0CSaTCRMnTgQApKenY+DAgZg4cSIyMjIwbtw4fPnll3bP9/777+O///0vvvzyS+h0Ovz888+IjY3F888/j5EjR2LChAnIzs7GqVOniux74cIFPPTQQ5g1axZSU1Mxc+ZMDBw4EJcuXZK3WbduHZ555hlkZGRg9OjRcm1dR/3www/4888/cfr0afz8889YvXo1goOD8cMPPyAgIADZ2dnIzs5G586dcfz4cQwdOhRvvvkm0tLS8PHHH2P06NE4e/asfLw1a9Zg/PjxyMjIwLRp09C7d2+b67N582aEhoYiISEBANCzZ0+cOXMGqampGDFiBB555BGbJDgRERERUW1lXRrBesRrZY+0vWw1CZn1eQVBkEfbpmTroa+CCdGqO7VCAb3FzJF/RFQrMGnrZho3boy4uDjMnj0bBoMBp06dwvLly6HT6QAA2dnZ8PX1hUp1pzauVquVE3fNmjXDpEmT0K1bN2zbtg1vv/02pk2bhunTp+P06dPo0aMHevbsif3795fYjpEjRyIwMBDNmjWDKIpy+QUAeOyxx3DPPfdAEARkZ2fjm2++wQcffACtVgtfX1+8+uqrWLduHSwWC7Zs2YLIyEg8/fTTUKlUGDBgQImjfT/66CPMnj0b7dq1gyAIiImJwV133eXQtVu3bh26deuGwYMHQ6VS4ZFHHkGnTp2wZs0aeZt+/fqhW7duUCqVGDduHC5fvozU1FSHjg8As2fPhr+/PyIjI/HAAw/gjz/+sLvtxx9/jLFjx6JHjx5QKBTo1KkTHnzwQXz99dfyNr1790afPn2gUCjkMhSrVq2S169atQqjR4+Wn48bNw4BAQFQq9WYNm2aTUK/tmJtHnIE44QcxVghZzBeyBmMl8pnnbSNsxrx6qqRtoDtZGQ3ShltWxtiRK1QwiSJMLGubZnVhjihisN4cS1OROZm1Go1vv32W7zwwguIiopCdHQ0xo0bh48//hgA4Ofnh9zcXJjNZjlxm5mZCX//O38cTJw4UR7punfvXly5cgUjR45EbGws9uzZA0mS0KNHD/kr/8VZvXo1Hn744WLXxcTEyI8TExMhiiLq1atns41CoUBSUhJu3LiB2NhYm3WxsbHQ64ufwfXy5cto3LhxmW4s165dQ1xcnM2y+Ph4XLt2TX4eEREhP/b1zf8DKisrC8HBwQ6do/D+JU08lpiYiJ07d2LFihXyMrPZDI1GIz+3vpYAMHDgQDz11FP47bffEB8fjx9//BFLliwBkD/ietasWfj6669x69YtKBQK6HQ6pKSkONR2d6RQKBAeHu7qZlA1xzghRzFWyBmMF3IG46VqZObdqZUaE+QHQQAkqXJH2oqShCv/jLQN9fOCj4ftf9FtJiPLyEF8iAbFcasY0WggGtXFrlIKCphEI4yixaFJusmWW8UJVTrGi+txpK0batasGbZv346UlBQcPXoUBoMBXbt2BZA/EletVuPYsWPy9kePHkWLFi2KHMdoNGLy5MlYunQpkpOTYTabER8fj/r168NoNCI5OblM7VMo7oRd3bp1oVAocOPGDWRkZMg/er0eUVFRiIyMtKnRCgBXrlyxe+zY2FicP3++2K/LWJ+3ONHR0UhMTLRZlpiYiOjoaAd6VT7Fta1u3bqYNGmSzXXJzs7Ghx9+aHc/Ly8vDB06FKtWrcLatWtx7733yonor776Cl999RW2bt2KzMxMZGRkICAgoFZ/tUiSJBgMhlp9Dah0jBNyFGOFnMF4IWcwXqqG9UjbQB9PBHh5AKjcpO0tXR4M5vwSd3HB/kXWR2l95Mc3Mu1PRuY2MeLlBaxejSuffADRy7PIarVCAZMowsiRtmXiNnFCVYLx4npM2rqh48ePIycnB0ajERs2bMDy5cvxyiuvAAB8fHwwfPhwzJo1C5mZmTh//jzee+89/Otf/ypynAULFmDo0KFo0KABQkJCYDAYcOzYMRw/fhxGo9Hh0aUliYiIwMMPP4yJEyfKIz6TkpKwceNGAED//v1x/fp1fPrppzCbzdi6dSt27txp93hPPfUUXn31VRw9ehSSJOHKlSs4c+YMACA8PBx///233RvO8OHDsXv3bnz77bcwm83YsGED9u7dixEjRpS7n6UJDw9HVlYWbt++LS97+umnsWLFCuzatQsWiwUGgwEHDx6U+2PP448/jrVr12LFihV4/PHH5eU6nQ4eHh4ICQmB0WjEq6++Wuvr2UqShPT0dP4SohIxTshRjBVyBuOFnMF4qRqZVklbjZcHgnzzk4YZeUZYxMq59tb1bGMC/Yqsty6PUNJkZLUlRpSCAiIkJm3LqLbECVUMxovrMWlbQQyiBXqLqVJ+DE7+Qvr6668RExODwMBAvP3229i0aRNatmwpr3///fcREBCA6OhodOzYEePHj7dJ7gH5E5Zt3rwZL774IgBAqVTiww8/RN++fdG3b198/PHHUCqVqAgrV66EVqtF+/btodFo0LlzZ7nWa1BQEL799lssWbIEWq0Wn332GUaOHGn3WM8//zyefvppDB8+HP7+/ujVq5c8Mvdf//oXrl+/jqCgIJvrUaBBgwbYsGED5syZg6CgILz66qvYuHEj4uPjK6SfJWncuDHGjx+Ppk2bQqvVYv/+/WjTpg3WrFmDV155BaGhoYiKisKsWbNgMJT8SX+nTp3g7++P06dPY+jQofLyMWPGoFmzZoiNjUV8fDy8vb2rZBQxEREREVFNoMu7k7QN8PJAoE9+0laSgIy8yhlta13PtriRtqH+3lAr80u/Xc8ouaZtbSEAMP0zATcRkTsTJKbMi9DpdAgICEBmZqZN/dC8vDycP38eDRs2hLe3NwDAaDHjcNp1ZJsrtzi9n8oT7YOiWLenFJIkQRRFKBQKFsyuQMXFvjsQRRG3b99GWFhYqeUzqPZinJCjGCvkDMYLOYPxUjXmff8H/rqVAQD4fHQ3rDp8Hjv+ug4AeO3Bu9EgNKDCz7nop6P481r+xMZLHumAMP+if2tP3/QrrqRnQxCAz0d3h1pZNAbcJkaMRmDOHNzSZ+PPSU8jTBNUZJOrORloro1Aff+i66hkbhMnVCUYL5XHXt6xMGYAy8lDqUL7oCiYpcr9pE8lKJiwJaoEBRPyEZWEcUKOYqyQMxgv5AzGS+UrGE3rpVbCQ6VEkM+dmqqVVde2YKStj4cSoX5exW4TpfXBlfRsSBJwS5eL6GLKKABuEiOiCJw8CS+THoKdkhQqhRK5FmOx66h0bhEnVGUYL67Fq18BPJQqeLi6EQQAEAShwso2kPtTKBQICQlxdTOommOckKMYK+QMxgs5g/FSNXR6EwDIE5AFWiVt0yohaavTG+Xjxgb52/2mYJTWuq5t8Unb2hQjaoUCuWaTq5tRI9WmOKHyY7y4Hsc3k1spKI/Aqh/kCEmSkJuby3ihEjFOyFGMFXIG44WcwXipfCaLiFyjGQCg8c5P2lb2SFvreraxQcWPngUcm4ysNsWIWlAiz2KCWMnfdnVHtSlOqPwYL67HpC25Hd5QyFGSJEGn0zFmqESME3IUY4WcwXghZzBeKp9Of+fr9hovNQDbpG1aTsUnba/YJG2LTkJWwHqk7Q07k5HVphhRKRQwSyInIyuD2hQnVH6MF9dj0paIiIiIiIhqtSz9na/bF1ceoTJG2iamZcmPSxppG6HxQUHlhGt2kra1iVqhhEkUYRQtrm4KEVGlYtKWiIiIiIiIarXMPOuRtvlJWx8PFTxU+f9lTs+rjPII+UlbhQBEa+0nbdVKBcL9vQEANzNzIdbyUW8qQQGzaGHStobRW0zIYy1iIqcwaUtux14Bf6LCBEGAh4cHY4ZKxDghRzFWyBmMF3IG46XyWZdHCPinpq0gCHKJhIouj2CyiLj+z6jZKK0v1MqS/2teUCLBaBGRkq0vst6tYsTTE5KHp93VCkGACIlJ2zJwZZxczknH9TxdlZ+Xys6t7is1FJO25FYEQYBCoeBNhRwiCAKCgoIYL1Qixgk5irFCzmC8kDMYL5Uvs5iatsCdEgl5JgvyTOYKO9/1jByI/wyYLamebYHSJiNzmxjx8gL+9z9c/vxTiF72E7cCABOTtk5zZZykGfKAWj5KvKZxm/tKDcakLbkVSZIgiiILZZNDJElCVlYW44VKxDghRzFWyBmMF3IG46XyWZdHKBhpC9hORpaRa0RFcbSebQHryciuF1PXtvbFiACjpeKS6LWFq+JEbzEh28LSCDVN7buvVD9M2rqhbt26wdPTE35+fvLP0qVLXd0sh3Xr1g3vvvtuiducPXsWAwYMQEhICDQaDZo0aYKFCxcCyL+x1KtXD5s2bSpXOxITEyEIAjIyMsp1HKq+JElCTk4OfwlRiRgn5CjGCjmD8ULOYLxUvuImIgNsJyNLyy1alqCsLqdly48dGmlrlbQtbjKy2hYjKkGBXCYBneaqOMk1m6A3M8le09S2+0p1xKStm1q4cCGys7PlnwkTJjh9DJOp+v4S7N+/P1q1aoUrV64gPT0d33zzDeLj4yvs+NW570REREREVLFsyyMUP9K2IuvaXnZypG1kgI/8+EZmboW1o9oxGoF58xC+8B0IRvsjm9UKJXLMFTfymSpXjtkEPZPsRE5j0raW2b59O9q0aYOAgAC0bdsWO3bskNeNHTsW48ePx7Bhw6DRaPDRRx/BZDJh9uzZqF+/PoKDgzFw4EDcuHFD3icpKQmjRo1CnTp1oNVq0aVLF+Tl5QEAXnrpJcTGxsLf3x9NmzbF+vXr5f3S0tIwaNAgBAYGQqvVol27drh8+TKmTp2Kffv2Yfr06fDz80Pfvn2L9CElJQUXL17E008/DR8fHyiVSjRr1gxDhw4FAAwfPhxXrlzBo48+Cj8/PzzzzDOltmf37t3QarX48MMPERMTgw4dOuCee+4BAERHR8PPzw+rV6+uwFeCiIiIiIiqi4LyCIIA+FnVtA3yvZO0Tc+tmKStJEnySNsgH0+bJLE93moVgv9py/UMNx75JorA77/D++gxCKL9PqoUCugtFoiSWIWNo7LKNhlg4mtF5DQmbSuCXm//p/Cng2XdtgJcuHABDz30EGbNmoXU1FTMnDkTAwcOxKVLl+Rt1qxZg/HjxyMjIwPjx4/Hyy+/jF9++QX79+/HzZs30ahRI4wYMQIAIIoiBgwYAJVKhdOnTyMlJQVvvPEGFIr8sGrVqhUOHz6MjIwMzJ49G6NHj5bP9fbbb8NsNuP69etITU3FsmXL4O/vj3feeQedO3eWRwr/8MMPRfoRHByMxo0bY9y4cfj6669x+fJlm/Vff/01YmJisGbNGmRnZ+Ojjz4qtT0AkJWVhWPHjuGvv/7Cnj178NtvvwEArl27huzsbIwcObJCXgeqPgRBgLe3NwurU4kYJ+Qoxgo5g/FCzmC8VD7dPyNt/T3VUFhdZ+vyCOl5FZO0TcnRI9eY/1XxGAdG2RaI/Gcyslyj2aYGL1D7YkQtKGGGCCMnI3OKK+JEkiSkmfKq7HxUcWrbfaU6Urm6AW7hnxGexbr7bmDOnDvPR40CDHZ+2TdvDixYcOf5+PGATpf/ePNmp5o0Y8YMzJ07V35+/fp1rFu3Dt26dcPgwYMBAI888gg++eQTrFmzBjNnzgQA9O7dG3369AEAeHt7Y+nSpfjll19Qp04dAMD8+fPh6+uLq1ev4saNGzhz5gz27t0Lb29vAECnTp3kc1onOUeMGIE333wTBw4cQL169aBWq5Gamorz58+jVatWaN26tcN9EwQBu3fvxltvvYV58+bhr7/+QuPGjbFkyRLcf//9dm8oJbUHyE9Cv/nmm/Dx8Sl2f3I/giAgICDA1c2gao5xQo5irJAzGC/kDMZL5ZIkSU7aarxtR70GVkJ5BOt6tnEO1LMtEKX1xYkbaQCA65k50Fq1rbbFiFqhQJYpP2nrpVSXvgMBcE2c6C1m5JqNUDLxV+PUtvtKdcSRtm5qwYIFyMjIkH98fX1x7do1xMXF2WwXHx+Pa9euyc9jYmLkxykpKcjJyUGXLl2g1Wqh1WoREREBDw8PXL16FZcvX0ZUVJScsC3sP//5D5o1a4aAgABotVqcPHkSKSkpAIBp06ahc+fOGDZsGCIiIjBp0iS5rIIjIiIi8M477+DUqVNITk5G3759MWjQIKSmpkIUi//aRUntAQB/f39otVqH20A1nyRJyMzMdN+vl1GFYJyQoxgr5AzGCzmD8VK58kwWmCz51zagUKkCrbf1RGQVlbR1rp5tgZImI6ttMaISFDBJFo60dZIr4iTXYoLeYoaXgmMGa5radl+pjviuqQhWtVGLUBTKi3/5pePbLltW9jYVIzo6Gvv377dZlpiYiC5dulg14U4bgoOD4ePjg19//RVNmjQpcrxff/0V169fh16vh5eXl826/fv3Y+7cudi5cyfatGkDhUKB1q1by292Pz8/LFy4EAsXLsSlS5cwYMAALF26FFOnTrVpgyOCgoIwd+5cLF68GJcuXYJWqy1yjNLaU7jvxT0n9yNJEvLy8uDv78+vfJBdjBNyFGOFnMF4IWcwXiqXzmYSMttRm2qlAhovNXR6U4XVtLUeaRvrzEjbEiYjq20xIggCJAlM2jrJFXGSYzZClKRaEZfuprbdV6ojZqUqgpeX/R8Pj4rZtgIMHz4cu3fvxrfffguz2YwNGzZg7969co3awhQKBZ555hlMnToVV69eBQCkpqZi3bp1AID27dujcePGmDBhAjIyMmA2m7F//34YDAbodDoolUqEhoZCFEUsX74cJ0+elI+9ZcsWnDt3DqIoQqPRQK1WQ6XK/wwhPDwcFy9etNuP9PR0vPLKK/jrr79gsViQm5uLxYsXIygoSE4uFz5Gae0pTmhoKBQKRYltISIiIiKims06aRvgXXRSsIISCem5BogVMOIsMTV/pK2nSoFwTfHfWiyO9Ujb64VG2tZGAgCjhUnb6i7LZICKA6KIyoTvnFqkQYMG2LBhA+bMmYOgoCC8+uqr2LhxI+Lj4+3us2DBAiQkJKBHjx7w9/dHu3btsH37dgD5Sd3NmzcjNzcXjRs3RkhICF555RWIoogHHngAjzzyCFq0aIHIyEicOnUKHTt2lI974cIFPPDAA/D390fTpk2RkJCAZ599FgAwefJk7NixA1qtFg8++GCRNnl4eOD69evo168fAgICEBMTg19++QU//PADfH3z/5CZMWMG3n//fWi1WkyYMKHU9hTH29sbc+bMQd++faHVavHVV185fc2JiIiIiKh6s57US+NVNGkb9E/SVpSALL2pXOfKNZqRnJ0/0XTdQD+bSc9Ko/HygP8/I4GZtM0fbWsUza5uBpVAkiSkGfPgqWDdYaKyECQWpyhCp9MhICAAmZmZ0Gg08vK8vDycP38eDRs2tFvHlVxLkiRI/3z1gsP3K467xr4kScjOzoafnx/jhexinJCjGCvkDMYLOYPxUrl2nL2OZQf+AgA82bEJejSKsln/2YEz+PnsDQDAGwPbo16wpsgxHHUmKR2v/nAEANCrcRTGdyhahq4k877/A3/dyshv12Nd4OuZnwxztxg5ln4TN/KyEO5lv+bvbX02Irz80DoosgpbVrNVdZzkmo3Yn3wZvkoPpBpz0VQTigaakEo/L1UMd7uvVCf28o6FlWuk7eHDhzFp0iT07t0bnTp1gl6vxxdffIEvvvgCWVlZpR+AqIIJggCFQsEbCjlEEATW56FSMU7IUYwVcgbjhZzBeKlcNuURihlpW1AeAQDScspX1/ZKulU922DH69kWiNLeqWt7PfPOaNvaGCMqQYEcS/lGPtc2VR0nuRYTDBYLPJWcTqkmqo33leqmzO+cGTNmYNGiRQAgj2z08vLC22+/jVOnTkGSJIwZM6bCGkrkCI60JWdIkoT09HQEBgYyXsguxgk5irFCzmC8kDMYL5VLV0p5BOukbXknIyuoZwsAsYH2R5HaExVwp67tjcxcNArTAqidMaJSKGG0WGAWLVAplK5uTo1Q1XGSYzZBhOhUGRCqPmrjfaW6KdNI29WrV2PhwoVygszawIEDIUkSvvnmmwppIJGzWPGDHCVJEoxGI2OGSsQ4IUcxVsgZjBdyBuOlclmPtNUUMxFZkPVI23ImbS+n5Y+0FZBf09ZZ9iYjc5sYMRqBN99E2LvvQTAaS9xULShgkiwwiWIVNa7mq+o40Zn0UAlMqNdUbnNfqcHKlLR97733AABNmjTBq6++arPurrvuAgCcPn26nE0jIiIiIiIiqlyZVpOLabyKTpgUWEFJW4so4VpGftI2IsAHXmrnk1n2krZuQxSBX36Bz6+HIYglJ4rUCgXMogijaKmixpEzRElEhkEPL5ZGICqzMr17Tp48CUEQ8PrrryMsLMxmXZ06dQAAN2/eLH/riIiIiIiIiCpRQXkED6UCXqqiidQgHy/5cXnKI9zMzIHJkp+IjA1yfpRtfls84aVWQm+y2NS0rY2UggJmiUlbk2iBuhqWh8izmJErGuGv8ix9YyIqVrkmIlMqi94Yrl27BgBQq4t+QukuRH79olpjrZWK564xLwgCNBoNY4ZKxDghRzFWyBmMF3IG46VyZf5THkHj7VHsNfbzVEGtzF9enpG2BaURACA2yPlJyID8WIgMyJ+MLDlLD6PZIi+vbTGS31epVidtk/U5+DPtBgwWs0PbV2Wc5Jr/mYRMwZG2NVVtvK9UN2V69zRp0gR//vknFi5ciClTpsjLL1++jEWLFkEQBLlMgjvx8Mj/JX779m2EhYVBoShXzpuo2iuoYXPz5k0oFAp4errXp6SCIMDHx6f0DalWY5yQoxgr5AzGCzmD8VJ5LKKE7H/KIxRXGgHIv/5ab08kZ+vLNdI2Mc1qErIyjrQF8icj+zslCxLyJyOLC/av1TFSW5O2RosZ57NScNuQgxijFhHepX8QUJVxkmM2ypOEU81Um+8r1UWZkraPPfYYjhw5gkOHDmHYsGHymzA+Pl7eZtSoURXTwmpEqVQiLi4OiYmJyMrKKn0HqnLWBbL5y6Hi+Pr6Ijo62u0+qBBFEWlpaQgKCnK7vlHFYZyQoxgr5AzGCzmD8VJ5sg0mFPwPIsCr6CRkBYJ885O2OQYzjGYLPIopo1CaihhpCxSqa5uZg7hg/1obIwooYBRNpW/ohhJz0nFLnw0FBKQZch1K2lZlnOhM+mpZtoEcV1vvK9VJmZK2zz//PL7//nvs3LkTwJ3kWEHCrFevXnj22WcrqInVi7+/P5o2bQpjKTNZkmvwplLxVCoVVCqV2ybBzWbHvkpEtRvjhBzFWCFnMF7IGYyXypGZd+f/dRrvEpK2VpORpecaEK5xbvSZJEm4/M9IW42XGoElnKs09iYjq40xolIokGOufUnbVEMuLmanI9jDBxZJwi19Dho6WNu2KuJElESkG/M4CZkbqI33leqkTO8glUqFH3/8Ee+++y5Wr16Nc+fOAQAaNWqEkSNHYtKkSW6dMFMqlfD29nZ1M6gYoihCrVbD29vbrWOQiIiIiIjKr6CeLVDySFutVdI2rQxJ24w8I9JyDDCJIhqElK9GZFSA7Ujb2kwlKGtd0tYkWnA+KwWiJMJP7QmzKOKWPhsZRj1CvXxLP0AVyDWbkGcxQ6P2Kn1jIrKrzB97qFQqvPjii3jxxRcrsj1EREREREREVUJnnbR1cKRtWSYj23jsEhLTsiBKEjLzjNh17ga6N4p0+jgAEObvDZVCgFmUcCMjt0zHqLY8PYH163E5/SZEsfRvt6oVCphEC0wOjjJ1B5dzMpCUl41Ibw2A/NHGEiSkG3OrT9LWYoJRtMCzlrwmRJWFQxHJrQiCgMDAQLf9Kj9VLMYLOYJxQo5irJAzGC/kDMZL5dFZl0ewMxEZULQ8gjNSc/RYffgCREmCUhBgEUUs2X0CqTl65xsMQKkQEBGQP9L3pi4XFlFynxgRBMDLC5KXV/7jUqgVCpgkS62ZjCzdmIeL2anQenhDZfXNUh+lB5LysmERxRL3r6o4yTGbOAmZG3Cb+0oN5tBIW+sJxhwlCAIuXrzo9H5E5SEIAjw9PUvfkAiMF3IM44QcxVghZzBeyBmMl8qj09/5ar2mhPIIgeUYaZuky0WuyQylIEAQBGh9PJFrNOOWLg/BvmX7+nhUgC+upefAIkq4lZWLyADfWhkjHgoVjJY85FlM8FWVvU5wTWAWLTivS4HJIiK00Gvtr/ZAsj4HmSY9gjztl+6oqntJpjEPHqxnW+Pxd4/rOfQuSkxMdCqzzk9UyFVEUURycjJCQ0NZ05ZKxXghRzBOyFGMFXIG44WcwXipPNY1bUtK2gZZJVedHWkb4e8NSZJgkSSoBAG5RjP8PNUI15R9npTCk5FF+Hu7R4yYTMAHHyAkV4ebI4cApeS0FYIACRJyzSbAzXNLV3IycSMvC5He/kXWqRVKWP6Z/KukpG1V3EssoogMkx5eCiZtazr+7nE9h6+6JEkO/xC5EmOQnMF4IUcwTshRjBVyBuOFnMF4qRyZeY7VtA20WpeW41zSVoKAEF8vKAQBggD4eaoxqVuLMo+yBYCogDuJueuZ+XVt3SJGLBbg55/ht3cfBEvJX/UvoBQE6ExlKzVRU2T8UxYhQO0FlZ06sT4qDyTpsyFKJV+3yo6TXEv+JGReHGnrFtzivlKDOfQuEkupi0JERERERERU01hPROZfQk1bD5USvp4q5BjMTo+0PXc7A/5eHvBWq9CpfgRG3dOwXAlboOhI29rMU6FGulHvtt/4tYgiLmSlQm+xIMrH/kRjfioPZBj10JkM0HqUfRR3eeVaTDBazPDw5CRkROXF8c1ERERERERUKxWMtPX1VNlM7FScgsnIMvIMTo0+u5CiAwColAp0aVin3AlbAIgM8JXn6artSVsvpQp6iwl6i9nVTakU1/J0uJ6XhTAv+wlbAPBUqmAUzcgwunbUcY7ZCEGAWybQiapamZO2JpMJH3zwAe6//37Ur18f9evXx/33348PPvgARqOx9AMQVQJBEBAcHMxfEOQQxgs5gnFCjmKskDMYL+QMxkvlKRhpG1BCPdsCQT75yVaTRUKWwVTK1necv50pP24QEuBkC4unVioQ5pc/mvJGZg4koNbGSH7S1oxci+OvSU2hM+lxPisF/ioPqO2URbDmqVThlj7b7ocKVXEvyTDmwYP1bN0Cf/e4XpneScnJyejduzeOHz9uszwxMRE7d+7Ep59+ip9++gmhoaEV0kgiRwmCAKVSyZsKOYTx4n5Sc/RI0uUiQuNTIaNYAMYJOY6xQs5gvJAzGC+VQ2+ywGDOLwVYUj3bAlof27q2JU1cVsBkEZGYmgUAiNB4l1iCwVlRWh9cz8hBnsmMv1OyUD/Ev1bGiEIQIEn5k5EFu9FkZKKUXxYh12xCtI9jyX5/lScyTHnINhvhry56MSr7XmIWLcg0GuDJerZugb97XK9MI21feOEFHDt2zO5EZCdOnMALL7xQ0W0lKpUoirh9+zbrMJNDGC/uZde5GxizaheeX38A41fvwa5zNyrkuIwTchRjhZzBeCFnMF4qh6P1bAsUlEcA8kskOCIxNQtmMX/UY6OwihllWyDHYEZiWhaupmfj3+v3Y9PhM7U2RhSCAlluNhnZ9dwsXM3JRJiXn8P7eKvUyDPbL5FQ2feS3H/KVHgrK+7DCXId/u5xvTIlbbds2QJBEBASEoJPP/0Ux44dw/Hjx/HJJ58gLCwMkiRhy5YtTh/3ww8/RMuWLaHRaKDRaJCQkIAffvhBXq/X6/Hcc88hODgYfn5+GDJkCG7dumVzjCtXrqB///7w8fFBWFgYpk2bBrPZPWvbEBFRvtQcPd7ZeQw3M3ORpTciI8+AJbtPIDXHvf54JyIioopjnbTVepc+RDPI6ls8aQ5ORnY++U5phIahFZe0Tc3R45dLtyBKEpSCgCy9Ccv/SERaLf3bx0upQrpJ7zYz3WebDDiflQJflSc8HCiLYM1DocRtQ1YltaxkuWYTjJLF6TYTUfHKNGa9YGj0O++8g9GjR8vLmzdvDk9PT4wZMwaKUoq4Fyc6OhpvvvkmGjZsCEmS8Pnnn+Ohhx7Cn3/+iWbNmuGFF17A1q1bsX79egQEBGDixIkYPHgwfvnlFwCAxWJB//79ERERgQMHDuDmzZt4/PHHoVar8cYbb5Slq0REVAMk6XKRpTdBKQgQBAFqpQK5RjNu6fIqrEwCERERuRfrpK3GoZG2tuURHGGdtG1QgUnbJF0uRFGS//YxiSKyDGYkZeUhxN+nws5T5Tw9gS+/xJWMJIhOZCs8lSrkWkwwiGZ4ucEoz4vZacgyGRwui2DNX+2JNEMecs1G+KhKL+FRkbLNRvCL9EQVp0wjbfv16wcA8PEp+svA2zu/GPrAgQOdPu6AAQPQr18/NGzYEI0aNcLrr78OPz8/HDp0CJmZmVi2bBkWL16MHj16oF27dlixYgUOHDiAQ4cOAQC2b9+O06dP48svv0Tr1q3Rt29fvPbaa5wcjYjIzUVofKBWKmD5p0xPjsEMHw8VwjXerm4aERERVVM6/Z2JqxyZiCzQqjxCuqMjbf+ZhMxTpUDdQMe/5l6aCI0P/L3UUKsUkCQJFlFCnskClaKGp8wEAQgIgKjR5D92kJdSBb3ZjFxzzZ+MLM9swm1DDoI8fcpUS9RHqUaOxYQMF5SLyJ+EjKNsiSpKmUba/uc//8GRI0fwf//3fwgKCsI999wDAPjtt98wY8YMtGrVCosXLy5XwywWC9avX4+cnBwkJCTgjz/+gMlkQq9eveRtmjRpgpiYGBw8eBD33XcfDh48iBYtWiA8PFzepk+fPnj22Wdx6tQptGnTpthzGQwGGAx3funqdDoA+fU7Cmp3CP98gllQt7dAacsL1/5wdrlCoShybGeXl7XtNbVPYWFhRc5b0/vkjq9TdelTSEiI2/XJ2eXu0KcgH0/0aBSJjccSYZEk+CgVmNStBYJ8PJ26FxS3XKFQICQkBACK/E7g68Q+FV4eGhpaoX2tDn1yx9epuvSp4N4CwG36VJa2s0+lLxcEweZ3kTv0qTq8Thly4lWCn6eq1P/7BcolFCSk5uhL3T4914DUHAMkSIgP9ocACaIoVUifAr09MKlbCyzZfQJJulxIIhDq542Vv57Hq/3vhlqpqPGvk/X6grYUVrBcAQGiJCLbaECgh3e17VNpywVBQIZJj1yjAYE+XkXWlXQNrKkgIEWfiwhPvyLbhoWFAYBN+yuiTybRgiyTEZ4KVZHt5esuSsyx1LA+lfVv2+rcp+rwOjlaJ7hMSds6derIj62TqNZCQ0NtnguC4FBt2RMnTiAhIQF6vR5+fn7YuHEjmjZtiqNHj8LDwwNardZm+/DwcCQlJQEAkpKSbBK2BesL1tmzYMECzJs3r8jy5ORk6PX5n055e3sjICAAOp0OeXl58ja+vr7w9/dHenq6zWhejUYDHx8fpKWl2fQ7MDAQnp6eSE5OtgmC4OBgKJVK3L5926YNYWFhsFgsSE1NlZcJgoDw8HAYjUakp6fLy1UqFUJCQpCXlycnngHAw8MDQUFByM7ORk5OjrzcHfvk5eUFX19f5OTkyK9dTe+TO75O1aVPBTfLyMhIt+kT4H6vk6N9ClYDURovmEUJbaOC0L1RJLKyssrdJ29vb6SkpECS8v+TxdeJfbLXJ0mSoFQqERoa6jZ9AtzvdaoufZIkCRaLBUqlEuHh4W7RJ3d8napLn9LS0pCXlyfP4u0OfaoOr9PN1AwA+ckrS242Cg5lr0+eXl5QKgQYTWbcTNfJ57bXp3OZ+Y8tZjMivBXy9hXVp+6NItEk1A8nL9/A2uPXkJFnwsXb6fj0wF8Y2y4OWVl36prWmNcpKAjmjz6CJi0ZNx7uD72PBYJSAS+tBhaDEaacO21UqFXw1PjBnKeHOc8AwZCLW4ZbCBAV1atPTr6f0hQmKIwWGAx3lis9PeDh5wNTTh4shjttV3l7Qu3jDWNWDkTTnbb7eiqRbMhBUnIyFFZt12q1UCqVNm2sqD7pJRF5oglaqKDPulMWpOB1gsGEbFM6bustAKph7NWS+54zfZIkSV7uLn0CqsfrZH1/LokgFfdRTSkUCoX8H1d7n6AUOZEgwGKxlHpso9GIK1euIDMzE//73//w2WefYc+ePTh69CjGjRtnMyIWAO655x50794dCxcuxFNPPYXLly9j27Zt8vrc3Fz4+vri+++/R9++fYs9Z3EjbevWrYv09HRoNBq5/a7OxJd1eXX+dKGi+yRJEpKTkxEaGirHaE3vkzu+TtWlT6IoIjk5GeHh4cXeu2pin8qy3F36tOzgX9hx9joAoGlEIGb3bVchfZIkCbdu3ZI/Za7KPrnj6+TOfSrpnlJT+1SetrNPJS8viJfQ0FCoVCq36FNZ284+lb7cYrHg9u3b8u8id+hTdXidPth7Cgcu3QYg4e1B96GOxqfUNv57/S9IzdHD39MDH43oVOL2X/1+AVtPXYUECVN7tES7uiGV1qfLqVl4+btfIQr58THm3obo3STa4etebV4noxHS0KHQmfQ4+ME7CNUGy8cpvG3h5amGXPip1EgIja1efXJiuVkS8UvyFUiShAAP23kZHLkGBURJwk19FtoHRiLc219eLkn5/18u+LZhRfYpKS8Lh9OvI9o7oNg2Xs3JQFP/UNTX3HlNa+rrVGPeT+XsU3n+tq2ufSrP8orsk06nQ2BgIDIzM+W8Y3HKNNI2JiYGglA5tXI8PDzQoEEDAEC7du1w+PBhLFmyBMOHD4fRaERGRobNaNtbt24hIiICABAREYHffvvN5ni3bt2S19nj6ekJT8+is4UqFAqbGxlw5+IXZm954f3LstzZc1b28urcJ+uvWjhz3urcp7IuZ58c61PBY3fqk6uXu6pPepMFwj9TH+QazWU+TuHlkiTJ95TCbeXrxD5V9j2lOvSpopezT3eWW/+94i59qg5td+c+Ff5d5A59Kk/b7S139JxZhoIRUwK03p4O/d8v0McTqTkGZBlMsEiAWlk08VXgQorun6MLaBSmrdS/I2KD/TGqTQy+OHYNAPDFb+cRG+SPuyICnTqOo8sr9XWys764ba2Xe6vUyBXNMIoWeCpV1atPDi7XGfKQbTYg3Mvf7vbFKbxcKeT/VZxu0qOO750kasH/l4v7u7a8fcq1mACp5DYKiqL/T6+Jr1NFL6/OfSp47E59KuvyiuyTvX0KK1PSNjExsSy7lYkoijAYDGjXrh3UajV+/vlnDBkyBABw9uxZXLlyBQkJCQCAhIQEvP7667h9+7Zcp+Wnn36CRqNB06ZNq6zNRERU9fJMd77NkW2o+ZNQEBERUeXS6fO//qpUCPDxcOy/xkGFJiML8y9+0lOTRcTf/yRtw/y9EOBd+kRn5dU2Uot0ixJbTl6BJAHv7jqBNwbeg2Bfr9J3dgOeChUyjXrkmI3wVJYp1eFyGUY9JEhQOZjQKYmfyhO39DloKFqgroLJwdKMefBSqiv9PES1SfnvBBVoxowZ2Lt3LxITE3HixAnMmDEDu3fvxsiRIxEQEIDx48djypQp2LVrF/744w+MGzcOCQkJuO+++wAAvXv3RtOmTTF69GgcO3YM27ZtwyuvvILnnnuu2JG05J7sfbJHVBzGi/vIs6rjlWMsvYa6Mxgn5CjGCjmD8ULOYLxUvIy8/KRtgJeHw9c3yPfO/ysz8gx2t7uSno3/Z+++49yoz8SPf2bU6/bibuNCtQFTHUroJIFcCpc70iCEHL9wKRBySUjCkUsllZQ7crm7EJJLIMmRHkIvtunVGBtww93bm3qf7+8P7Wole4tGq92V5Of9evFidzQafcd6dkZ65pnnm8pkb69d3nLo7eLTQdM0/nH1Eayc2whAMJ7i+49uIpUpbsKbamfVdTIY2YrPKmQog+54GJelPAl+j9VOOJ1kKBkvWD4dx5JkJk0oncRZpclyMT4598yukpO26XSa73znO6xevRqv14vX62X16tV897vfLWrCsbH09PRwxRVXcOSRR3L++efz/PPP88ADD3DhhRcC8P3vf59LL72Uyy67jLPPPpv29nb+8Ic/5J5vsVi45557sFgsrFmzhg984ANcccUVfOUrXyl1N0WV0XWdtra2okvNxeFN4qW2xPIStfFUhnSRM3JORuJEFEtiRZgh8SLMkHgpP0OpXKWt31l8dWCje7RqdSAyftJ2e08g9/Py1ulP2o7EiNVi4RNvPo4Wb3acb/QFuf3pLWP2Qq1FOhqR9PjvSyULpZIEkwm81vIkba26jkIxmIzmlk3XsSSaSRHPpHFJ0ramyLln9pX0F5VKpbjoootYv349MDoZ2caNG9m4cSP33nsvDzzwADabudL422+/fcLHnU4nt912G7fddtu46yxatIh7773X1OuK2qGUIplMYrcXf7VcHL4kXmpLfnsEgGgijb8MtyJKnIhiSawIMyRehBkSL+UXSaQZyWPWuYq/K7M+77PFQHT85OCO3tGk7bIZqLTNjxGf08YN563iS397gWTGYN32TpY1+7kgb2KyWuWwWBk8qLK0Wgyl4iSNdFlbO3isdrpiYZZ6m7AMT4I02bEkZWQ4EA1Sb3dSbx+7/cfBIukUacPAOgNtGMTMkXPP7CspXX7rrbeybt26Q2ZUG/l93bp1/OAHPyjXGIUomlKKwcHBw+ZKspgaiZfakt8eASCcLM+tcRInolgSK8IMiRdhhsRL+QWGq2zBZKWtp7Cn7Xi2DVfa2iwaixq9JYzQnINjZHGTj2vOODr3+M+f3cbze3p4tXOA/kh1JjWL4dStRNIpEpnytsqaCT2xcNl78XqtdoKpBIFU9j2f7FgSTiXYONjJhoEOXhg4wIFosKjjTiSdQHJ6tUfOPbOvpKTtr3/9ayBb1frXv/6V7u5uenp6+Mtf/sLixYtRSnHnnXeWdaBCCCHERA5O2kYS1fdhXQghhBAzI5SXtDUzSVh+e4TxkraBWJLecDZJdkSzvyyTSpXijKXtvO3YBQAMRRN84u4nue53T3H1net4bFvHrIxpUg4H3H47+390K4bD/B1TTouVWDpVdX1to+kkQ6kYnjK1Rhhh0y0YSjGYjE26bk88zIsDHXTEQsxz+1EKNgx0sD3UR2aStmODybj0sxViGpR09ti+fTuapvGtb32LSy65hJaWFpqbm7n00kv55je/mVtHCCGEmAmpjJGb7GNEuSpthRBCCFF7ArH8StviE2X17snbI+S3RpipScjG876Tl3NEs5/uUIxUxiCRyhBOpPjh2k2VWXGradDaSrqlmVJKN626hYwyiKar63PgUCpOJJPCbTHXYrIYLquNrngYQ42deM0YBm+E+nlxoINYJsU8lx+rbqHJ4abO7uTVQC+bhrqIjfNvmsikCaUTOHVJ2gpRbiUlbSfqZTFSNi39LsRssVrlZCGKJ/FSGw6usgWIJMr3YV3iRBRLYkWYIfEizJB4Ka9S2yO4bFZctmzfzvGSttt6Zraf7YixYsSia7xj5aLsz5pGMmPgslmJJtN0ByevvqxGmqYRTScnX7GCDCSiWNGnJY/itdoJJhMEU9l4zY+TeCbF5kA3m4a6cVlstDq9BWPwWO3McfnYHRnipcGOMSt2o5kU8XQa5zQknMXsk3PP7Copabt8+XKUUnz2s5/lvvvuo7+/n/7+fu677z5uvPFGNE1j+fLl5R6rEJPSdZ3m5maZ3VAUReKldhw8CRlAJFme9ggSJ6JYEivCDIkXYYbES/kF46MXd820R4DRvraDkcSYvR6351fats5M0naiGFna4sfvtJMZnoMmEEvitltp8xc3ydSMSqfhZz+j8Ve/RkuX9lnOoVsZKKIdQKVIZtL0xqN4bOVtjTDCYbGSNNIMJeMFcTKYjPHSQAe7woO0Ob34bWNPyGfXLcx31zGUiPHiGH1uI+kkBsastQER00fOPbOvpH/5yy+/HIB9+/Zx6aWX0traSmtrK5deeil79uwB4H3ve1/5RilEkZRSRKNRaZQtiiLxUjtiYyRow2WqtJU4EcWSWBFmSLwIMyReyi9YYnsEgAZXNrmVzBiHXCTOGIo3+oIANHkcNLrHToSV20Qx0uRx8t6TlqJrGhmlsFo0rjtnJU0e5xhbmmXpNPzxj/j/dh9a+tCL8sVwWqyE00mSVTIZWSCVIJxO4i1zP9t8DouV7ngYwzCIRCLsiwzxwsABBhMx5rvrJp0ATdc05rj9oOCl4T63aSP7/kTSCTTkTutaJOee2VdS0vaGG27grLPOQg1fqcv/D+Css87i+uuvL+c4hSiKUopgsLgZLoWQeKkdY7ZHKFOlrcSJKJbEijBD4kWYIfFSfsESJyKD0UpbyE7wlW/fYJhkOts7dKaqbGHyGLl05SIWN/pY0ODlgiPnce6KuTM2tpnmtFiJZ9JVMxlZIBlDobBo01fN6LM6GEzGGExEea1zHxsGO9FUNhGrm2jJ0OhwU2938lqgl81D3cTSKQYSMWmNUKPk3DP7Sjoq2Gw2HnroIW655RZWrVqF0+nE6XSyatUqvvnNb/Lggw9is8kfrRBCiJkx3T1thRBCCFFbCnvamqy0zauePbiv7fYKmoQsX6vPhctuwWWz0h8ZuxdvrbDpFlJGpiqStoYy6IyFp2UCsnwuq42EkWZruJ8DsSANNheNjtLaY3isdtqH+9y+OHCAcCaFc5JKXSFEaUr+y7Lb7Xzuc5/jc5/7XDnHI4QQQpgWSx56+1w4UR23xAkhhBBi5gWG2yO4bBZsFnO1TBMmbXsqM2mraxpz6zzsGQjTGYySyhim97uaaEA0lYQKbNubL5hKEEonaHS4p/21PBY7/YkojQ4XbuvUksQjfW67YyESRpp6T315BimEKDDlyyEbNmzg9ddfJxqN8pGPfKQcYxKiZJqmYbfbp2XWTVF7JF5qx9jtEcpTXSFxIoolsSLMkHgRZki8lN9IewS/ydYIQEGf2vEqba26xuIm3xRGaE4xMTK3zs2egTBKQXcwyvwG74yNb6Y5LNUxGdlQMk7KyGDXLdP+Wo0ON0opkulIWbY30ufWUMpUiwVRPeTcM/tKvrT2wgsvsHLlSk4++WQ++MEP8tGPfpR4PE5jYyNWq5W1a9eWcZhCFEfTNBobG+WgIooi8VI7YqlDK20jZaq0lTgRxZJYEWZIvAgzJF7KK5UxiA7fpVNnsjUCQGPeBF6DeUnbUDxFVzCbKFzc5JvRStZiYmR+/WiS9kCgPIm7SuW02Aink6SM0iYzmwlKKbrj4UknASsnTdNw+L1lPZZIwrZ2ybln9pV0FtmyZQvnnXcer732WsEkZE6nk3e+850YhsHdd99d7rEKMSmlFKFQSBpli6JIvNSO6BiTjoXL1NNW4kQUS2JFmCHxIsyQeCmvqUxCBge1R8jrD7ujL681wgxOQgbFxci8ek/u5/1DtZ60HZ6MLF25fW2jmRSBVByv1TH5ymWilCIVjcmxRBRFzj2zr6Sk7b/9278RDofRdZ01a9YUPHbaaacB8MQTT0x9dEKYpJQiEonIQUUUReKldkxnewSJE1EsiRVhhsSLMEPipbyCBZOQme/tWee0M1J4ll9pO5v9bIuJkXl1o31TD8xC0rY/EufVzgH6I/HxV3I44LbbOPCdb2A4zCfUR9h1C0lV2ZORDSXjRNMpXDM8iVc6VtsT0YnykXPP7Cvp6PDYY4+haRq33HILa9as4ayzzso9tnjxYgD2799flgEKIYQQk8lP2vqdNoLxFKmMIpnOYLdOf48wIYQQQlSPkUnIAPwltEew6Br1LjuD0WRBT9tKnYRsRJvfja6BoeDAUHRGX/sPL+/i+4+9goZGo8fBdees5NwVcw9dUdNg4UJSgzaIhab0mjoakXRy8hVnSX8iik3X5dZzIcS4Sqq0DQSyJ6MTTzzxkMdSqeyVrGh0Zk8CQgghDl/5PW2bvaN95sJjtE0QQgghxOEtGB+tviylPQKMtkgIxpJkDIWhFDv6gsOP2WnyzNwt78WyWXTmDFfbdgYjGDNUPdcfjvG9R18hmkwTT6UJxZP8cO2miStuy8CuWxiq0MnIEpk0vYkInhlsjSCEqD4lJW3b29sBePDBBw95bKSX7fz586cwLCFKo2kaLpdLrlaKoki81I5YXnK2xevK/RwtQ19biRNRLIkVYYbEizBD4qW8plppC9A4nLRVwFAswYGhCPHhi8jLW+pm/L0qNkbm1WX72qYyip7QzCQ0n9rVQzyVxqJp2XHarESTabqDY7x+Og133UX97/6Alp7axXeHxUoolSRdgZORBVJxIukkHqv59hxTZZlC2wlxeJFzz+wrKWl74YUXopTiu9/9Lp/85Cdzy8877zx++ctfomkaF110UdkGKUSxNE2jrm7mPySJ6iTxUjuiw+0RNKAxr7IlVKakrcSJKIbEijBD4kWYIfFSXgUTkZWYtC2YjCyaYHvvaGuEZbPQGqHYGMmfjGym+to+v6cHXdPIDE9gHowncduttPldh66cTsOvf0397/+Elp5astWpD09GVoF9bQeT2TuTLVpJKZmSaZqG3euWY4koipx7Zl9JR4gvfvGL1NfXo5Ti5Zdfzr2B69atA6C+vp4bb7yxfKMUokhKKQKBgDTKFkWReKkdI+0RXHYLXsdoxUK0DO0RJE5EsSRWhBkSL8IMiZfymupEZHBQ0jaSYFt+P9vWmU/aFhsj+Unb/TOQtH2jL8j23iBtPlcucWuz6Fx3zkqaPM7JNzAFDouVhJEmmq6spG3GMOiORfBYZ77iVSlFMhyVY4koipx7Zl9JSdvFixfz8MMPc+yxx6KGr5aN/Hfcccfx8MMPs2DBgnKPVYhJKaWIxWJyUBFFkXipHSPtEVw2K1776JevclTaSpyIYkmsCDMkXoQZEi/lFYiNfj7wl9jTtjEvaTsYTfBGb7afra7BEU2+qQ2wBMXGyEh7BJiZSts/bdwFgM9pZ3GjjwUNXt52zMKxJyGbBrpGxVXaBtMJQukk3llI2gJkEpU7OZuoLHLumX3WUp+4evVqNm3axMaNG9m2bRsAK1as4Pjjjy/b4IQQQohixFKjSVuPY/TUVo5KWyGEEELUlpFKW02j4A4dMxrzqkQPDEVyVauLm3zYrZapD3KazK1zo5HtxXsgML1J2/2DYV7Y2wdkK5qD8RRWiz6jE8XadGvFTUY2lIyTVhlseuXGiRCiMphO2qbTaV599VWSySRHHXUUxx9/vCRqhRBCzBpDKRJpAwCX3YrHPnpqC5eh0lYIIYQQtWUkaetz2NBL7NXYkFeh+8Le3tzPs9HP1gy71UKrz0V3KMaBoQiGUiX/G0zmz5v25H5+x6rF/HHjLsKJ9IxNgAbZvraBZIKMYWDRZ7Z/7FiUUnTHQzj1mZ+ATAhRfUwdtX75y1/S3t7O6tWrOf3002lubuYzn/mMlEqLiqFpGh6PRxpli6JIvNSGWF61hstW2NM2UoZKDokTUSyJFWGGxIswQ+KlfJRSBGLZpG29yzHJ2uPLr7Qdio3ebr5ilpK2ZmJkXr0bgETaYCCSmJbxdIdiPLmzCwCvw8p5K+bR6stOPDYYTZDKGNPyugdzWKzEjcqZjCycTjKUjM9aawQA6xTiXhxe5Nwz+4pO2q5bt44PfehDDA4O5pK0qVSKW2+9la9//evTNkAhzNA0DZ/PJwcVURSJl9owMgkZDLdHyOtpGylDpa3EiSiWxIowQ+JFmCHxUj6xVIa0kf0+W+okZJC9UOywHvp1etksTEIG5mJkbl3+ZGThaRnPPZv2MFLb9dZjF+K0WWjxZpO2CugLx6fldQ/m0C0kM5WTtA2k4iQyaVzW2am01TQNm9slxxJRFDn3zL6ik7bf+973cpONAQX//8EPfiDVtqIiKKUYGBiQeBRFkXipDSP9bOHQSttwYuqVthInolgSK8IMiRdhhsRL+QTyqmLrSpyEDLLJjAZ3YcWi32mj1esc5xnTy0yMzK/Pn4wsWvaxDEQTrN3eAYDTZuGio+YD0JL3b9MbHqdFgt0Ot95Kx9f+DcM+9cTmSLIpmq6MpG1fPIJ1FnvZKqVIBMNyLBFFkXPP7Cs6afvss8+iaRpnnnkmu3fvZnBwkGuvvRaAwcFBduzYMW2DFKJYSimSyaQcVERRJF5qQ0HS1l44EVkkOfUP6BInolgSK8IMiRdhhsRL+Yz0swXwTyFpCxyStF3WUjdrFWlmYmReftJ2GiYju3fz3lw184VHzc9dUG8bbo8A0DNepa2uw/LlJJcekf25DGy6hUAFTEYWz6ToS0bxzWJrBAAjJRP1iuLIuWf2FX0U7O/vB+DGG29k4cKF1NXVccstt+QeHxgYKP/ohBBCiElE8/rWum1WdE3DZctWMMhEZEIIIYTIF8hP2jqnljxrPChpu2KWWiOYlZ+03T9U3qRtKJ7i4a37AbBZNC45dmHusZH2CMDMTkZmsTKUimOomemjO57+RIxoOoV7lpO2QojqYZ18lSzDMNA0jfr6+twyv9+f+zmTyYzxLCGEEGJ6HdzTFsDrsBFLZcoyEZkQQgghakcwPnpBt26KSdsGt4N0xiBlGNh0neWzNAmZWS6blSaPg/5IggNDEZRSZasQfuD1fSTS2eTouSvmFbSgaM2rtB2rPcLeyBD9kSB19z1IKB5k55mnMOSJUWdz0u7ylTwmp8VKMJUgmk7htc38JFyGMtgXDbIl2INdt6BLf1AhRJGKTtqOuO+++8ZshTDW8iuuuKL0kQlRAk3T8Pv90ihbFEXipTYUtkfIVth67FZ6yVbaTvWLiMSJKJbEijBD4kWYIfFSPsFYfqXt1Hqmdgaj7B4IYSiFrmnsGwpzzJyGqQ6xJGZjZG6dh/5IgmgyTSCWpN499WRmLJXm/tf3AaBrcOlxCwseb/Y60chORHZwpe3eyBDH/e1HEI/z6x/9DoDPu/pI2K3YdQu/PePykhO3Dt1KwogSzcx80jaZSbMt1MfO8CA+q4M6x+z0PM5n87gmX0kI5NxTCUwnbb/xjW8U/D7y5o21XJK2YqZpmobb7Z7tYYgqIfFSG2LJQyttPcO905SCeDqTW14KiRNRLIkVYYbEizBD4qV8AmXqadsfifPQlv0YSmHRNNDgPx9/jZMXttDkmfnEnNkYmd/gYVNHtsXh/qFIWZK2D285QGR4Etizls4paIcAYLPoNLgdDEQT9B7U07Y/ESVhpBlrFEkjQyAVLzlpq2kaKDXjk5EFU3FeD/TSGQvR6vTgtEx9YrWp0jQNq3Pmq41FdZJzz+wz3dlbKVX0f0LMNMMw6OvrwzBmt1+RqA4SL7WhoNJ2uJdt/mRkU+1rK3EiiiWxIsyQeBFmSLyUT/5EZFNpj9AVjJLOGFg0DU3T8DpsRJNpuoOzM+GV2RiZV1feychSGYN7Nu8BQAPevnLRmOu1+LIJ7VA8VfAZbrpZdQvB1DiTn02DzliIF/oP0BOPMNflr4iELWTzOfGhoORrRFHk3DP7ii49Ovvss6UkWlSFdFp6WIriSbxUv2jeB363fbinrX30g3EkkabFO7XXkDgRxZJYEWZIvAgzJF7KIxArz0Rk7X43PoedWCqTrbQl+zmkzT97t56biZH8ycgOlGEysrXbO3L9gk9Z3FKw/XwtXhdbuwMA9IbiLGyc4oe0IjktVoaS2cnIdM107VrRMobBrvAAW0P92HSdeW7/5E+aYSojCThRPDn3zK6ik7Zr166dxmEIIYQQpYkl8yttC9sjAESSM3srnBBCCCGmrj8SpysYpd3vLmu7gdBwYtFu1XEO36FTiiaPk+vOXckP124imkzjtlu57pyVs9IaoRT5lbb7p5i0TRsGf920J/f7u1YtGXfdgycjm7GkrW4lnEkQy6TxWKc2Ad14YukUW4O97IoM0WR3zcqkZ0KI2lJ6kz8hhBCiAsRSh/a09drz2yPI1WEhhBCimtz36l5ufWwTSim8DhvXnbOSc1fMLcu2h2IJYGqtEUacu2Iuq+Y10h2M0eZ3VU3CFsDntOF32gjGU1OutH1qZ3euR+3x85pY3DR+79kW7+i/0cGTkU0nh8VKfzJKNJ2alqTtQCLKa8Ee+uNR5rh82PXSLwgIIcQISdqKmqJpGg0NDdLKQxRF4qU2jNXT1l3GSluJE1EsiRVhhsSLMONwipf+SJxvPLiBaDKNw5o9r/9w7SZWzWucclI0Y6jcxdy6KUxClq/J46yIZG0pMTKv3kOwa4hgPEUonsLnNN931VCKP7+yO/f7O49fPOH6bXmVtj15k5E1Odw4dCtw6MV2m6ZTZ5vav7GuaSgU0Ux578BKZNJ0x8NsDfaSNDLMc9ehV/jfqd03dusKIQ52OJ17KpUkbUVN0TQNh0NuQxHFkXipDQWVtsMVtr68icgiU6y0lTgRxZJYEWZIvAgzDqd46RiK5vrEZgyF3aLnJviaanI0FC9PP9tKVEqMzK/38HrXEJCdjOwoZ73p131k6wHe6Ati03WOm9vIUW0TbyO/PUJ+pe1CTz2bL/kk/bEwgTmnc8OGv5EcTtr/3fyjaXeNX71bLKum0xcPY9E03BYbbqsNh241lZBKZNKE0glCqSR98QiBdJxwKonP5mCOq/KToZqmYbFXxqRoovIdTueeSiVJW1FTDMOgt7eXlpYWdH36GsyL2iDxUhtGeto6rHqussGd92E0nJhaRYXEiSiWxIowQ+JFmHE4xUtGGWhARiksQH8kwZw6d1km+AoUJG1rK3FVSozkTxa2fygyacL1YI9uPcCX/vYCiXQGXdN467ELJn1Og9uBRc8m5HvDhe0RFnrqWeiphwvnk07uRoX6AHiufz9KqSlX+zXYXXTEwhyIhdDQcFqtuC02Gm3Z/rNuqw23xYbTMprIHStJG02nQIHdYsFtsTHP7ccyjZOblZNSivhgAGdDnVRPikkdTueeSiVJW1FzlFKzPQRRRSReqt9Ie4SRfrYAvjJPRCZxIoolsSLMkHgRZhwu8dIXjtPmc9EdipFRCh14/8nLytKCIBgf/UxQrvYIlcRsjORPRtYRMNfXtj8S5zuPbCSRzlZFo2n8ZdMe3rFq8YTvla5pNHuddAdj9Ibj4yZjz2s/gq3DSdt90QBvhAdY5msyNcaDOS025rmznxEzyiCeSRNLp9iRiGEoA13TcFqsuK126m1OYpkUQ6k4sXQKQykclmySt87lrJok7ZgOj0OJKJPD5dxTqYpK2r7yyisALF++HJdr6lc4hRBCiHLJJW3zJh9zy0RkQgghRFXa3hvA57TjsllJGQY2XSc4xbtmRgRjtdseoRTz8yttB80lbbuCUYLxJBZNQ9M0Gt2OottYtHpddAdjxFMZQolU4XuRTsMDD3B5337+22qQsWSTo49275xy0jafRdPxWO0Fk5LlJ3IHEzGsul4bSVohRNUq6shzwgknsHr1ajZs2JB9kq5jtVp56qmnpnVwQgghxESUUsSS2Z62I5OQAXjzK23L9EVPCCGEENNvR28QAIfNQoPbgdWi8/iOTqLJqV+EzW+PUCdJW+pcdjzD8wAcGDKXtG31ukgbioxSKBTJjIHbbi2qjUWrbzSp25s3GRmQTdr+5Ccc/evfs9Q52sf2se6dpsZXipFEbqPDzVy3n1anF6/NIQlbIcSsKfroo5QinU4X/C5EpdE0jaamJunPI4oi8VL94ulM7g4vd157BJfNwsjbGpnilzyJE1EsiRVhhsSLMONwiZdwIkVHIArAokYvZy1tByCRNli3o3PK2w/m97StsfYIpcSIpmnMHW6RMBBNmEqMd4VitHic6JqGRdfxOW1cd87KotpYtHjHnozsYKc3jfbI3R0ZZFd4oOjxifE56qY+qZs4PBwu555KVlR7hIaGBoaGhvjCF77AhRdemFv+s5/9jIcffnjc5918881TH6EQJmiahsVikYOKKIrES/WLpTK5n515lbaapuGxWwkn0lOeiEziRBRLYkWYIfEizDhc4mVnXzD38/KWOi44ch4PbTkAwIOv7+Pio+fnJh0tRSBWuxORlRoj8+s9bO8JANm+tsta6op63rO7u3NtLC47cQkXHjW/6L7DLd68StuJkrYtC/nfri253x/t3snV3saiXkOMTdM0sOg1fywR5XG4nHsqWVFJ2+OPP561a9fy9NNP8/TTTwPZSts77rhjwudJ0lbMNMMw6OnpobW1VWY3FJOSeKl+sbyKkPyJyAA8DhvhRHrKlbYSJ6JYEivCDIkXYcbhEi/bewO5n5e1+Jnf4OWYOQ281jlIVzDG5o4BVs0rva9pwURkNdYeodQYKehrO1Rc0jZjKJ7b0wtk5xF456olBRfPJ9Pqy6u0DY+ftJ3vqmOJp4FdkUEg2yLh6qUnF/064lBKKeIDAZyNdZKIE5M6XM49layof/VvfetbtLS0oJTKze6oaVru97H+E0IIIabbyCRkUDgRGYDXnq2giSbTGHJeEkIIISreSD9byFbaAlx01Pzcsgde3z+l7Y+0R9AAX40lbUs1t86d+7nYvravdQ0SGk6AnzC/yVTCFrL9cEf0hOITrAnnth2Bx2rnLXNW8P+WnSq5BiHEYaWoSttTTjmFHTt28Nxzz3HgwAE+9KEPoWkaX/jCF1i+fPl0j1EIIYQYU357BPchlbajv0eT6YLJyYQQQghRWZRS7BiutPU5bblqzJMXttDodjAQTbBhXx89oVhBpaYZI+0RvE4bFl2qDAHm13tzP3cEikvaPru7O/fzaYtbTb+mz2nDYdVJpA16J6i0BXjf4uO58ojV2HVziWEhhKgFRSVtAXw+H+effz6QbXugaRrvfve7Wb169bQNTgghhJhItKA9QuGH+fwkbSSRkqStEEIIUcG6QzHCiex5fVmzP3frtkXXuOCoefzfSztRwENb9vP+U0orHAoMV9rWWmuEqWjyOHDaLMRTGfYXUWmbMRTPD7dGsFt0TlzQbPo1NU2jxedi/2CEvnAcQ6lxexV7rPJeCSEOXyU1pdi9eze7du2ShK2oOLquS78VUTSJl+o3UXsET97v4Sn0tZU4EcWSWBFmSLwIMw6HeBmZDAs4pK/qeSvmYR2ujH1sewfJdAaz4qkMybQBZCs9a02pMaJpWq5FQm8oPum/7Wtdg7newCfMbzpkToFijbRISBuKwWhi9AGbDW6+me7P3IBR4rbF+DRNk362omiHw7mn0pX8L59Op/nOd77D6tWr8Xq9eL1eVq9ezXe/+13S6alN+iJEqZRSZDIZ6XUkiiLxUv3y2yMcXGnrsRdW2pZK4kQUS2JFmCHxIsw4HOJlR99oP9tlLf6Cx+pcdk5f0gZAJJHmqV3dmDXSz3Zke7VmKjEyry47GZkCOgLRCdedamuEEa0+Z+7nnlBeiwSLBU45hdjqE7I/i7JSSqEyRk0fS0T5HA7nnkpXUtI2lUpxwQUXcOONN7Jx40ai0SjRaJSNGzfyuc99josuuohUqvQvyEKUSilFf3+/HFREUSReql9Bpe1B1Rj57RDCU0zaSpyIYkisCDMkXoQZh0O8jPSz1Ti00hbgoqPzJiR7bZ/pf4tAXtLWX4PtEaYSI/PrPbmfJ5qMrBytEUa0FExGNnFf2xFKKXaE+vnd3s0lv66ARCA020MQVeJwOPdUupKStrfeeivr16/PXqXJe/NGfl+3bh0/+MEPyjVGIYQQYkyxvLYH7oPbI+RNRBaZQnsEIYQQQkyvZDrD7v5sImluvfuQczpk+9we0ewDYPdAmO29gUPWmUgwliSdMYil0ljl1vAC8/KTthNMRlau1ghAwWRyveH46APpNDzyCN51j6Pl3cH7TN8+Ln/yN3zw6bv53pYn6IgGEUKIWldS0vbXv/41AIsWLeKvf/0r3d3d9PT08Je//IXFixejlOLOO+8s60CFEEKIg01UaVvQ03YKlbZCCCGEmF67B0IYw7VAY1XZQrYX50VHjVbbPvj6flOv8eTObnYPhNg3GOZ/n9/OY9s6Sh5vrZlXZKVtuVojALR4x2mPkE7DD35A80/+By2vv26dzcHe6Gii/rGenVN6fSGEqAYlJW23b9+Opml861vf4pJLLqGlpYXm5mYuvfRSvvnNb+bWEWI2SFN1YYbES3WbqKdtfnuESGJqlbYSJ6JYEivCDIkXYUYtx8v2nvx+tmMnbQHedEQ73uE7aZ7Z3UMglhx33Xz7hyL830tvYCiFRdNIpjP8cO0m+iPxyZ9cRUqNkVafC5sl+9z94yRt81sj2CzalFojjLzmiIJK23Ec5W+h3enN/f5olyRtS1a7hxIxDWr53FMNSkraTvSmjbRLkDdWzAZd12lra5PZDUVRJF6qX357hEMrbfN62iZLr7SVOBHFklgRZki8CDNqPV529I1WUC5r9o+7ns2ic96KeUA2ifjItgOTbnvvQJgv/e15Yqk0Fk1D0zXqXXaiyTTdweJ6qVaDqcSIrmnM8WerbbuCUVIZ45B1Xs9rjXDi/OYptUaA7Oe2kQR8MT1tNU3j3Lalud9fC/bQGZPerGZpmoarsV7yNaIotX7uqQYl/csvX74cpRSf/exnue++++jv76e/v5/77ruPG2+8EU3TWL58ebnHKsSklFIkEglplC2KIvFS/QoqbSfoaRudQk9biRNRLIkVYYbEizCj1uNle082aeuw6ixo8E647gVHzWMk3/TIlgOkjUMTjCPW7+jkX+95nmAsha5pGECT20EkmcZtt9Lmd4373Goz1RiZV+8GwFDQHYwe8vgzZWyNMGKk2nYwmhgzUXyw89uOKPh9rbRIME0pRSaZqtljiSivWj/3VIOSkraXX345APv27ePSSy+ltbWV1tZWLr30Uvbs2QPA+973vvKNUogiKaUYHByUg4ooisRL9RvpaWvVNWyWwlNafnuEqfS0lTgRxZJYEWZIvAgzajleBqMJ+iMJAI5o9mPRJ64AbPG6WD18a/5ANMGLe3sPWSeVMfifJ1/nPx9/jWTGwGrRWTm3kXa/i7Sh8DpsXHfOSpo8zkOeW62mGiPz60eT5QdPRlbu1ggjRpK2CugrokXCMXWttOW1SHisW5K2pUiGxu9bLES+Wj73VIuS7mm44YYbuPfee3n88cfHfPyss87i+uuvn8q4hBBCiEmNVNAeXGULYLfoWHWNtKGm3NNWCCGEENNjR29ea4QJ+tnmu/joBby4tw+AB17fz2mL23KP9YRifP+xTezuH711/rwVc/nQ6UcSjCfpDsZo87tqKmFbDiOVtgAHhgorbcvdGmFEize/r22MOXXuCdbO3tp/TusSfrt3EwCbhrrpiYdpdU5cnS2EENWqpEpbm83GQw89xC233MKqVatwOp04nU5WrVrFN7/5TR588EFsNtvkGxJCCCGmYKTS9uBJyCD7wd4zXG0bmUJPWyGEEEJMnx29+ZOQjd/PNt9xcxpyCb7Xu4bYOxAG4MW9vXz+L8/lErZ2i85HzzyafzrjaGwWnSaPk2PmNEjCdgzz6jy5n/cPhQsem47WCFA4GVlPEZW2AOce1CJhXc+uso1HCCEqTcmXyOx2O5/73Of43Oc+V87xCDFlVmt5rvyKw4PES/VSSuV62o5X8eF1WAnEklNqjwASJ6J4EivCDIkXYUatxsv2EiptNU3j4qPn8/NntpHOGPzi2a3MqXPzyNaO3DrtfhfXn7uSRY2+so+5Uk0lRtr8bnQt29M2v9J2ulojALR6R5PnucnIbDb43OfoDfVhjPH5bmV9O80ON32J7Bgf7drJexauLNuYDgeaRSaVEsWr1XNPtZC/VlFTdF2nublZZjcURZF4qW5pQ5Exsv2V3GO0R8guz1baJtJGURNcjEXiRBRLYkWYIfEizKjVeDGUYmdfttK2yeOg0e0o+rlnLZ1DPJ1m90CIP72ym/964nVC8SQApy5q4etvP/WwSthONUZsFp12f7Z6uTMYwRjuYTldrRHg0PYIAFgscOaZRE4/LfvzQXRN45zW0WrbjUOd9CWkR2uxNE3DWe9H0ybuHS0E1O65p5rIv7yoKUopotGoNMoWRZF4qW4j/Wxh7PYIAD7H6BeL/PXNkDgRxZJYEWZIvAgzajVe9g2GSaSzF1WLrbIdEUulGYwmMJTComkYStETivGu4xdz/bkrx72gW6vKESPz67MtElIZlat8fXZ3T+7xcrZGAGj2OhlJHeYqbYuQ3yJBAeu6pUVCsZRSpOOJmjuWiOlRq+eeaiJJW1FTlFIEg0E5qIiiSLxUt5F+tjB+e4SRSlug5BYJEieiWBIrwgyJF2FGrcbL9rx+tstNJm27glEsmo5F19A0DZtFx+u0cdycxsOyirAcMTKvfrSv7YGhCBlD8dyebNK23K0RstvUaRiuru4d6WmbycATT+B55tnsz2M4vqGdOlv2eRY0tgR72Tr8X1csNOZzxKhUpPgEuTi81eq5p5ocXpcfhRBC1IxikrZex2jSViYjE0IIISrLjoJ+tsVNQjai3e/G57SRNgxsFh2lFD6nnTa/a/InizHlT0Z2YCiCw2qZttYII1p9LgaiCULxFLFUGlcmDd/6Fi2pOG/8+NYxn9MbjxBOZ1thZFDc07GVezq2AmDXLfz2jMtpdx0+rTGEELVLKm2FEEJUpVhytPrCOU57BE/erZHhRGntEYQQQggxPd4YrrTVNVjSZC7J1uRxct05K2lwO9A1DZ/TznXnrKTJ45z8yWJM+ZW2+4ci09oaYURL3mRkvaF4Uc8JpOJkxqn8SxoZAqnitiOEEJXO9KWyWCzG3XffDcCxxx7LSSedVPZBCVEqTdOw2+2H5S1RwjyJl+qWX2k7Xt86T36lbYntESRORLEkVoQZEi/CjFqMl2gyzYGh7ARSixp92K1jX4CdyLkr5rJqXiPdwRhtftdhnbAtR4zMrXOjke0Tu28wzEA0AUxPa4QRrb7CycgWuqVCdrrp01AxLWpTLZ57qo3pSluXy8VHPvIRrrrqKnbv3l3Wwdxyyy2ccsop+Hw+Wltbeec738nWrVsL1onH43zsYx+jqakJr9fLZZddRnd3d8E6e/fu5ZJLLsHtdtPa2spnPvMZ0mmpsDocaJpGY+Ph2cdKmCfxUt0KJyIbpz1CXjI3UuJEZBInolgSK8IMiRdhRi3Gyxt9QUZqJZe3mutnm6/J4+SYOQ2HdcIWyhMjdquFFl/233H3QHjaWyNAYaWtmcnIRGk0TcPh99bUsURMn1o891SbktojLFmyBAC73V7Wwaxbt46PfexjPPPMMzz00EOkUikuuugiIpFIbp1PfepT/PWvf+Xuu+9m3bp1dHR08O53vzv3eCaT4ZJLLiGZTPLUU0/xi1/8gp///OfcfPPNZR2rqExKKUKhkDTKFkWReKlusdRoewTXeO0RHOWZiEziRBRDYkWYIfEizKjFeCnoZ9tsrp+tOFS5YmR+XouEEdPVGgEKK217wtLWYLoppUhFYzV1LBHTpxbPPdWmpKTtDTfcgFKKn/zkJxiGUbbB3H///XzoQx/i2GOP5fjjj+fnP/85e/fu5cUXXwQgEAhw++23c+utt3Leeedx0kkncccdd/DUU0/xzDPPAPDggw/y2muv8atf/YoTTjiBt771rXz1q1/ltttuI5lMlm2sojIppYhEInJQEUWReKluBRORjdMeweuYeqWtxIkolsSKMEPiRZhRi/FSOAlZ6ZW2IqtcMTK3rjBpO52tEeCgpK1U2s6IdCwx20MQVaIWzz3VpqR7HLq6ujjiiCO4//77WbZsGW95y1toa2s7pGR6qtWtgUD2RN7Y2AjAiy++SCqV4oILLsitc9RRR7Fw4UKefvppTj/9dJ5++mlWrlxJW1tbbp2LL76Ya6+9lldffZUTTzzxkNdJJBIkEqMHrmAw2xDfMIxcUlrTNDRNQylVELCTLT84qW12ua7rh2zb7PJSx16N+zTys1Kq4HWreZ9q8X2qlH0yDKMgZmphn0pZXq37FE2mUCg0NJxWy5h/826bFTV882UonkQpZXqfYPxjirxPsk/FHlOqdZ+mMnbZp4mXj8SLYRg1s0+ljl32qfjlB383qdZ9AtjeG0Sh8NpttHoduXN0te7TbMfeZMeUYsc+t85NKpMhbRjYdAunLGrDYdGnLfbqnDYsGqSVyiVtR0aXP9aRMQL4rQ7suoWkkeFgdt2C3+rIPf9g+dsp9/Lp3Ha5lud/Tilm/XKPRRmHHscq8e9psuXVeIwoZZ+m8tm2UvdpKsvLuU/FFsCWlLT98pe/nDvZ7tmzh//6r/8ac72pJG0Nw+D666/njDPO4LjjjgOyyWK73U59fX3Bum1tbXR1deXWyU/Yjjw+8thYbrnlFr785S8fsry3t5d4PHuLhsvloq6ujmAwSCw2egXQ4/Hg8/kYHBwsqOT1+/243W4GBgYK+uk2NDTgcDjo7e0tCIKmpiYsFgs9PaMzdAK0traSyWTo7+/PLdM0jba2NpLJJIODg7nlVquV5uZmYrFYLvEM2TYWjY2NhMPhglYTtbhPDkf2BB0MBgsS8dW8T7X4PlXKPhmGQTAYrKl9gtp7n8bbp97BAJl0GqvVhsVIF2xnZJ+0dIL0cEVu31CQYDBoep+cTmfutiBd1+V9kn0ad58MwyASidDW1lYz+wS19z5Vyj4ZhkEgEEApRXt7e03sUy2+T5WyT0NDQwwNDeXORdW+T1GsDIazt2jPbXDR29tb9fs027E3ckyxWCy0traWvE9b93exuz+EAnRNY83ChoLxTMc++WwavZEUHYNBlMVC6p//mf29nRiRGHEjgGbRcdb7ySSSpCIx6oFfHPs2QqS5f3Avf9j/am6731r2ZpqMbJojFYmRSYy+H1aXA5vbRTIUwci7Y8vmcWF1OkgEQqjMaCLF7vNgsduIDwZGM8mAo84HFp34wGi1OICzsQ6VMUgEQqMLNXA11mOk0iRDo//uB+/TCN1mxeH3ko7FCypiLQ47dq97yvtk87kBiA8GyS+5m4l9IpEinBqkJ55Ntlfy31Pu37eGjhGl7JNhGLn9qJV9gsp4n0KhEMXQ1FiXQSYx8qV1wg1rGpnMoVe+inXttddy33338cQTTzB//nwA7rrrLq666qqCZBzAqaeeyrnnnsu3vvUtrrnmGvbs2cMDDzyQezwajeLxeLj33nt561vfeshrjVVpu2DBAgYHB/H7/bn9me1MfKnLK/nqQrn3CSAUCuHzFc46Ws37VIvvU6Xsk1KKYDCYuxBUC/tUyvJq3acfP/4aT+zsQkPju+86jTl+9yHbTqYzXPHLxwBY0VLHly852fQ+AQwNDeH3+3O/y/sk+zTWcqWyfb/q6upyv1f7Pk1l7LJPEy8fOQf5/X4sFktN7FOpY5d9Km7sgUAgdy6q9n16amc3/7F+Mwr4++OX8O4TllT9Ps127E12TClm7P3hGB++az0HhiJYNI2MUsyv93D7+86mcXiit+nYp1sefJlNnQMA/Pd7z8bnsLFxsJOOWIg2pze3nYP3H2BbqJ8PPfO73O+fPuoMLltw3LjrT+fy2XhNs8uVUqSjcaxuJ5qmTbp+OceyLzLEMb4Wlvqbcssq9e9psuXVeIwoZZ+UKv2zbaXu01SWl3OfgsEgDQ0NuXP7eEqqtL3jjjtKeVrRPv7xj3PPPfewfv36XMIWoL29nWQyydDQUEG1bXd3N+3t7bl1nnvuuYLtdXd35x4bi8PhyFVo5tN1/ZAE9cg//sHGWz5egtvMcrOvOd3LK32fRg4oY6nWfSpluexTcfvU0NBQ8Nh0jV3ep/LvUzydQRuuEXDbbWNux2614LRaSKQNoql07rlm9yk/TqZzn2ZyucTe9OxT/ueTWtmnci+XfRpdfvA5qBb2qRLGXov7pOv6mOeiat2nHX0BGD6LL2+tLxhXte7TRMtnap+mekzpDseJpzK47TaS6Qx1ThuxVIaecIJmn7tg/XLuU5vfxebO7Jh6w3H8TnvusfyxjjXu5b4mGu0uBpLZarln+vbz9wtXjrv+dC+fjdc0s1zTNOxe95jrjredco5F0zXJsVTZPpX62baS96nU5eXcp/Gec7CSkrZXXnllKU+blFKKT3ziE/zxj39k7dq1LFmypODxk046CZvNxiOPPMJll10GwNatW9m7dy9r1qwBYM2aNXz961+np6eH1tbsLJcPPfQQfr+fY445ZlrGLSpH/hXm8U4WQoyQeKlusdTo3Rwu2/inM4/dRiKdIJwofSIyiRNRDIkVYYbEizCj1uJle8/o7atLW8avMBLFK0eMtPvduO1WDKVocNuJJtO47Vba/K7JnzwFLd68yciGwizdtRVXsA9WLJ70ubqmcXrzAu7t2AbAiwMHSGTSOCwlpTpqnlKKVCSGzeOqiWOJmF61du6pRsWldiewYcMG7rrrLv7nf/5nyoP52Mc+xq9+9SvuuusufD4fXV1ddHV15XpM1NXVcfXVV3PDDTfw2GOP8eKLL3LVVVexZs0aTj/9dAAuuugijjnmGD74wQ+yceNGHnjgAW666SY+9rGPjVlNK2qLUopYLDbmLRlCHEzipbrFktkkrKaBwzr+6czrsAHDE5eV8F5LnIhiSawIMyRehBm1FC+pjMGegWwvvzl17tx5WkxNOWKkyePkunNW4nXYiKcyeB02rjtnJU3DrRGmS4t3dPv9gyH4yldo+86t6KniLrif3rQw93PcSLNxaOy5bERWfk9cISZSS+eealXy5acXXniBq666itdeew3Ilvh+8IMfZO7cuQSDQR5++GHOOeccU9v8z//8T4BDnnfHHXfwoQ99CIDvf//76LrOZZddRiKR4OKLL+bHP/5xbl2LxcI999zDtddey5o1a/B4PFx55ZV85StfKXVXhRBCVKDY8Ad5l8064ZVfj2N4MoqMIpkxcFgtMzI+IYQQQhxqd3+ItJFNACyXKtuKc+6Kuaya10h3MEab3zXtCVuAVt9opW1vODbBmmM7tWk+OhrG8Gxhz/Tt5dSm+ZM8SwghKl9JSdstW7Zw3nnnEYlECjLuTqeTd77znfz85z/n7rvvNp20LSZ773Q6ue2227jtttvGXWfRokXce++9pl5bCCFEdYkmR5K2EydhPfbRU104kZKkrRBCCDGLdvQGcj8vbxl/Lgoxe5o8zhlJ1o7IT9r2hOOmn19nd3JMXSubA9m5bJ7p28cnjyzb8IQQYtaU1B7h3/7t3wiHw+i6nuslO+K0004D4Iknnpj66IQwSdM0PB6P9FsRRZF4qW7x4Z62LvvE1x89ebddRkroaytxIoolsSLMkHgRZtRSvGzPS9ouk6Rt2VRzjPgcNpzDF+H7Sqi0BTi9eUHu512RQbpiobKMrRZZXdI2UhSnmo8rtaKkpO1jjz2GpmnccsstfPvb3y54bPHixQDs379/yoMTwixN0/D5fHJQEUWReKleacMgmTGAiSchA/Da85K2yZTp15I4EcWSWBFmSLwIM2opXnb0Zichs1t0FjR4Z3k0taOaY0TTtFxf2/5wglK6Z+YnbQGe6d9XhpHVHk3TsLllEjJRnGo+rtSKkpK2gUD26uiJJ554yGOpVPYLcTQancKwhCiNUoqBgQFplC2KIvFSvUaqbAHckyRtR3raAkSS5ittJU5EsSRWhBkSL8KMWomXQCxJ7/Dt70c0+7Hokggol2qPkRZvtkVCWilSwxfmzTja30q9bbSlw9N9e8s2tlqilCIRDFdtnIiZVe3HlVpQUtK2vb0dgAcffPCQx+6++24A5s+Xxt9i5imlSCaTclARRZF4qV7RvOSryz5xj9r8WanDCfOVthInolgSK8IMiRdhRq3Ey46C1ggyCVk5VXuM5Pe1TaQzE6w5Nl3TOLVpPhZN44T6OaxumFvO4dUUI2W+iEEcnqr9uFILSpqI7MILL+T222/nu9/9Lg8//HBu+XnnncfatWvRNI2LLrqobIMUQggh8sXyPmxO1h4hfyKyUnraCiGEEKI8RlojgPSzFYVah9sjZHQLe97zftx+UCYnj/3nFafzmaPPwmuTnq1CiNpQUqXtF7/4Rerr61FK8fLLL+f6W6xbtw6A+vp6brzxxvKNUgghhMgTy2uP4LIVX2lbSk9bIYQQQpTHdqm0FeMYqbQ1LBa2nHwGoYsuQFnN1Zi1Ob2SsBVC1JSSkraLFy/m4Ycf5thjj0UpVfDfcccdx8MPP8yCBQsm35AQZaZpGn6/Xxpli6JIvFQvU5W2U2yPIHEiiiWxIsyQeBFm1EK8GEqxpXuIWCqN12GlyeOc/EmiaNUeIyM9bQF6w7FZHEnts3lck68kBNV/XKkFJbVHAFi9ejWbNm1i48aNbNu2DYAVK1Zw/PHHl21wQpilaRput3u2hyGqhMRL9Yrl9bR12yc+lXntU5uITOJEFEtiRZgh8SLMqIV4+f2GnWztHsJQioFInMe2dXDuCuk7Wi7VHiMtvmwSXzMMtE2bceotsEjio9w0TcPqlGpkUZxqP67UgpKTtiOOO+44GhsbAZg7Vw6qYnYZhsHAwACNjY3oekmF5OIwIvFSvaIF7RGmt9JW4kQUS2JFmCHxIsyo9njpj8T576e2YCiFRdMwFPxw7SZWzWuUitsyqfYYcdms+Jw24qEIZ9z+I9pb3Oz+8a0whXxRJJ0klErQ7vKVb6DDumIhAqn4IcvrbM5peb1yUUqRCIRw1PmkelJMqtqPK7Wg5KTtjh07+PznP8+9995LPJ49WDmdTt72trfx9a9/nRUrVpRtkEKYkU7LREOieBIv1Sm/0naynrbuMkxEJnEiiiWxIsyQeBFmVHO8dAWjRJNpLJqGpmnUuexEk2m6gzFJ2pZRNccIQIvXyb5QhFTGYCqT1f9u72Ye7X6DV4a6eXPrYr5+fHknSe+KhfjHJ39D0sgc8phdt/DbMy6v7MRtxpjtIYgqUu3HlWpXUtJ2w4YNnHfeeQSDQVTe0TQWi/GHP/yBBx98kLVr13LiiSeWbaBCCCHECDM9bXVNw223Ek2mZSIyIYQQYha0+93oQEYpLGTP436nnTa/9NYUo1p9LvZ1ggJSU0gsbhjsYMNgJwDP9+8nbRhYy1gluDcSGDNhC5A0MmwJ9hYkbau1KlcIMftKStpef/31BAKjM382NDSgaRoDAwMopQiFQnzqU59i7dq15RqnEEIIkRPLb49gn7jSFsAznLQtpT2CEEIIIaamyeNkYaOXbT0BDMDvtHPdOSulylYUyJ+MLJ0pvdT29OaFPNq9E4BQOsmrgW6Ob5gz6fPGS676rA6GUnGe7tvLk717eD3YO+F2frD1Kc5pOyK3zWquyhVCzK6SkrbPP/88mqZx8sknc+edd7Js2TIg2zLhAx/4AM899xzPPfdcWQcqRDE0TctdRBBiMhIv1Su/0tY9SaUtZPva9objRJJplFKm3nOJE1EsiRVhhsSLMKPa4yWVMVDA4kYfrT4XX7n0ZEnYllm1xwhkK21HTKXS9vSmBQW/P9O/b9Kk7UTJVbMWe+pzPwdS8QmrcgOpeElJ26lU79p9HtOvJw5PtXBcqXYlJW2bm5s5cOAAN910Uy5hC7Bs2TK++MUv8o53vCM3OZkQM0nTNBwOmQ1TFEfipXoV9LS1T34q8w6vo1S2StddxHNGSJyIYkmsCDMkXoQZ1R4v3cEoSoHVonN0e70kbKdBtccIQKt3NC6S6dKTti1OD8u8TewI9wPwTN8+/t+yUyd8zkTJVbMWeRrKsp3xTKV6V9M0LHbbmI8JcbBaOK5Uu5Iau1x99dUopdi7d+8hj40su+KKK6Y2MiFKYBgG3d3dGIY0VxeTk3ipXgXtEYqstB1htkWCxIkolsSKMEPiRZhR7fFyIBDN/Tynzj2LI6ld1R4jcHB7hKntx5rm0WrbLcFeBhKxKW1vxBGeBt46Z/mE65zeNL8srzWeYqp3x6OUIjYwVDA3kRDjqYXjSrUrqtRo/fr1Bb+fddZZrFq1ihtvvJGenh5OPTV71eq5557j+9//PitWrOC8884r/2iFKIKcgIQZEi/VKb89gtM2eU9br2P0dBdNmp8BVeJEFEtiRZgh8SLMqOZ46QzmJW39krSdLtUcIwDNXieGbmHdmRfjdVlYaJ38M954Tm9ewC93v5z7/bn+fbxl7opx1zcm+be7YvGJvHPB0cxx+emKhXike+e4la5LvMXfdZwqIRmWzEyxIri6w0TMsGo/rlS7opK255xzzpg9LJRSfO1rXztk+bZt23jLW95COm3+i7EQQggxmZGkrdNmQS+ix5In7zawkExGJoQQQsyozkAk9/PcOumnKcZms+jU+dw8f9JZYDG4wlpSN0cAVta347bYiGayn/ue7ts7btJWKcWv92yccHvntR/BHJcfgHaXj9+ecXnJPWXz/XjbM/zw5Eux6cUlqAcSMb79+vrJVxRC1ISij4LjZdfNLhdCCCGmKpbMVhi4iqiyBfDmtUeIJiVpK4QQQsykjrz2CO1SaSsm0OpzMRBNEE2mp9TX1qZbOLlpHut7dgPwbP9+MsrAoh3aIfIXuzbwUNcbprbf7vIVlZytszmx65Zx2xlsGOrkX195mK+tugDrJInbXeEBPv3SfXTGQ6bGKoSoXkUlba+88srpHocQZaFpGk1NTTK7oSiKxEv1ig5X2hbTzxbAk9ceIZwwdxeIxIkolsSKMEPiRZhRzfGilMq1R2jyOIpqayTMq+YYydfitjPUvZ9YJkUwPBe8pW/r9KaFuaRtIBVnS7CXY+vaCtb58/7X+K8dz024Hbtuoc5W2uR5Y1Xlvh7o5ftbniSpsoncdT27uHnTI3xl5fnjJm6f6dvHTa88RCSdLGkc+Rx1xVcCi8NbrRxXqllR33bvuOOO6R6HEGWhaRoWi0UOKqIoEi/VyVCKeGqk0rbIpG1ee4SIyfYIEieiWBIrwgyJF2FGNcdLKJ4iMnzBVPrZTp9qjpF87U4rp/3mJ2SUwUvnHQvtpW/r9LzJyCCb+MxP2q7t3sW3X3u8YJ0rFp/Iee1HFCwz2/LgYAdX5R7pb2GBp45Pv3QfCSP7t/FY907+DY1/W3k+Vr2wGvj3ezfz/a1PkinibubJEsyapoFFHzNOumKhsrR8ELWjVo4r1az0JjFCVCDDMOjp6aG1tRVdP/TWFyHySbxUp5GELRTfHsFjz6u0NTkRmcSJKJbEijBD4kWYUc3x0pE3CdnceulnO12qOUbytficKKUwDEVv4NAEohlzXD4WexrYHRkEsknbq5eeDMBLAx18adPDGHmzcv3T0lP48NKTpvSaxTqpcR7fOfEt/MuG+3KtEx7pfgNd07j5uPOw6jppw+BH257i7r2bC557cuM8rjvyTWTUoe0j6mxO6mxOHuzczkVzlh/yuFKK+EAAZ2NdQSKuKxbiH5/8zbiTq/32jMslcXsYqpXjSjUrOWkbCAS466672LFjB0NDQ4f0sNU0jdtvv33KAxRCCCHyjUxCBuC2F3cak562QgghxOzozOtnK5W2YjJ7+8MsTKVRCh55pYc5rS2sXtxY8vbOallEg93J6c0LWTNcebs91MdnX76/IEF52YJjueqI1VMevxmnNM3nOye+hc9sGB3Lw107OKVxHiv8zfx2zybu69xW8Jx3zD+afznqzHHbKGwN9nHdi39jb3QIl8XGWa2LixpLIBUft+9u0sgQSMUlaSvELCgpafvYY4/xrne9i1Bo4gbYkrQVQghRbrG8StlSetqGTLZHEEIIIUTpOgKR3M9z6yRpK8bXH4nz+407uV4BGsSTBr96YieLmz00eh0lbfPa5acVVJQeiAa5/sW/FfSGPb9tKZ866oxZuQX81KYFfOuEt/DZDfeRUtm632+8tm7MdT+5Yg2XL1o17jh74mGuee6PueTr119dyy/976HFKRXuQlSrkuqbP/WpTxEMBlFKjfufEEIIMR1i+e0R7MW1RyiotDU5EZkQQgghSteRX2krSVsxga5glETaQNc0NEBDEYyl+Mkj23j+jT7SmUPbAUxG0zS6YiG2Bnt5rm8f1z7/ZwaSsdzjJzfO4+aV52HRZu/W79ObF/CJFWsmXOeTK9bw3sXHT5hYbnV6ec/C43K/B1JxvrL5UYwi8jObA93FD1gIMWNKqrTdsmULmqZxxhlncN1119Hc3FzucQlREl3Xpd+KKJrES3XKb49QbKWt02pB00ApCJustJU4EcWSWBFmSLwIM6o5XjqHe9raLTpNnvEnSBJTU80xMqLd78Ztt6LrGoYCQ4GuQTyZ4d6XD/D41h7etKKFkxY3YbMWt58T9WrVgE8ddQb2cVoNzKRVDRPPuLa6cW5R2/l/y07lhf4DbA31AfDCwAHu2r2RDyw5AcgmsfP72UbSSf5969P8+cDrpQ9e1KxaOK5Uu5KStkuXLmXLli18/vOf561vfWu5xyREyZRSZDIZNE2TGQ7FpCReqlMpSVtN0/A6bNkZrE1ORCZxIoolsSLMkHgRZlRrvKQNg+7hpG27341eRWOvNtUaI/maPE4+fvax2P5LJ2UY1HlstLXVE4xmWxmEYike2NjBE1t7WLO8hZOXNJFIZ+gPJ2ny2vG77Idsc6JerQpIjfNYtbLpFr6y6gKufPp3xI3sZ96f7HiOk5vmcZS/JXtndMYAi56NFTSe698/y6MWlaoWjivVrqR0+Ze//GWUUvz0pz8lEolM/gQhZohSiv7+fmnRIYoi8VKdCtsjFH/t0TO8bsTkRGQSJ6JYEivCDIkXYUa1xktvKI4xPGRpjTC9qjVGDvbmoxdy1Kc+iv2qy7nmkiP51FuP5p/OW86Rc+ty60TiaR7e1MnX/riJm+/eyL8/sIVv/uVVXto9MIsjrxwLPfXccPSZud8zyuDGlx/g5cFOtgZ72dS5h63BXrpiIdxWG1849pxJtxlKJaZxxKJS1cpxpZqVVGn793//99x000187Wtfo729nSOPPBK/31+wjqZpPPLII2UZpBBCCDEiWjARWfG3s2X72saIJjMYSkm1jxBCCDHNZBIyYZrViu+qD2Eb7MQTy058PrfBzeVrFtMViPH4lh5eOzBEJqPoDsYwFFh1jYyh+N2ze1jW5h2z4vZwc+ncI3m6by+Pde8EoDse5trn/1ywjl238NszLufkpnlcs+wUFrjqWODJJsdf6D/Af2x/JrfuL3Zt4KTGeVJtKcQMKylp+/vf/55vfOMbaJpGJBJhw4YNBY8rpeSPWQghxLQopT0CgMc+OhlZJJHG57RNsLYQQgghpqpgEjK/JG3F1LTXuXjPaYvoDbbx15f20zEUQ9eybQ50TSORyjAQTlZl0rbO5sSuW8Zs5WDXLdTZzPWD1jSNG495MxsHOwsmXsuXNDIEUnHaXT6uOuKkgsdW+Jp5fuAAz/bvA7K9cZ/p28ealoWmxiGEmJqSkrY33XQThjE6c6OUSotKIhcMhBkSL9Unlsxrj2Cq0nb0lBdJpkwlbSVORLEkVoQZEi/CjGqMl5FJyADm1ntmcSSHh2qMkUMoBfv2YQt0Q6N/zFVa/E7+/rSFvN4RYDCSREcRTaZp8jpo9FZfwhag3eXjt2dcTiAVP+SxOpuTdpfP9Db9NgfXLD2Fb76+3vRzNU3j00edwfuf+j/cVjvXLj+V05oXmN6OqH41cVypYiUlbffu3YumafzjP/4jn/70p2lsbJTZ5ERF0HWdtra22R6GqBISL9Wp5Epbx2iSNpwovq+txIkolsSKMEPiRZhRrfHSKZW2M6ZaY+QQiQR87GPMS8XZ9+NbwTX2an6XnfeuWcx/P7qdtKHQUVx2ysJDqmzLXcE6ndpdvpKSsxM5qq6l5Ocu8NTz9eMvYlV9O3X2yvl3EjOnZo4rVaykpO1JJ53Ek08+yfvf/35OOumkyZ8gxAxRSpFMJrHb7XJFSExK4qU65Sdt3SVMRAbZ9gjFkjgRxZJYEWZIvAgzqjVeRnra1rnsps7ZwrxqjZGpWL2kibOODPDqgSGsuk57w6EZ3umoYD2cnNW6eLaHIGbR4XhcqTQllcfedtttNDY2csstt7Bz585yj0mIkimlGBwclJYdoigSL9UpWtAeofgvgN78Sttk8ZW2EieiWBIrwgyJF2FGNcZLJJEiGM+eb2USsulXjTFSDivm+nFYLVh0jb19kTHXaXf5ONLfcsh/krAVYmKH63GlkpR0ufMd73gHhmHw9NNPs3z5curr66mrqytYR9M03njjjbIMUgghhBiRX2nrNNHT1l1ipa0QQgghzOvI72crSVsxTRY1eXM/7+mLsGZ56e0AatF0tIeIplPsjwZY4W8uxxCFEBMoKWm7e/fuXGm0UoqhoSGGhoZyjyulpHRaCCHEtBhJ2tosGjZL8TeM+PIqbSMmKm2FEEIIYV5hP1uZhExMj2a/A6fdQjyZYV9/RHIRBzm4PYRSikQwjMPvpd7uMlVtrJTise6d/HDrUxgofnPG5Xis1TnxmxDVouTGQvnl0VIqLSqJ1Sr9skTxJF6qTyyVrRQw0xoBCittzUxEBhInongSK8IMiRdhRrXFS0HSViptZ0S1xUg56JrGwiYP2zqDRBNp+kIJWvwyaVa+/AnOlFIklBOH32c6uX1Px1a+8era3O937HyRj69YU86higp0OB5XKklJPW0Nw5j0v0zm0PJ7Iaabrus0Nzej6yWFtjjMSLxUp5FKW5fJCU28BZW2xbdHkDgRxZJYEWZIvAgzqjFeRiYhA2mPMBOqMUbKZWHzaCX3nnH62oosTdNw1vtLqka+sH0p7c7RdhS/2bOJXeGBcg5PVJjD+bhSKeRfXtQUpRTRaFSqv0VRJF6qj1KK2HDC1WylrSc/aWui0lbiRBRLYkWYIfEizKjGeBnpaWvRNVq8rlkeTe2rxhgZk9UK73oXwUveirIWN3fBwqbRpO3efknaTkQpRTqeKClOnBYbnzrqjNzvGWXw1U2PsiXQw9ZgL1uDvXTFQuUcrphlNXNcqWIl1TmvX7++qPXOPvvsUjYvRMmUUgSDQZxOp/QyEpOSeKk+qYyBMfyZwWViEjIAb/5EZCYqbSVORLEkVoQZEi/CjGqLF0MpuoeTtu1+Fxa98sdc7aotRsZltcKHP8zAYCeqyATgnHoXVotOOmOwVyptJ5WKxLA4SutFe1bLYlY3zOGlwU4AXg/1cdWzf8g9btct/PaMy031yhWVq2aOK1WspKTtOeecM+kbpmka6bTMzi2EEKJ8RvrZgvlKW7vVgs2ikcoo0z1thRBCCFG8vnCcVCZ7lXWOX1ojiOlltejMb3SzuzdMIJokEE1S55YJsqaDpmn8w6JVuaTtwZJGhkAqLklbIcqk5PYISqlJ/xNCCCHKKZpXIes22dMWwGPPtkiIJOSiohBCCDFd8vvZzqnzTLCmEAdRCnp6sPb2ZX8ukvS1nTn5fW2FENOrpErbK6+88pBlfX19PPnkkwwNDbF8+XLOOOOMMZ4pxPTSNA273S6l+6IoEi/VZ2QSMjDfHgGyk5ENxZKEk8VX2kqciGJJrAgzJF6EGdUWL52BaO5nmYRsZlRbjIwrkYCrr2Z+Ks7+H98KRbZDXpSXtN3bF2HVwoZpGmD1003erWZWKJ2c1u2LmVMzx5UqVtJf6x133DHm8lAoxEUXXcRLL73Ef/3Xf01pYEKUQtM0GhsbZ3sYokpIvFSfwqRtCZW2juxzkmmDVMbAZpn8hhOJE1EsiRVhhsSLMKPa4mVkEjKQpO1MqbYYKbf5jW50XcMwlExGNgFN03D4p7dS9uubH+N3Z70Piybz3le7w/24UgnK+lfk8/m44oorSKVSfOELXyjnpoUoilKKUCgk7TlEUSReqk9BT9sptEcAiBTZ11biRBRLYkWYIfEizKi2eMmvtJ3jl/YIM6HaYqTc7FYL7fXZstzeYJyotMIak1KKVDQ2rXHy1jkrJGFbIw7340olKNtfklKKzs5Ofv/73wPw8ssvl2vTQhRNKUUkEpGDiiiKxEv1iSWn2h5hNNEbThb3YV7iRBRLYkWYIfEizKi2eBlJ2nodVnxO2yRri3KothiZDoua8lokSLXtuNKxxJSeX2dzYtfH/hyuAW+fd1TBsq5YiK3BXnaGB3gt0MOGgQ42DHSwNzI0pXGI6SfHldlXUnsEi2XiL8qaptHS0lLSgIQQQojxRPPaI7hLao8w+sUxaqKvrRBCCCGKE0ulGYhmk0IyCZmYSQubPTy9vRfITkZ21Ny6aX/NYCxJfzhJk9eO32Wf9terBO0uH78943ICqXjB8mQmg023MMftzy3rioX4xyd/Q9LIHLwZHLqVzZd8koWe+ukeshBVq6SkbTFZ9n/5l38pZdNCCCHEuKbeHiGv0rbI9ghCCCGEKF6X9LMVs2RhU+FkZNNt3evd/P65PaQNRZ3LxntOX8zqxYdH/892l492l2/S9QKp+JgJW4CEkaY/EZWkrRATKClpu3DhwkNmj9M0jbq6OpYtW8Y111zDhRdeWJYBCmGGpmm4XC6Z3VAUReKl+ky9PUJ+T9vi2iNInIhiSawIMyRehBnVFC8def1s5/olaTtTqilGpovbYaXF76Q3GKdzKEYilcFRwufFycSSaR54pYN7Xz6AoUDXYCCS5O5ndrOszVvxFbcWR2WPT1QOOa7MvpKStrt37y7zMIQoj5GLB0IUQ+Kl+sRS+Unbmam0lTgRxZJYEWZIvAgzqileCiYhk0rbGVNNMTIhiwXe9jZC0QDKYn4KnoVNHnqDcZRSHBiMckTr5NWgxUpnDJ7f2c/6Ld0EIslcwlbTNJRSDESSdA3FKzppq2kadu/M/V2mDGPGXkuUX80cV6qYTOknaopSikAgII2yRVEkXqpPQXuEKfa0jZiYiEziRBRDYkWYIfEizKimeOkIjN6WLj1tZ041xciEbDa49lr6P3wlymZ+EruFzaMxt6dMLRKUUry2f4jbHtrKg690EE9msFp0dA0suo6GwlDZ9R7a3EksOXY7gEqglCIZjs5YnNh0STlVs5o5rlSxor/x/vd//7fpjV9zzTWmnyPEVCiliMVi+Hw+KeEXk5J4qT7RvESru4Setl57ftK2uEpbiRNRLIkVYYbEizCjmuJlpNJW06DN55rl0Rw+qilGptOi5vL2td0/EOHBVzrZ15+3LQ1WL2mixWfnby93EE2kiaUy1Lts9AXj/O/jb3DFWUeUNP/CTMgkktg88rcpJifHldlX9FHkox/9qOk3SZK2QgghyqmwPYL5HmUeR357hOIqbYUQQghRHKUUncMTkbX6XNhKuL1dHOaUgmAQPRgsqZljndtOndtOIJpk/0CUdMbAajIOg7Eku3sjbNo7yI7uUMFjS1q9XLRyLu312aTnyoUNDISTGIbiDy/sJRJP0zUU4xeP7+SDZx5R8NnzcFRnc2LXLWNORubQrTQ5pIWKEBMxdQQxUxItWXghhBDlNtIeQdco6YtgQaVtkT1thRBCCFGcgWiCRDrbw1ImIRMlSSTgAx9gYSpOx49vhRIKQhc1e3hlb5J0xqBzKMaCpuLbdLy0e4BfPv4GoXgaXYMGtx23w0qzz8GFK+eyvL2w4tDvsud62F551lJ+8fhOIvEU3UMxfrE+W3HrdZpv81Ar2l0+fnvG5QRScbrjYY7wNLDAUw9Ak8PNwuGfhRBjKzppe+WVV074+ObNm3nxxRdzTbiFmA2apuHxeOSigSiKxEv1Gam0ddmtJb1v7vxK2yJ72kqciGJJrAgzJF6EGdUSLx0yCdmsqZYYmQkLmjy8sncQgL39kaKTtsFYkl8/tSuXsDUUDMVSvO3EeZx5ZBsWfeJ/2xa/k6vOXsovHn+DUCxFbzDOL9a/wQfPWorfVTmJW6vLMaOv1+7y0e7y4bHaOcbfwjJ/84y+viidHFdmX9FJ2zvuuGPM5S+99BJf+9rX2LBhQy5hu2zZMj7/+c+XbZBCFEvTNHy+8s0QKmpbNcVLfyROVzBKu99Nk8c528OZNbHhRKu7hEnIAKy6jtNmIZ7KFF1pW01xImaXxIowQ+JFmFEt8SKTkM2eaomRmXBwX9szVhT3vL5QgmAsha4NJ6tsFiwWjUXN3kkTtiOafA4+dPZS/vfxnQSiSfpCiVzFbZ3bXsrulJWmadjc1d3PNr3vANF7HiDT2Y1lThvuSy/GumDebA+rJslxZfaV3GTo2Wef5dJLL+WUU07hz3/+M4ZhcPTRR/OrX/2KLVu2cNVVV5VznEIURSnFwMCAVHuLolRLvDy2rYOrf7WOT/3+aa6+cx2PbeuY7SHNmlylbYlJWwDP8KQQ4SKTttUSJ2L2SawIMyRehBnVEi+deZW286TSdkZVS4zMhGafI3d31d7+CEaR/yYD4SRKKQyVbcWl6+C0WWj0mku2NnodXHn2Uuo99uHtJvj5+jfY2x9hV2+YYCxpbofKSClFIhiu2jiJ3vMAve+9mshddxN/dB2RO++m971XE/3bg7M9tJokx5XZZzppu3btWi644ALe9KY3ce+996KU4oQTTuB3v/sdmzdv5n3vex+6Lg3nxexQSpFMJuWgIopSDfHSH4nz1ftfZN9QGEMpwokUP1y7if5IfLaHNuNSGYNUJvteuezmJyEb4XVkb0+LJNNFvffVECeiMkisCDNqKV76I3Fe7Rw4LM9NM6Va4qWgPYL0tJ1R1RIjM0HTtFxLhHgyQ29w8mNTxlA8vb2XBrc9N3eCy27l709blOtZa0aDx86Hzl5KozfbiqBjIMo3/rSJH97/Ot/8y6u8tHvA9DbLxUhV52S86X0HCHzz+9m+FRkj+38j+//ALbeS3n9gtodYc+S4MvuKLlW6//77+frXv85TTz0FZN+8NWvW8MUvfpG3ve1t0zZAIYQ4nD23p4dALIlF0wgnUsyt8xBOpOgOxg67Ngnx1Oiss1OptHUPV9pmDEUibeC0lZ4AFkKIw91j2zr43iMbCcST1LnsfPq84zl3xdzZHpaYJZ3BbNLWZbNQV0KiS4hyWdTsYWtHAMi2SGirm7glwIu7+hkIJ3A7rCxt83PhynaafI4JE7YZZRBOJ4ln0jgtVjwWO9a8ArY6t50rz17K7Wu3c2AwiqEgmTbQSPO7Z/ewrM1bUkJ4ugVjSfrDSZq89ooaX/SeB0DTgLESiBrRvz6A/9oPz/SwhJhWRX/rfdvb3pbrWatpGqeccgpvfvObeeKJJ3jiiSfGfM43vvGNsg1UCCEON0opHtvWga5pZJQCI1vN1OB20Oav7l5UpYjlVQW4ppBo9TlGJ4KIJFOStBVCiBL1R+J879GNdIVi6EBPOs4P125i1bzGw+7CooBkOkN/OFvROKfOLRPXiFm1MK+v7Z6+CKcsHX/yq0Qqw7rXu3O/X7J6HvMaxq4UTxsG4XSCcDrb4sBnddDu9DKUjNMdD6FQuCx2PFY7TosVv8vGxSvn8vqBILqmyBgKp81CIpVhIJysqKQowEu7B/jds3uIpzI4bRb+/rRFrF7cONvDAiDT2Q0TVHxmOrvHfUyIamW6VGnk5PvCCy/wwgsvTLiuJG3FTNM0Db/fLx8SRVEqPV6e2tnNvsEIbT4X3aFYNnELXHfOysPyy3A0OZq0HamWLUX+c8OJ1KT/lpUeJ6JySKwIM2ohXvYOhukNxdEhV9xxuN4NMt2qIV46g9Fc/dtcmYRsxlVDjBTFYoHzzyccDaIspbddnFPnwmbVSaUN9vZHcsVnY3lyWw/RRPZz5rHz6w9J2KaNDKF0kkg6iaZpeC12lnubaHK6qbc5sVuspIwMgVR8OHkbJpCK0xNP47BYaayz4bJbiCTS6CjC8TQ+l810r9xysXnGLv4IxpLc/cxuBsJJQJHKGBVVEWyZ0zZBpe3w46KsxjquyERwM8vUt14zfSyq/mQhqpKmabjd0j9LFKeS4yWeynDXCzsA8DnteOxWEhmDOpeds5a1z/LoZkdhpW3pSVtvXqVtfiJ4PJUcJ6KySKwIM6o9XpRSPPz6fgylMJTCAmSUQte0w/JukOlWDfGSPwnZHJmEbMZVQ4wUxWaD66+nb7ATFQuVvBld11jQ6GFnT4hQLMVQNEWD59DEYzCW5KntfQBYdI3zj5sDZBO1wVSSaCaBhk6dzcFR/mYa7G7q7U5seuGdWjbdQrPDQ7PDwxHeBsLpJEPJOL2JMAN6nJOX17N+cx+Gyr5Oqb1yp0rTNKxOx5iP9YeTRBJpFGr4QhwVVRHsvvRiInf+39gPKoX77RfP7IAOAwcfV6L3PJDtK6xp2apnTSNy5/9R9/kbcF9y0SyOtHYV/a33S1/60nSOQ4iyMAyDgYEBGhsbZUI8MalKjpd7Nu9hIJoA4IT5TbhsFp7e1UMybbCla4jj5lbGbUozKVamnraevKRtOJGadP1KjhNRWSRWhBnVHi/3vbaPl/b3F9wNomsax89rkirbaVAN8dIRHE3azpVJyGZcNcTITFvYnE3aAuzpC9PgOfTz86OvdpPJGACcsrSZBo8dQyk6YiGa7G4We1ppcLipszmw6sW11NI1Hb/Nid/mZKGnnlg6xdxT69hx4HmiqTTHzquftZYDSikSgRCOOt8hhXZNw5W/hgIdRTyVwT+LFcEHsy6YR93nbyBwy62Alp2EbJjWUIdlzuFZ2DKd8o8rxoHO0YngctXO2f8HbrkV+/HHYp0vFbflJklbUXPS6eqcDVPMjkqMl/5InL9u2gOArsEHTlnOnoEQT+/qAeCFvb2HadK2PD1tvXntESJFVNpCZcaJqEwSK8KMao2XVzsH+NXz24Hs3SAff/Ox/OzprSgFoURqwtuQRekqPV6k0nb2VXqMFEUpSCTQ4vEJ+5cWY1FeX9u9fRFOWFT4+blrKMbGvQMAOO0Wzj6qFYDBZIxGu4tTm+fjsJReKDDCZbVxTHMzjW4n6UiU/lBiytucCpUxxlzuddqo9ziIp7KTpukanHNMW0VU2Y5wX3IR9uOPJfrXB0g88QzpXdnvTGpgiPjaJ3Cd/+ZZHmHtGTmuyERws6OiLsGtX7+et7/97cydOxdN0/jTn/5U8LhSiptvvpk5c+bgcrm44IIL2L59e8E6AwMDvP/978fv91NfX8/VV19NOByewb0QQoip+fULO0gOf5i66OgFzKv3cML8Ziz6cE/xvb2m2tXUioJK2yn0tDVbaSuEEGJUXzjOj9ZuzuVS3rFqEW85ZiEnLWzBatEJxJIcGIrM7iAn0B+J82rnAP2R+GwPpeZ0BLLvuwbMkUpbUapEAt7zHhZddQ16IjmlTc1rdKMPf37e03focemhzZ25/NNZR7bhslvJKINIJskSb2NZErYjNE1jSaMfXdMIxFOE45X3GbRzMIZFg/Y6F61+B+11LhzWypuw1zp/Hv5rP0zTbd9By2v1EP7f3xyW35FmSqaze7jKdgxKyURw06SikraRSITjjz+e2267bczHv/3tb/OjH/2In/zkJzz77LN4PB4uvvhi4vHRD13vf//7efXVV3nooYe45557WL9+Pddcc81M7YIQQkzJtp4hntyZPeF5HVYuO2EJkJ0869g5DQD0RxLsGTj8LkbFkuXpaevJr7RN1EBFSokkcSGEMCuZznDro68QHE42rJrXyD+sXgrAyrw7QDZ1Ds7K+Cbz2LYOrvrVWq7//dNcfec6HtvWMdtDqhlKqVylbZPXib0CEz3i8GOz6MwdnlRsIJwoSJS+0R1iZ3e2dUK9x86pS5uy6yViNDvctLu8ZR/P0uZs0lYpRedQrOzbn6qtnQEg23PXYbVg0TV29VTudw69vg73O96W+z29fSeJp56bxRHVNr2lafzqd6VQcflOMR0qKmn71re+la997Wu8613vOuQxpRQ/+MEPuOmmm3jHO97BqlWr+N///V86OjpyFbmvv/46999/Pz/96U857bTTOPPMM/n3f/93fvOb39DRIR/KDgeaptHQ0CC35ImiVFq8GErxv8+O3j3wnhOXFkyadcrCltzPz+/tndGxVYJytUcoqLRNTl7lUGlxUg4Pvr6P9/38Ea773VOSuCijwWiCzoTGYHR2b3sU1aHaji1KKW5/egu7+rNJjlafk0+8+Tj04fEfN2c0abu5Y2BWxjgWQyne6Avyy+e2cdM9z3NgKEIglmAomuCHazdVzYWrSo+XQCyZuyNGqmxnR6XHyGxZ2JTXIqE/e2HBUIqHNnXmlp93bDtWi07aMIhnUiz2NBwy0Vg5LGnyYdV0DKXomsWkrd3nGXP51s5g9gcNPM5skcP+gQip9NjtFCqB572XgXW0ICP8i19LtW0Z5R9XMt0Tf/9MPPEMof/5Bcqo3HipRhWVtJ3Irl276Orq4oILLsgtq6ur47TTTuPpp58G4Omnn6a+vp6TTz45t84FF1yArus8++yzMz5mMfM0TcPhcMiHFVGUSouXJ9/o4o2+7Iel+fUezj+ysJH76ryk7Qt7DvOk7RTaI+QnwiNFtEeotDiZqt39If7t3hfpC8eJpdKEE6mqSlxUqse2dXD1Xev53F9f4Oq71ksiXEyq2o4tD27Zz/odXQDYrTo3nLeq4Hi6oMGD35n9/bWuQdIz+KXt4DsHhqIJ1u/o5N/Xbeajv3mcm/76PL9/eRfxVBqLpqGhkcwYRJNpuoOVV+02lkqPl878Scikn+2sqPQYmS2FfW2zVaOv7BmkO5D925/b4ObY+fUADCSjtDo9tDvLX2ULsLjRl7vQNVuVtpqmYbHbDomTwUiSnkD2GDq/wc2Rc+oAyBiKvf2V2/LG0tqC620X5n5PbX6d5MubZnFEtWXkuBJf9ySJR9cXPqgfeqwJ33EXQ//6Dam6LaPyNWmZZl1d2Q+JbW1tBcvb2tpyj3V1ddHa2lrwuNVqpbGxMbfOWBKJBInEaFVMMJhNmhiGgTH8gVPTNLThWxnyr9xMttw46AOr2eW6rh+ybbPLSx17Ne6TUoq+vj6am5sLTkTVvE+1+D5Vyj4ZhkFfXx+tra25152tfYql0tz1wg6yjbU0PnDKMjQUxnDfIE3TaHQ7WNrsY0dfkD2DIboCEdrrPDX/Po2IJTOAQgFOi557ntl9yrZHyG4nnEhhGMaE6/eHY7y25wBHLZhLs89V1n2a6fdpKJbg6w+8RCKdwaJppDMKh8tCNJmmKxilyeOsun2aaIwz9T71h2N85+GX6YskcFt1DEPxw7WbWDmnnkaPsyr3qRbfp0rbp5FzUHNzM1artaL3aWv3EP/77DYge/S85k1HsaDec8jx89g5DTy1q5tYKs3OviDLW+qmfZ8e3XaAH63dnGvZsLjJRzyVLpgmRQNsuo6uaWSUwgIk0gZOm4U2v6sqYi+TydDb20tzczO6rlfc39OBQJSRc2u7zzXpuVWOEeXfp8mOKVWzT+TNS5/3+MhYDjbZ8vmNLtCyd3Xv6ctWjT76WlfuNS5c2Y4GpI0MiUyahXWt6GgFMVyu96nd78JhsRBNp+gYTtqWsk9TWa6UIjEUxFHvR9NGvy9v6ci2RlDA8jl+Gjx2XtzVjwbs7AlxRGthIrvUsShDlT3H4nn/e4jd8wAMLw//4tfYjj9OjhFl2CfDMOjdsg3tlu8XPN95wTmAwtLehhGLE/v9X3KPxR97nP7OLupuuRlLS3PF7dNUlpfzfTr4sfFUTdJ2Ot1yyy18+ctfPmR5b29vrl+uy+Wirq6OYDBILDZ6Vczj8eDz+RgcHCSZHG2U7vf7cbvdDAwMFMzi2dDQgMPhoLe3cCKhpqYmLBYLPT09BWNobW0lk8nQ39+fW6ZpGm1tbSSTSQYHB3PLrVYrzc3NxGKxXOIZwG6309jYSDgcJhIZvUpWi/vkcDhQShEMBgsS8dW8T7X4PlXKPhmGQTAYpLW1ddb36Z4tnfQGI1isFk5e2EK7LVMw/pF9Wl7vYEtn9t/g0c1vcPma42r+fRrZp1gqjaEUmXSGSGCQnmSkpH3y+f0YGYOMYdAXCNHT0zPuPr3YHeE/nthKKJ7A79zKR05ewpsWNVXl39NQLMmPnnqDgWgCXdNIK4VFKfojcZrddhqHb4Orpn0aMdvHvQ0799Ebzs5yHUkZtLvsRBJJXt/TwfJmb1XuUy2+T5W2T4ZhEAgEMAyD9vb2it2noViSb6/fRtpQ6JrOOYsaWerRcu9L/j4tcOukh++KeGV/P0saPNO6T3u6+vjewxvpiyRQSpEh25phfp0Ly3AywmnVWTmviZMWt9PVN8CvNuyhN5JAI9vjPJ7K0Buu/NgbGhpicHAQwzDQdb3i/p46AxEymezFCKeRoKenR44RM7xPI8cUXddpbW2t3n2qq8MwDDLJFCoYJm5Y0Sw6zno/mUSSVGR0jLrNisPvJR2Lk46NfvezOOzYvW5SkRhaIkmz00JPOEnXYJR1W7oJRBKgFMua3bTpGTKJJH0qSUMStECUnlB82t6ndreNoViM/mCMWDKDzUib3qdM3gRtVpcDm9tFMhTByLsrzeZxYXU6SARCqMxocsjmc4OC+GCQ/DrJbR0BFKAyGZa4NFxWA5XJgMXCrp4w8YHA6MoauBrrMVJpkqHRWJrsfSKRIpwapCeebaVStthrbcZ5/tnEH1oLQPK5l+h+8hmaTz9FjhFT3Ccjlcb4/n9iCeX1Nn73pSQ+8J7cPg0MDMDCufAft0MqewE1tWU7fVd/Ej7yAdixE3r6cC6cj+8dl9Bvt8qxvL+fUChEMTQ11mWQCqBpGn/84x955zvfCcDOnTtZunQpGzZs4IQTTsit9+Y3v5kTTjiBH/7wh/zsZz/j05/+dMGbl06ncTqd3H333WP2yoWxK20XLFjA4OAgfr8/N57ZzsSXurySry6Ue5+UUvT29tLS0lJw5bCa96kW36dK2SfDMOjt7aWtrW3Mq8IztU+94Rj/8sdnSRkGVl3nO+88nTafc8x92jcQ4jN/zrZ7Obqtni+97eSaf59G3PLgy2zuHEABt7/v7NxkZKXs00fuXEc4maLd5+LWd68pWL8rEOGVjgGe3d3DPa/uI2MY2V5Cmkaz18kvP3gOTV5XVf099YZifP3BDXSHYsMf0DXe6AuQMRRWXeerl57MhUfNr6p9qqTj3o/WbuJXz+/AUAqdbPuORo+Tn773LKm0lX0ad/nIOailpaViK227gzG+/uBLdAVj2Cw6x81p5LMXHI9FP/QzlmEY9IXjfPL3TwFwdFsDN7919bTu0/O7e/j43U+ilMqtl1GK0xe3cdbSNlbNa2JZix+bxZIb40Akzv8+t52ndnVjs+gc3d7AFy86AU0be59KHXu536dMJnsxt6WlpSIrbb/z8EY27O9DAf/+92+iyeOUY8QM79Nkx5Sq2adkEvWe9xBMxXn6tu/RUt+U287B6xa7/L6XD/DczmziRyNbTapr8NHzV9Did5I0MvQlopzcMIc2l6/8+5S3/I5ntvKnV3dhKMXVb15e0L7BzD6VulwpRWIwiKNhtNI2lkzz3b+9hlLQ4LHz8YuORNM0fvLwNnqCcTQN/uWSY3HZLRNue7Ll+yJDHONrYal/9D0tV+yl39hF3xXX5pY5zn4TDbfcLMeIKe5T+Je/JfJfP8+tYz16BY3/+T00q/WQ9VOvbmHo81/BGBgseC00LfuHp2VL3v03fqqgpcXheiwPBoM0NDQQCARyecexVE2l7ZIlS2hvb+eRRx7JJW2DwSDPPvss116b/eNcs2YNQ0NDvPjii5x00kkAPProoxiGwWmnnTbuth0OBw6H45Dluq6j64Vtf0f+8Q823vKDn1/KcrOvOd3LK3mf8m+1MPO6lbxPpS6XfSpun0Z+ns19+u1LO0kbCg2Ni4+ez5wJesHNb/Ayx++mKxhja0+AYDyJ32mv+fcJGJ7gRBtOitlyPcFKGaPHYSUQS9IditEZjNEdirLxwAAbD/Tn+hvGUmkyhpGr1gLoCcX4xXPb+eQ5K7FZxj7OmNmnmVjeG47ztQc20BuOo6HR6nNy01tWc8fTW7NJC12neTgJPd7YK22fKum4t/FAP8/s7qXN56I7FMNQCptF57pzVtLsO/RvuRr2qRbfp0rdp/zPK5W2T+t2dPHle18glEihaxrLWur4xDnHYbOOPTmPruu0+t25c9S2niHi6UzuAlu5xxiKp/j1i9mLJYZS2IZnO693OfjKpSfT5HEesh1d12n2ufnYm49j90CY3nCc17uGeGJnN29ePnfM9adj7FNZfvD3k0r5e+oIRgENh1Wnyeua0jm6UvapnMtnap9m8pgybfuk62hnnEE0FgSLXvD4WOMoZvnCZi/P7+wnYyjSGQOrRefkpc201mXbXg0ko7Q7vbS5fejaoeMs5/t0RHMdVk0nbqTpHIqxuGXs/rml7quZ5SOPvdETZiQ/deTcutx+LWn10hOMoxTs7Y9w1Ny6qb+mfujn53LEnm3ZETjOPJ3EE88AkFj/FOnde7EtWSTHiBKXJ1/bSuSnvxxd7nLS8OUbsdjtY67vWHkMzT/9EQOf+xLp7TtHV1BquOdJNsiC3/w+jhOOwzq/cP6Ww+19Gu85h2yjqLVmSDgc5uWXX+bll18GspOPvfzyy+zduxdN07j++uv52te+xl/+8hc2bdrEFVdcwdy5c3PVuEcffTRvectb+Kd/+ieee+45nnzyST7+8Y9z+eWXM3fuoR/ERO3RNI2mpqZxTxRC5KuEeNnSPcTTu7K3TficNt59/JIJ19c0jZOHJyRTCjbs65v2MVaKkYnInDZLwZfBUoQTKXYPhNjWE+Bd//0AN9/zAg++vr9gQhqbrmO16Fh0HYfVQkYpdE3jmV093PTX59k7EJ7gFSpDdzDKV+57MXvrPtDud3HzW0+ixevi/CPn4bJZsVp0nto5ft93Mb5wIsV/P/k6AD6nncWNXubXe3jr0Qs4d4V87hATq4Rz0Hj6wjG+et+LhBIpLJqGoRTBeJJUxpj0ucfNbQTAUNlz3HQIxJJ89f4X6QzGaPO5sFp0PHYbjR4nnzpv1ZgJ23wOq4UPrzky9/uvnt9OMJ6c4Bmzbzbi5eAJ3saTyhj0hLLnzzl+95TP0aI0lXxMMcVuhxtvpOf6T6AOSg6VamGzh2giTVcgRk8oQVcgRqM3u+1EJo2hYJG3fsyEbbktbvLm/ka6yjAZWTCWZFdvmMEsnPYAAQAASURBVGCs+GOYo85X8PvWjtHbyY+cM1rxtyQvobyrp/I/93qvuLzg98gvfztLI6l+RjTG0Je/BZlMbpn/ho8dkmg9mKW9lab/vBXL/Ik+B2tE//pAmUZa+yqq0vaFF17g3HPPzf1+ww03AHDllVfy85//nM9+9rNEIhGuueYahoaGOPPMM7n//vtxOkc/mN155518/OMf5/zzz0fXdS677DJ+9KMfzfi+iNmhaRqW4VvghJjMbMeLoVRuYheAf1i9FE/eTNzjOWVRC/ds3gvAC3t7x6wOqkUjSduxqrbM6I/E2dodwFAKi5adlKY7FMNls2K36hzZVs/x85o4fl4Tb/QF+fd1m4km0zhsFtzDSc69g2G++NfnuPykZbz12AUV+QW1IxDha/e/xGA0+yF+bp2bm96ymgZ39s6SVfOa8DisRBJpXtjbSzyVwWkbu4JOjO3nz2zN/fseM6eB1zoHsVh0AonULI9MVIPZPgeNJ5HO8P3HNhGIJ7EMV4O0eBykMtl2CZMlRI+b08jDWw4AsKljgBPnN0+4vllD0QRff2AD+4eyvekWNHj51jtOQ9M02vyuScc34oT5zaxZ0srTu3oIJ7KTgX70zGPKOtZymul4eWxbBz9cu4loMo3bbuW6c1aOezGqOxTLVenNneBuITG9KvWYUhkUgVgKQ2XbIlgtOvdsOMBxC+oJqzjz3D5aHIe2KZgO8+u92HQLkKJjKDqlbb20e4DfPbuHRCqDw2bh709bxOrFjRM+R9O0ggrmdMZgR3e2t6bTbmFB0+i/w+IWL5qWvVV8V2/lJ23txx2N/aQTSL74MgCxhx7De/UHsc6bM7sDq0LBH/wnmX0Hcr87zz+7oKXBRHS3C9uRy8ns7xh3nUxn95THeLioqKTtOeecM2b/kxGapvGVr3yFr3zlK+Ou09jYyF133TUdwxNVwDAMenp6aG1tLbrcXBy+Zjte/rZ5D691DWLTdZY0+zi3yOTrspY6/E4bwXiKVw4MkEhncIxzu2otybZHALd9aqeurmAUTSOXjLBbdHQN/vGkpbzt2IUF21/c5OP4uQ28vqeDoxfNJZLK8B/rX2X/YIS0ofjV89t5aX8f/3zWMUUnCmbC/sEwX3tgA4Hhqov5DR5uung1da7RihWbRee0Ra08uq2DRNrgpX29vOmI9tkactV5dncPT+7MfuB02y3881nH8K/3PE9PIEJnYGpfwsThYbbPQWPpj8T53iOvsL0ngD58UavJbSdtKLwOG21+16TbOHZOQ65n5OaOgbKObyCa4Gv3v5T7G2t0O7jpLasnbCs0kQ+euoKX9/cTS2VYt72TNy+bw9HtDeUcctnMZLz0R+Lc8uAGBqMJnDYriXSGH67dxKp5jWOe6zoDo5O7zKmbmcSXOFQlHlMqRX84icWi5VoY1XvsxJMZOoNR/H4LCz31M5bstll0FjR4CPUk6A3GSaUNbFbz71cwluT/nt7NQCSJ3aqRMRS/e3YPy9q8+F3jVygrpYgPBHA21qFpGnv7IySGP2Mvb/cX9Cx32CzMbXBxYCBKbzBOKJbC55q8wGQ2ea+8nIHhpC0Zg8hdd1P3mU/O2njS+w4QvecBMp3dWOa04b70YqwLJq5WnY1t5os9up7YPXmVsM2N+D79cVN/I5a57WDRYZw7dCxz2qY6zMOGHM3FrCr2tishas39r+3j6w9sYN9gmN0DIY5pbyj4kDQRPa9FQjJjsKnMX4orkaEU8eEPlFOtBm33u2lyO3HbrbT7XXjsVlq8Ls5dMXfMhHCjx8nyZi+NHieLGn184+2ncsmxC3Mz7r7WOchn//QMT77RNevHtP5InEe2HuDmv72QS9guavTyr28pTNiOeNMRox+YRhKQYnKBWJKfPvV67vcPnXYkTR4n7f5s4iicTBGWaltRZXb2BfnXe55nV38Iq0VnfoOHFq8L0PA6bFx3zsqiLk55HTaWNGdvvd03GGEompjkGcXpj8T5yn0v5hK2TR4HN7/tpJITtgANbgfvPXlZ7vefPrWlqBYQtW79jk76I3E0IJnOEEumORCI8H8vvTHmLdj5F6rm+qXSVkxRPA5vfzuL33sFerw8x48mrx2/y47LZqHebSeayN5BpawZ5rl8NNlnNm6XNtXlLozlt+Yyoz+cJBhPAYpUJlv4lkhlGAiba/WytXPs1ggjjmgdbZGwuxqqbU86Adsxo+1vovc8SKavf1bGEr3nAXrfezWRO+8m/ug6InfdTe97ryb6twenvs27yrdNyCaCg//5MwY++yWGvvLt0Qd0Ha7/KLrfN/6Tx+C+9GIYryBTKdxvv3gKoz28SNJWzJpHtx7gH25/mGt+vZ6rfrWWx7aNXz4vxGwrZzLuiTeyk7ukMtlJriy6xp9e2W1q2ycNJ20h2yKh1o0kbGHq7RGaPE6uO3cl9W4HsVTGVDICshUSHzh1OV98y4k0ebKtBqLJDLc8uIF3/c+DXP+7p7j6znUzfkx7bFsHV/zvY9z452fZ1DFAKJ5kSZOPm96yGr9z7IqLo9sbaHBnH9t4oF8SjUVQSvHfT75OOJFt13HKohbOXJqtUJ6TV4XYGZRqW1E9nt3dzZfvfTHX7qPF6+RHf38Gd37oPH5w2Zu4/f1vNtWneeXc0dtzX+0cnGDN4vSEYnz53hdzyY0Wr5Mvve0k2nyTV/5O5vwj57GsJZuo6AhE+evmPVPeZjXbPxjmDy/vyiWUlFJkhieReXRrBx+/+wl+vP5VdvQGcs/pyDveTSWJLsR08bvsvOe0RXicNuKpDC67lb87eR4NbseMVtmOWNLsw6rpGErRWWJf2yavHaUUhsp+Ngkn0tiseq5XbzGUUmwbTtrqusbStkMTc/kTpe2sgqStpmmFvW1TKSK/+cOMjyO97wCBW76fbfBuGNn/Z7L/D9xyK+n9BybfyFjb/Ob3C7Y11W1CYSI48cQzkBz9PuD54D+i5SXBi2VdMI+6z9+Q7Udy0N+X/YSVk/bGFaMqqj2COHz0R+J886GXGYolsGgafeH4hLddCTGbHtl6gO8/+gqJjIFnkr5uEwnGkvzy+e08tGU/yVzCVqfV5ySaTBfVK3DEyrmNOKw6ibTBi3t7yRiq6ErdajTSzxbAZZ96K4hzV8xl1bxGuoMxUz0Q8x07p5FvveM07nhmK+u2d9IdimEoRcqqk1FqRo9p/ZE433t0I92hGDqQUYrBWIJrzzoG7wR9knVN4/Qlbdz36j4yhuK5PT2ct0I+RE1k/Y5OXhqeANDvtPGRNUflvuy1+UaTFV2BKMtb6sbchhCVQinFH1/Zzd0vjc7yvKK1jk+ftyp3e20px7Dj5jTy51eyyc9NnQOcsbT01ivdwShfvf8l+iPZirt2v4ub3rK6bMdWXdO4es1RfOGvz6EU/GnjLtYsbjssk4/BWJJvP7yRtKFo87kIxpNYdJ20YVDntGO16KQyisff6OLxN7o4otnHhUfNZ0dvgFgqjU3XD8t/N1EdVi9uZFmbl4FwkkavnaCKMc/tp9Ex8zG7pMmXNxlZ6QUhfqeNwWgy16t3Rbt/wtYIB+sJxhmKZC/WLW72jnk324ImDxaLTiZjsKsnjFKq4vsmO848HesRi0nv3A1A5P/+SPpAJ9aF88veSmAs6T37GPzCV8evNB2eiMt/7YdNbTd6zwPDCdCxtlvaNgsSwWNs13HhOZRahuC+5CLsxx9L9M/3Ef3zvahwtpVOcuNmUrv2YFuyqMQtH16k0lbMiv2DkVzCVtOyPXgiw0mrqdB1Xfo4iaIVEy/9kThfvf8lOoNRgvEkPaEY33t0o6mqWKUUa7d3cMMfn+aJN7qw6Tr6yOQuPieR4Uk+iukVOMJm0Tl+fhMA4USabT1DRT+3GsWSeUnbKVbajmjyODlmTsOkX/wnihOPw8bH33wc7z5hMYpsn1zDgFTayCXiZ0JXMMpAJIFOtsLAbbPitlkJxSevnD0jr49tJbZImO2WEweP5Rd5kwd+5E1HFXw5mlvvwWqzoqHRFZqZ915Ur9n+zJLKGNy2/tWChO1ZS9uz1fkmvvSP5ci2emyW7Jf6zR0DE85ZMZHXOwf5zJ+ezR1L59a5+de3nlT2i2GLm3xccuxCAFIZxc+e3lLymKfLdMdLKmNw62Ov0BvOHmtXzm3kN1ddyG3/cCZ/uuZibn//m7nk2IV4HKPn4J19Ib778EbWbe9k32CYfUNhntnVMy3jE5Ob7WNKNfC77Cxu8WKxgV23sNAzOxdXFzR4sWjZ96ljsLSU2M7uMG6HlfY6F61+B+11LjqGYoRiE3/20zQt18+2oDXC3ENbI0D2O8fCpmxiOxBNMhQ1135hNmi6jveKfxxdkM6QWP9k2VoJjCf1xm4G//Ub9L7vn0jvmviujVIm4sp0dk+QCC5tm6OJ4DHoOokHHp3SccU6fx7+j32Ehq99cXShYRD68e0lbe9wJEd0MSte7x5EKXK3XaUNAw1MJa3GopSiNxhlc0dlfMEXlU0pRSaTmfCL2dbuIULDM2ijsjOsdgai3PLgy7y4txdjki91HYEIX73/Jf7rideJDN9O7XfZ+cCpy5lT5yZewu35I07Ja5HwfI23SIjmVdpOdSIys4qJk4uOXsAcvws1vH40lcZQasrHtGL5nXbShpG9hRWwWy14ipw06IgmX2691zsHGShT/8lyeGjLft5z+0P8013r+dAvZ7eNjqEUP3n8tdyEeGcubeeURa0F67T5nMMfphVd0h5BTKKYY8t06I/EeWZXN1/863O5CzUa8N6TlnLtWcdgs0z964HNonNka/3w6yXoKuEC1h9e3sVVd67l1c4Bdg+EsFt0bn7rSTS6HVMe31guO+GIXMubzZ2DPLmza1pep1TTGS9KKf7nydfZ2p1teVDvsvMvFxzP3Hp37uJmm9/NB05dzm3/cCb/78yjWdzkI50xcneZWDQNpeCHazfJZ/BZMlvHlGo0kIiywF1HvX1mPqcdzGWzMrfOja5pdAViZAzz79mO7hAAFl1jaVt2ArFMxuCJrRNfOFFKoTIGSqmCpO2K9rGTtnBQi4Seym+RAGBdvqxwgaIsrQRgtP/r4M23EPzPnxFf9xSDX/gKfR/8f8QfWTdhYnVEKRNxZZ8zfpVzKducPBHcVZbjiuPUk3CcdlLu98STz5J4aeOUtnm4kKStmHHhRIqHthygzefK9cvSNY0lTb4pV048uu0AH75zHZ/83ZN8+Fcz31NSVBelFP39/ROehN7oCx7S103XNPb0h/juI69w3e+e4i+v7CYYL7zqnMoY/P7lnXzuT8/yetdQbvmbjmjj1nev4bpzVnL7+99cUq/AESfMb85dGH1xb29Nf0iPJcvX09asYuKkyePkhvOOp9nrzMWIx24t6MU7nTYe6KfVmz2mWi06PmfxFwI0TctV2yrgmV2VUW27ZyDEl+99kUAsSTpj0BeOzWoy4KEt+9k83Juz0e3gQ6etOGSdVq8r+8EWJGkrJlXMsaXcRnpff+LuJ3lsWweheBK7VedT563k71YtLustr/l9bTd3mpswsz8c49ZHX8n1ftc0GIwmSBvTN0mY02bhw2tG+/b98rntFdXnezrj5c+b9vD4G9kktd2i8y8XHD/u+cNhtXDO8rl84+2n8OE1R2Kz6Fj07N1DdS7bjN5lIgrNxjGlGoVTCVxWGwtmqcp2xBFNfnRNI20Y9AbNfbYxlMolTx02C+85bSE2aza18+KufgKTVMMmAiFC8RQdA9nPKm31Luo9499hsSQvaburSpK2sfsfHr+C1FAEbvkBiZc2YkRGP68dnIxN7zs0sVswEdgj64j88rcMfv7LxNc+WfzgSpyIy33pxdn+uGXcpmVO29jdFobp7W1lO674PvaRgvck9B//g5rG83qtkJ62Ysb9ceMuosk0Pqed81bM5fXuIYai2dkvOwPRknth9Ufi/GjtZnqjCVAQTaalT66YEkMpntvTS5vPRXcohs9pQ9M02nwuRi6I94Xj/PrFN/jdyzs5fXEbpy1ppTMQ5YHX9tEXGa1YbPE6+fCaIzlhfnNuWZPHOaXY9DpsHNvewObOQXpCcfYNRljY6J38iVWooKftGP22KsFIn9zbn9rC83t6sVp0/vPx1/jyJSdPa79hQyke2rIfn9OOy2blE28+jmPnTt72Id+blrTxh5d3AfDkzi7eNnyb8GzZPxjm3+59gVgqPdpGRynCiZSp3s/l0hmIctcLO3K//78zj8YzRq9gm0WnwWUjmMpW2lZD3zdx+OiPxLn10VcKel/3ReJ87e2nFJybyuW4uY3w4htAtkXChUfNL/q5a3d05v7+bVYLrT4nkYS53u+lWL2ghVMXtfDcnl6C8RQ/e3oL5x85j3a/u2Y/Sz67u4ffDr9PAP989jEsbR6/4m6EpmmcuriVVp+LUDyJx5FN2Hod5to9CTHTBpMxVvia8dtm9296SZMfyw6dtJGmayhGe33xfzedQ7Fc67BFzR7iWpKTj2ji6W3ZeS4e39LDpasnPuZuy2+NMGfiv/l5DW4cNguJVIZdvdXR1zbT2Z0tSh0n15jc8AoDH/8saBrWxQvQvF5Sm1/PJhWVAg0iv/o/nBedi3XBPFQoTLqzm8T6p4a3MH4S037KanxXvY/0gU4Ct9wKaAXJVvuaU0qaiEslx7+QqDmd6PX1prfpPO8sIr/87XiviOvSiynXZTjbsiNwve1CYsPtKVJbthN/eC2ui84r0yvUJqm0FTOqJxTjwdf3A2CzaFx5+pH83crFWIdvxXtse+mVsV3BKMF4CmVkTyKGoRiIJuRqvyjZKwf66QvH8TntXHLsQv79PWfy2w9fwC+vPI/PXng8x89ryt2gksoo7n11Lx/99eN86W8v8MzuHkLxJJoGb1+5iO+86/Rp+VJ88qLRFgkv1HCLhFhq9iptzWjyOLnu3JXMb/AA2Urtv2zaPa2v+fL+fnpC2QqN1QubOXv5HNPJhXn1HhYNJ/x39oVmtUr05f193Py3FwjH04VV7kb2/zOdDOgLx/jGgxuIDrc3ueCoeaya1zTu+i3Dt1dHk5miegoLMVO6glECsWSu97XLZsXrsGG3TM+FsMVNvlz/082dg5O2ExqRMRTrtnfm/v79DhuheMp07/dSXXHaCpw2C6F4kl8+t51P3P0kV99Zm3dv7ewL8uP1r+Z+/4fVR3Da4uJvr23yOLnunJX4nPYptXsSooCuw8knEzvheFQJF70zyiBpZIilU4RTCQLJOAOJKL3xCAeiQdw2+6xX2UJ2MjLLcOKzc8jc99U3hlsjALQ3OVDAkYs82K3Z4/mGPQMMRiautt3WObqNFZMkbXVdY1Fz9rNtNJGmx2Rl8GywzGkbv9I2n1Kkd+0ltem1bLLWMIb/r0Ap4g88SvinvyTy2z/mJWzHec15c2j6nx/S9MNbsJ+wEvclF9Hym9vxvO/v0TyjhWmpza9jxMz/G0Z+/buC3/W20TZdKhYjfMedprcZf2ht4QJNy/4N6hp1n78B63zzd4NOxHfNleAYbXMU+snPUYnK75M8myRpK2bUb17cQXq4RPFtxy6kyePk7GVzGDkfr9/RWVJPH4B2v5tUxiCjyN3GHk+lmcYCN1EDJrpK/GjeF7RLjluY6+umaxonzm/mxotO4PuXreGSYxdit+oFfd0MpRiMJfjchcfzvpOX4bBOz5fikw+TvrazXWlrpprAYbXwz2cfm/uc+PuXd7G7PzTxk6Zg5EIYwEUmKtkOlj8h2VOzMCGZUor7X9vHtx/eSCyVwWrROW5uI20+V67lRLPHSd0UJ0gy47FtHfzjzx7hqZ1d7B4IoWvwvpOXTfic1rxkRVdIWiSIic1kpVK7353rfa2UwmbR8RbZ+7oUuqZx7JwGIHv3064ij4Nrt3fQG47T5nPhtFnIKDWjycAmj5NLjl2YO6cn0hnC8VRF9GotZ7z0R+J895GNJDPZ6q8zl7bzzlWLTW/n3BVzp9zuSZRPpVc/FsVuhy99ie7PfRpln/ycnzIy7I8G2BcJsC8aoCsWZjARI5JJklIGmgYuq40mh4vF3nqO8bfitU1Pb2wzFjf50Iffr44hc58XdnaPtihobbQxx+nFZtVYfUT2mGsYivVbxv8slzQMdvZmj8k+l405RVT5VltfW/elFxfVW7ZsNA3b0UdiP/aogsXW+fPw//PV+D9xTW6ZCoaI3fuQqc1nenqJPfBo7nf76uNp/e3tWObNyS2L3P3nMVs6jCe1aw+R3/5xdBc8bpznnonn/e+h5Te3477kouFdK99xxdLSjPe9l+V+z3R1E/n9n8u2/VokSVsxY97oC/L08IyyPqeNv1u5GIA6l52ThhNPgViSl/f3lbT9UDxFvcuebcI+/AW/1evi1y++UXR1hzi86LpOW1vbmLNhDkYTvDicBK132TlxwdhVsiMTc1x/7krcdisumxWrRafJ68Rjt2HTpzfB2ORxsrjJB8Du/tCsf6GcLtHk7E1ENlGcjGd5Sx3vGD7GZQzFjx9/lVSm/D2bOgNRNh7oB7ItOMaL02KsWTJaXfXkzq4Z7YmXNgx+9sxWfvHsttzn65MXNvPjfzyTX155Hm85ZgGLG33ous7ze2bm4kR/JM73Ht3IUCwxeiEmmiiIxYPpus7yea1owzX4nQFJ2orxlXJsmYpEOkOj24GujfQftU97InTl3NGq9E0dk/e1jaXS3L1hJwA+p51b3/2mWUkGHtlWj65pWDSNdEahULPeq7Wc8RJPZfjuwxsZHO57uaK1jmvOOLrkL+ZNHmfuwraYPTN9TKkU3fEw81x+Tm2ez5uaF3Jm6yLObF3EWS2LOatlEWe3LuaMlkWc3DSflfXtzHNP3v5jJngdNlq92cnIOodiRX9fTaQy7BuIAFDvsVPvcTDfU8cR3gaWzHfiGC5u2LhnkP7QoZPLappGZ8pCJpN9vRXt/lzyeCJHtI4mbXf3Vn7S1rpgHnWfvwF0DSz6cPXocAXpFz9N619/TcO3v4z3qvehNzVMuj2tzo/mm6ANnaZNOBGY6+Lz0etHK7wjv/2DqX6ukd/8ATKjdx56P/APaHY7/o+PJoNJpwn++38XtT2lFMFbf1ywzfp//QwNX7sJ/7UfzrVvmI7jiuf970FvqM/9Hv7FbzCCwfGfcJg7vI7oYtYopbjz+e253y87YUlB4uWc5aMfxB8t8fazezbvwee0sbDRw9VrjuTkhc34nHa29QT42+a9pQ9e1CylFIlEYszk1Lodnbm+tecsn4t1khPVwgYvDW4HTpuFOXVuDEPN2K2cpyys/RYJhZW2Mz8R2XhxMpF3n7Ak13Jg32CE3w0nIsrpoa2jVbYXHjW/qA/d42n2OjmqrR6AjkCUPQMz84E8nEjxrQdf5uEto5UBf7dyEZ86bxUum5Umj5PLT1qWa6OTX1k8nbqCUYaiyVxP3XqXnbShJkzaKKVoclkZ6XPWJe15xARKPbaU6ok3uvA57Sxu9HH1mqNmJBG6cs7oF+HNRSRt/7Z5L4FYNpF4yqIWTlvcOivJwLl17tzEkkophmLZY8Fs9motV7z0hWN8+d4X2NGb/YLc4nXy6fNWYbPI18JqN9PHlEoQSMZxWW0s8zUxx+Wjxemhwe7CZ3PgstqwW6zoWuXG9hHD1baJdIaB8KEJ1rHs7g1jDH9Jmdfswm9zUG9zssTbyFyvl+MWZ4s5lBq72lYpxZb9g7mOrEfOLS6J3ep34h5uebOnL5IbQyUbbU/wHpznnV1QQWppasR55un4/ulKXG+7KJvYHYuu4/nAP9B+3900//RHjH8b78QTgWkOO+7L/i73e2Z/B4knnilqP4xgiOhf7sv9bl22BPtpJwHgOHsN9tXH5x5LPPEMiedfmnSb8UfXk3zx5dzvjtNPxnHWmkPWm47jiu5x4736A6OvEQoTvuPXZdt+rancI5ioKS/t6+P1riEA2v0uzj+ysPH28fOaaHRnb1PZsL+PwWhxJ60RveEYT+3qRgFeq86HTjuST56zMtdv9P9eeoN9g5V/RVDMLKUUg4ODh5yEDKV4dGs2gaRBUV9qR/q6eYd7783krZz5LRJemKEqxJk2mz1tx4uTydgsOteedUxuErK/bt7Dtp6hso0rlkqzbrgPuM2iFVz8KtWbjiistp1unYEo/3rP82zuHATAqmtce9b/Z+++w5yq0j+Af296Msl0ptOGOvSuglIU7F0RXUXFsmBBV1f9uatr33Vtu7quLhawi10RC4KFIigISO8wQxum9/Tknt8fmdxJmJYMM5PMzPfzPDxMbm5uzp2cOTn3vee8ZxCuGtM3KAA9JD0BGbWLVO4qrMDBsrZLN+GXaDLUptzxjbID0OyNGCEEjLJLuRBiegRqSkvblpa+l/9vWqtR4fJR2e3y/ZRiMaKb2fc+uwsr4PR4G923wubEV9sOAvBdE181uulUJG0pKcaAe84YjgSTXpm9ZTZom72B25Zao778tCcf0+d/j6W7jiCvrBpOjwf3TR2O2HZMO0Ntpz3blDblcACXX46e190MlaPxa0KP7EWlx4G+5kTE6TrmKO/eybFQSyrIQqCgIrTZcvsDUhOkJemQZoyBRqWGUaNFv9hkDOkVB53W11ZtOVyO4uPyz8pCYPfRSgC+74Pe3UJbxFiSJGVfp9sbdkqHSNFkZSL2lhuQ8NhfgkaQBmo6lYKA6cKzfcdqavTuX+5udnEx0yXnA7q6hWytCz8N6RxsX3wNYasbCGC++gplZoQkSYj90xxfOWpVPT8PoonvW9lmDx6Rq9Ui9q5bG5xt0VbtiunCc6DuUZfWzfrpl/AcPdaq79FZMGhLbc4ri6BVt68c3bdep1etkjCxry8fixDAqn3h/cF+s/2w0s5O6t0NBq0aOWkJOG+IbwV0jyzw8srt8IQxBYG6rm35ZSiu8XVwhmYmIsUS2siaSOV1654Qo1wUby8oR42z8y1+FDTSVtf+OW1bqmeiBZePzAbga9teXrUDDnfjnahwrD5QCJvLd6zx2WmwGLTNvKJ5J/VKUQYQ/JJb2KapZVbvL8Ddn63BkXLfFL9YgxYPnj1K+S4IJEkSzsyp69gt29X2o213F1Wgm9mXw1qjUsFiCG0qeVLt9HMAKGB6BIoSe4srlQULB6clKDfK25okSRiSkQjA1xfbXVjR6L6fbDoAp8fXT5s6MAvpcaZG920PU/pn4MNZZ+CM/pnolWiBRqXCq6t3dNiAWKnVgX8u+x1VDpeS8sXu8sLYzimHiELidEJyNT2Ip9BRgyxjLLqbIr+oWEv1Sgx/MTL/ImSSBGQkGpGgq2sr0wxm9I9PxOBeFt8NZAEs3xk82vZomQ222r5onxSLMpMpFL1TOlZe21CFE4xtavRuc9SJ8TCePVV57Nq8Da4du5t8jXC6YP3oi7pjpKXCcMbEoH20fbOVwDIAeHIPwvblN40es+athZCL6lJSxlx1GTTdmw44tzZJo0HsrTfWbfB4UD3vjXYtQ0fBoC21uZ/2HEV+7YVr/5Q4jAtY7T7Q5IAA109780PuFFc73Phxj29UpE6twsRedTkdrxjVB1nxvpUu88pq8PnmvJacQpsptTqw/VhZp81D2lH9sKdumvbp/cP7AotEXjdJkjCm9u9KCLQ4L3Q0s7siN9L2RF0wpCf6dvNNPSussmPhhn3NvKJ5Qggs3XlYeXxWTssXIAsUa9ApOShLrU7sKapsleMe7+VV2/GnT9dgT1El8sqqoVOr8Pj5YzGgNj1DQyb2TYehNk/bqv0FbXpzwr8omn8q+cPnjg75RoxaJSk3UQqq7R02wEOdy8/760bOn9onrYk9W9+QwBQJtaPqj3ekvEZJj2XQqnHZ8N7tUrbmJJmNeODsUUiM8QW5Nx4uxdJ2uGnUFvYVV6HM6lRSviTVpn+IZJ5eopaqdDugV2vQ15IETRuvH9GWeoe5GFm51amkUUhLMCDRaEC8tu6aQ5IkZJsTMaFfKnQ633F3HKlAQWXd3/meY3W5Qwekh5fft6PltQ1HOMHYUEbvNibmykuDHls/+KzJ/e3ffg+5rO67M+bKSyFp6l8LmW++DlJMXQC/+rW3IVfVn5nmOXg4aISvKrUbzNddFXL5W5P+tFOgGz5Eeez4YQVcO3ZFpCzRjEFbalOBC0oAwNVj+za6yEGqxYhBtR37gio7djUxGiPQsl1H4KodmTG5XwbiA4Jl/unJ/pFjn2/Oxf6S6Ehy/dOefFz79k+Y+/Fq3PjeCvzUwly+dGI0x33pVdpdSoqBWIMWo3u0fGGn9hSY1/a3TpjX1hbBnLZA/XoSDrVKwq2nDYYuICdrKAvyNGVXYQUO145Q7ZcSh95JrbeoxoSAFAlr2iBFwr7iSrz5627IQkAtSVCrJN9iX43mCPMxajXKKFyXR8bKMGdkhGNvcaWS07d/ahzOyuke8o0YjUaDtFhfp9nh9ir5OYkaciJtS6g8soxfcn0jrXRqFcb2TGnz9ww0JD1R+bmxvLYLN+xTZkxdOLRnVE3XjzPqcMtpg5TH7/22N2Ipt1paXwJv9HmFgEGrbtfc+9R+2qNNiTSPLKPS5UAfcyLidR27/iaY9Ig3+Gbo5Jfbmr3Ru78wMDWCASmGGOjUwZ+5SaPD4MRuGJEdD7k2YdPyHXWjbXcX+AJ5KgnoF2bQNt6kQ5zJ1z4fKrXB0waL7EbSiQRjQ6Xt1QP6U8Ypjx0/rYS3oKjBfYXXi5qFnyiPpVgLjBec3eC+6oR4mGddXffayirUvPFe8PGEQOW//wd46q6rYu+YDZWx6T5uW7UrkiTBMvfmoG3l9zyEqpfnw3P4aCOv6noYtKU2tXjrQVQ5fKOhxvXqhv4p8U3uP6Vf3bTYUIKYLo8XS2o7oZIEnD+kJ5KTk4NWN8xOjsUltSM2hAD+t2o7XE3keGkPpVYH/v7dRhRU2VDjcKPM6sQLy7dyxG07U6lU9erLir35YS1AFi36p8TDYtDC45Xxy4FCFFZF/7TscEaa+9Mj6DSqZoN7ra2hehKu9DgTrhpTl5/xlZ93wObyNPGKpn0XsBjXWQNbZ5St35ie3aBV+37Hv+YVtXpambfX7YFX9gVsLQYdMuNjYHd7QxrtdWbAuS7deaTN0jcE/X5zuof8On9dSY+tG+lwrAP8LVJktEbbEootR0tR4/S1N6N7JActBNseYo06ZVHGvNJqVDuCR8nvOFaOjYdLAQCJJj3OHdyjXcsXihFZyTh7kK8tcHsF/rNiW7v3JU+kvqzcdww7CiqQajFCo1ZBp1a1a+59ah/t1aZEWpGjBulGC3rGxEe6KK2iT3IsJEmCzeVBlb3pWUT7alMjCACZyQYk6WMa3C/dYMHZOd2h00kQAHbnVyK/3IbSGidKqhxQqdXISopBjL7x74MatxNeEdwHlCRJSZHg9co4VGoN/URJEXPVZXUPvDKsH3/R4H6OVb/AGxC8jLn8wiYDrDHTL4I6IM2B9ZMv4TlYNzPPsWI1XOs2KI91Y0fCMPnUJsva1u2KbtBAaHIGKI/likpY3/8YxVfdCNvXS9vkPTuazt2iU0SV2Zz4evshAL6RZqEsKDGuZwpMtfkq1+YVNRvUWLHvmNL5P7lXCrqZDbDZ6t+lvHh4L/RO8q2kebTChg837g/7fFqLEAJv/roH5ba6KWpurxdWl4dT1NqZECKovshCKNMzAeD0dspJ2xrUKgkJRj3yyqqxv6QK177zU1SP3v5pTz5mvbscd336S0gjze21bUEkRtkeX09a6sycLAyunU1QanVi3qodLUqPUmp1YN1B3x35WIMW43q17qg5o1aDUd19I7erHe6QVnwP1Y5j5dh5rAIqSYIMX/kr7a6QR3tlxscoU60Lq+3YcrS01crmV25z4tfaUYkWgxan9E5t5hV1/HUlLeBcCqvZrlPDWqttaU4kUyP4+UfbCgA7CuraFFkIvPvbXuXx9FHZ0Guic6rzH8b0RY8EX7DiSLk1aL2G9tDS+lJS48Bba/cAACwGHZ68cBxeuHxCu+bep/bRXm1KJFW7ndCoVOjXwdMiBOqdFAuNpIKAaDKvrVcWSkoCvVaFHknmoNQIgSRJQk58N0zon6IEXn/aUYg9x6og4Ksr/dMaHmXrkr04bKuA1eNGmbN+ebK7dd4UCe1FN3o4NP2ylce2L7+FbA0OgAshYH33o4AX6WC67MImjytptYid+8e6DV6vsuCYcDhQ/cIrdc9pNIhrZPGx48vRlu2K5/BReHbtCd4oC0AWqHzyX/Ac4YhbBm2pzXy8cb+StmDawExlumhTdBo1JmT7LihcXhlrcgsb3dcrC2WVYQC4cGgvCCFQVVVVr1HRqFS49bRByuixb7cfxs6ChvOqtSWvLPDKzzvxa24hVJLkW5VcCLi8MryyzClq7ez4+rLjWLkSYBmSnoDUEOpstCi1OrDpaIky5bykxrfgSDSO3i6utuOxbzfgaIUVVpcb1Q53syPN7bULJhi17d9Bb6xdCZdKkjD71BwYtGpUO1xYuGEfbvso/PQoP+w+qkwjPmNAJrRhLCARqsAUCasPNN4Oh8Mjy3jj193QqFVItRiRYNLD6vKEPdorcEGywBGxreXHPUeV0fan988I6/frrysp5rq2/BgXI6NGtFbb0hSby4P1tSlzzHoNhmUmtdl7NWVIRl1e28D0ML8cKERuqW/kWI8Ec4MLEUYLrVqFuZMGK33J73Yewe/tmEO+JfVFFgKv/LxD+Q6d2DcNp/fPbPfc+9Q+2qNNiSSvkFHusqOvORGJ+o7TR29OryTfYmRCNL0Y2dEyG5y1f8vpSQak6GNg1DS+CG2MRodLhmTDZFBDhsC+gir8us/3fSBkuV4+WyEEypw2FDlq0NMUj96WBDi99QdQ9QoI2uZ2osXI2pMkSYi5sm60rbDaYFv8XdA+rk1b4Q5YpMx0/llQJ8Q3e2z9hJOgGztKeexcsw7OX9ej5u0P4S2sS8MQM+MSaHo1P7OlrdsV21ffAY3OopTq/V66IgZtqU0cLq/Bitp8gyadWklPEIrAu/4/7Wn8zsq6g0XKSshDMxLRq3YkbWOyEsyYPrIPAN9Ij/+t2hG0In1bc3q8+NePm7Fi3zElaBFn1MErBFSSBItei07ax+owfgyob2cMaN8VNE9UQZUNQgAmrQaSJCmB2/fX74uqznu5zYl/LK1bvdrjFZAkX2ChsZHmQgjlb7W9p/W2tm5mIy4d3guF1Xbfyt1uDypsoadHcXtl/LDbV08lqe3q6YisZGXWw/pDxa0yDXjpziM4UuEbRTA8KwkLrz8dz182PuzRXqO6d0NS7aJAm4+UtmoqEI8c/PudOqBlqSfSA27AFTA9AkXQbweL4Pb6vgNO6Z0asZQ/A1MTlNQ22/J9N83dXhkfBMx8unpsX2VBnmiVlWDGNWP7K4/nrdoR1Xmrl+06oiz+lmjS49px/Zt5BVEUUKmAIUPgyBkIERDMKXLUIM1oRk9zQhMv7ngCFyM7Vt540HZ/UUBqhCQDuhkaTo0QqKc5DmcNzlRSXZXXuOB0e2HWqZFs0Sv7ObweHLFVQiVJGJWYgWEJaeimj4EkoV6aLItRi26xvps+R8vtSiCZwmOcOgmq5LobqbaPvoAI6G9b3/24bmeVKjilQhMkSULsHbN9f0e1yh/6B2reWlh3uG7JQflvI8l7rBBNBUG8x1pn8EhHxqAttYn5a3bB5vLA45Vx8bDeiDWEvqBE76RYJffZgZJqHCqrfwdPCIHFW+tG2V4wtGdIxz5vSA8MrF2dvLjGgfcCpuS1pRqnG3//7nclZ5tGJeFv54zCxzdOw5Wj+6BXogUmnbZVVpWnlqmyu7AuaAGybs28IrqkxZpg0mmg16hh0mmUmwEr9x7DixHIvdeQnQXluH/RWhwptwaNNC+3OaHXqBsdae70yMp3eSTSI7S23kmx0KhUUEsSIHyLrFXYXSGlR1mXV1SXJ7xnSpuNlNIGLFbkcHux8fCJjSarsDnxSe2ilBKAWScPQLLZ2KLRXmqVhGm1uW0FgGW7Wm/a1PqDxSi3+QIwo7snI9ncst9vstmoDBpgTluKpGhIjQAABq0a/VPiAPhShhRV27Fkx2GU1NTdfI/UKOBwTRuYiVHdfYuUVjnc+N+qHW2WX/tEHKu04f3f6vqVc04bhBh946PyiKKGTgc8+SQKHvorhM53DWn1uKCSVOhrSYK2k6RF8OtmNsCs00IlSTha0XifoS6frUDfNEujqRECqSQVLh/SFwkxelQ73SiotKO42onDFQ78nlcGIQRKnFaUOm3oZU7AScndkWWKg0pSIVarh1mjh9Vb/8ZU79rRtkKIsFIk1Ng92FdUFZUzAdubpNUi5vKLlMfegkI4lq8CALj358L5yzrlOcOU06DJDH0mirZPL5guPk95LGqsQYFR/aknQWWKjhm+6vRU30iJpp7v4hi0pVb35q+78fX2QzhcXoPDFTUwtGA6c9Bo2731pw1vO1auTKfrlWhWchxKkgSdTtdobhaVJGHOqTnQa3xV/7sdR/D55gNt+sVRanXg0W82YG9RJQDfhcv/TRuBk3qlIinGgFtPG4z42lU41xwoxJ6iijYrCwULrC8r9h2Dt3ZO9MS+6W0y5bwtJcUYcOfkoTAbtNCqVUgw6ZUFR37JLcJj325Euc0ZkbIJIfDlljw8vmQjqhxuaNQq9EmODQouD0yNbzR4FzgiPhLpEZprV8KVHmdCN4sBkkqCEAJeWcDqdGN/SWWzr/1uV+ACWa27ANnx/KlqPF4ZX249eELt5Hvr9ynTcyf3z0DfbnEnVLYp/TKUKco/7c2Hs5VuSiwN+P2eGcYCZH7+uqJRq5Bi8XWGC6vsURnQochr7bbleGU2J7bXpoJKsRjQ7wT/7k7UkIxE5ee1eUX4YkseAN+NnKvHNr/uQbSQJAmzJ+Qgzujru20+Worvdhxu5lWt876h1hdZCPzv5x1w1a7sfmZOFoYG/P6pc2rrNiVSvEJGqdOGPuYEJDey8FZHJkkSspNiIUFCld2FGkf9xcjsLg/yy30B3bgYLbJiLYjRhDYoKl5vxFk5maiwuiEL30x0AeDjtQexq6wUOpUaoxIzMDQ+NeiYWpUaSXoTbJ4GgrYpAXltS0JbjGz17kL8d/E+/H3x1rBTg3VWpovPhWSoG/FsXfipL5ftex8H7We+enrYxzaeM7XR5+yLvgk5V2xbtyum889qYqStgOmCs9rkfTuSjhWVoFYXzurtIR2vxo5XV+9U8mrq1Cq8tHJ72MefkJ2mXJCv2n8Mbm/wtIzjR9n6GxFJkpCYmNhko5Iaa8I1Y/uh2uFCXlk1/vHdJsx6d3mbfHEcqbDi4a/XK1OCYw1aPHzO6KALlxi9FleM6qM8fmvtHl7gtxN/fQGCUyOc3r9jpUbwm9I/A/OvnoTnLxuPD2+YikfPG6PcoNhfUoUHF/+GvNqbHe3F6nTj2R+2YOGG/cr38dCMRLx61US8f/0Z6J8Sh16JFhypsGJvccNBy+CgbfuPtA2lXQlHUowBd00ZhrRYEzRqFVSShFSLEe+v348vtuQ1ms4it7RKufmTlRCjzBpoK4PTE+CRZeSVVWPpriMtbid3FVYoo/1MOg2uDGjvWirWqFMWCLO5PFh9oKCZVzTvYFk1dhZUAAAy4kzKzcBwBNaV9Nqc2C6vHLEbJhTdWrttOd4vBwqVdndCdlrEAzlD0+v6Ph9u3K8sNjuxbzp6Jjad4iraxBp1uPW0Qcrjt9fuwfe7j7TpIIBw6stXWw8q3xepscaQFgOmjq+t25RIKXZY0c0Qg14xnSstQqBeSRZoVI0vRnagqMYXaQWQkWxAmtES1uc8IjUFKkmCBAGNSoUYgwY2twcWYcK4pCxkmmKhkuqHhpL0JriPS48AAD2Tzcr7Hyhq+tqiwurCJ+sO4q1VB2B3eeGWZdQ4m1/PoitQxVpgPL8uKOneuQeOZcthX7Zc2aYbMwLagf3CPrZj5ZomRrCGniu2rdsVTfdMxP3lbt/dBLXKl9ZBpQJUEuL+cjc0WR3zurw1MWjbhflXb5/zwSrc8G7r3O36+UAhnB4v1JIEvVaNbhZjk7kqG2PWazGudmqu1enBbwfrkmbnlVYri1h0MxtwUq+6IfNCCFRXVzebw3NkVhIq7C7IQkACUFBlx/M/bWnVL469RZV45Jv1KLX6LtZTLAY8dt6YBnPvnt4/E1kJvjvHB0qqg6YzUtvx15cdBeUoqK2jg9MTkB7XcRc3SIoxKFPOR/fohkfOHaPk/yyzOfHwN+uD/p7aUl5pNf7y5Tplar0E4NIRvXH/mSMQa9She4IZ1588AJraUc1vr93T4N+uPSBXljECOW1DbVfCMaV/BhZcPQmv/mEibjhlICy1KWQ+3LAfb6/b2+CNm8BFt87K6d7mF2XlNidKahyQhYAKQLk19Ny7fl5Z4I1f6hZRmDGqD2KNoafLaUrgSNilO4+c8OezLGiUbVaLfr+BdSUtoB1hXltqSFu0LYF+3n9M+TmSqRH8spNjYdSq4fH6Ltg9Xhk6tQrTR2U3/+IoNCwzCecO7o5qhwv7Sqrw1y9/ww1tNAgACL2+HCqrwcf+dDQScOtpg1o06406nrZuU9qNwwFcfTV6/PE2OGt8U+/7W5KhU3f8FFmN6R2wGFlBA0Hb/bWpEWQIZKeYQ0qNECgrwYxUiwEatQpGgwoOlxdxej0mZGTC1MSI3VitHga1Bg5v8Ohfo06N9HjfjKKiSkeDo4NLa5xYtOEwXly6CxsPlNaN8hUCJp2mRTGCzijmikuCgqsVjz4FeOuufczXXNGi43qPFfouvpp6PgTt0a6YzjsT3T6Yj5g/TIfh9ImIuXo6un0wH6bzzmyz9+xIGLTtokqtDvxz6e/Ir/StQllmc7TK3a4Nh4qVXJVmnRaVdhdMOk2juSqbMrlfXYqE5XvrLjy+2lY3yva8IT2UhS0AX6NitVqbbVQKqu0waNXQqlW+C3MhUFhtx5HyE18Bs9TqwGebD+Dhr9fD6vSNIumVaMZj541FamzDwUC1SgpaHGLh+n3tukhaV+WvL/6FhwDfavGdSa8kC544fyz6dvOtEOvyyPj3j1vx5ZY8lNbYW3WkPeCr/9vyy7BoSx4e+vo3FNfmK4zRa3DftOGYPjI7aKGZMwZkIjPe93exr7iqwRGT/tFYgG+htfYWarsSrqQYA4akJ2LOqTm4cnTd6NMlOw7jpZXbg2YYVDvcWHPAP1pVjQnZbZ/fqaDKBkkC1JIESZLg9HhRanWEFYD8fvcRHKptV3slmjF1YOvdLe+THIs+yb56fbCsBnuKmk8v0Rir041VtTfLDFp1i1ewD6wraZa69v4YL0qoAW3VtgDAkfIa5NWuCZCdbEFGXOSnFKtVEiwGLfLKqnG4vAZ5ZdXo2y22zXJzt4czB2ahzOb03WgTAkXVrdOfbkgo9cXtlfHyqu3w1KZ7Om9wD/RPiW/1slB0ass2pd1VVUFVXQ2vkNE7JiGkRbc6sl6JFqhqI2z5xwVthRBKPltJAgamxcOiDe8GeFKMAfecMQLdzEZAlmDRaXDXlKFIMjd9jW7W6GDR6mH11A/KBqVIKK5LkVBS7cDnvx3CS0t3Y1NeGWRZKDPL1GoVks162FyeFscIOhtNVgYMk8bXbTju79dT1LJ1JVorV2x7tSuarEzE3nIDEh77C2JvuYEjbAMwaNtFFVTZ4JZlqOAb8u7xyid8tyuvtBp7i6uQajFCp1b5Ard6Le6cPLRFHfJB6QnoVrsIzLb8MhTX+BauWJPruytkMWiDArvhSIs1wazX+qZaS4C3Nq/kF1vy6qViCMdPe/Jx5Rs/4O9Lfsfe4kpUO1wYnJ6Av50zWsl91pihGYnKwhYVdhe+3HKwyf2jVWun3GhrNU6PsgCZWa9RFl/qTOJNejx0zmgl0CcAvLp6Jy59fRnu+vSXVssr5R+9/8eFK/HEko0oqx1lnp1swZMXjsOIrOR6r9GoVJg5NvCGxX44jluFNtI5bduaJEm4aFgvzD41R+lbrTlQiGe+36yc+/K9+coK8JP6ZbRLmoi0WBNi9Tqo1Spf7l0h4HB78d2OIyG1k5V2Fz4KWBl+1ikDWn1l+MC8vt/tbHlOyRX7jsHl8Z3TxL7prfL7TQu4ECnkSFtqZ6sP1I2gOTU78qNsAX//oFxJoSUArD9U3GH6Cw0psTpg1GqgVvlubnllGUXVduRXhpbjsbV9vjkXB2uD9VkJMUHpt4g6GglAmsmCbEvnz8ecER8DvUYNlSQpuWv9SqqdqLb7gqapCXp0j2k4lUFzpvTPwFszp+DFyyfguXOGYUoI19GSJCHVYIa9icXIvLLAxrxSHCisxidrD+KlZbux5VC5EuTTa9WYMjgNN0zqg1ijBna3fEIxgs7IMGVio89V/fPfIeefDcRcsZ0Hg7ZdVFqsCbEGHVS1C+G4vDJkIU7obtfi2hGwFoMO904dgecvG4/5V08KWlQsHCpJwuTa1woAK/YewzfbDyltz1k5WdBrWhbA8S/aFGfUIUangVqlQqrFiF2Flfjvim3KglThKKyy4dFv1qPM6oBakiALgSqHGzePHwhTiFO6rxnbTxk5/PX2gyiu6Vijs37ak48b3l2BOz9Z02ESzK87UgZPba6mSX0zOtwCZKHSqlW4beJgXDEqGx6vjMJqO2qcbthcHlTaXSc8MqjU6sAz329CQZUNntr2pLDajlP7pOGRc8f47uw3YnhWEkZm+VYNL7M5g0bTA77FF/wikR6hvUzul4E/nz5Myee9Nb8MTyzZiAqbM2jq/rQBbbsAmV9SjAF3ThmKVIsReq1ayb3726Fi/P27jaiy1+/AB1q4YR9sLl8AfmLftDYZ7XVy71TEGnyroa/NK2pR7lhZiOAFyAa2zu83LTZwpC2DttR+ZCHwc+3IfEkCxkdJ0NY/Sl9TO8spOUYPu9vboafHpsWaYDH4BgEI+G5uub0yFm89eEKDAFpiX3GlsribSgJuO21wp+3TUNegVWkwMLYb9J04LYKfSpLQO8kCCRLKrM6gAQz+UbYCQM9uMUjQtfx6PSnGgEFpCYgPI1VVnNYACSp4RXCb1iMpBg63FwWVdqzcVYR/Lt6G3/aXKLl3DTpfsPbOs3MwZVAaTu7XDTec2Rv/d86QE4oRdEbuvfubeDb0/LOBmCu28+A3eRflD1omxRiU1dsTTHqY9doWHa+o2o5fAkbAnjekh5JX80RM6puujDz7cc9R/LTXFwTUaVQ4c2D9lb0lSYLRaAwpF6F/0ab/Tj8V/7l8vFLWdQeLMe/nHWEtBlZUbccj325AtdOtTCWOM+pg0KqVnLahSI8z4ZxBvvNyewXeX78v5NdGWqnVgX//tAXHqqyosrtQUtN2UwRb069HKpR0P6cP6NydB0mScMnw3rh8ZG8I+Ka9u70yrC43SmocOFrRspFBNpcHr63eicJqOyB876NWSYjRaTClX2iB8GvG9YM/08nirQeD6k1QTtsIjLQNp105UaN7dMMDZ41SbvQcKKnGnz5dg0PlNfB4ZQzPTGrXnMv+dvKVKyfi7xeMVdrJ3YWVePCr3xpNKbO3qBIratPamHRq/GFM+AsohEKrVikLB8oCQalOQrXlaKkSNBqSnoDM+JZPwQysK8lmAzS1lbojB6Wo7bRV27KnqBIltalphmUkNTvTp734ZznF6DRIsRjhkUWHnx7r708nmPSI0WmhVvlubm3NL8fzP21t1cBtU/WloNKGfy7bBHftjIHLRmQ3uIYCdW7t2V9pD0a1Bkn6jrvORLh6J8XWLkYWnNfWv9CXV8jISY9DXJj5bI8Xbj2J0+oRo9HWS5Fgd3tQaXcruWplAZTbXNBpVJg6NB1/OjsHEwemwqir67ubjRr0SbFwhO1xvAVFTaYyCDX/7PFaI1dsZ2tXOiIGbbuwKf0z8Pa1U3DOoB7olehbsXJpwEI34QgcAXt2TvcWj4A9XlKMAcMyfCPwiqsdqLS74PHKmNIvAxZD/QCzJEmIi4sLuVHxL9p0cu9U3H36MOUC++f9BVjwy66QcrdsPFyMv3y5DiXVDiWfb4JJB5Uktehi5JLhvZWRY7/mFmFnQXlYr4+Ugiqbbzp8bdDO5fWiyuGK6mDF7qJKFNvcACTkpMVHRc6/9jB1YBZSzAYI+PIUeWUBp8eLV37egW21i/yFat3BItz7+a/YcKhEqf8atYQYnRbxJn3I9T8jLgZn1d6wcHllLAy4YRGcHqH9R1uE266cqAGp8Xj03NFINOlR7XBh+7FyJf9jslnfLmUI5G8nz8zpjofOHY0Eky8AVFzjwN++Xo9NR4JzbclCYMGvdYuPXT6yT5sGjaYOzFT6ud/vPhp2kCTwe+/MnBMbZRtYV1SSpNT/wmpbWDcCqWtoq7YleAGyts9/HSp/gDPWoIPT4+0002P9N7deuuJUPHfxKUisXfxz4+ES/OvHLa0WuG2svizbdQQz3vgevx8uQV5ZNUw6NS4a1qtV3pM6lvbur1Dr6p0UW7sYmcCx2qCtxysr+WINejWGpCRBrTqxEE649USn1iBJZ4TVEzzDqrTGBZUkQSX5jqlRSdBp1Jh+Uk9M6J8CfSdMadZWWiv/bENONFcs25XIY9C2i0uKMWDOqTnKSLgvt+aFvQBWlcOlTIPXaVSY1kpTS/2m9M9AtcMVtHBFY1M6hBCorKxsUaLs4VlJuGPyEKW9/GF3Pt79bW+jx/LKAh9s2Idnvt8Cm8sDjVqF/qlxSIs1QRZo8cWISafB9IAcZI2tJB9t/IE/rxBKINDh9kYkyBSqr7cehNXhhMfrxRn9u84UkaQYA+6dOgIZcTHQadRQ1057L7O58Pfvfsf/Vm1HlaPpqe+lVgee/WEz/v3jVpTZnNCoVciMj1FGG8UZdWHX/0uH94ZZ7wvKrj5QiD1FFQCOW4gsAukRTqRdaamsBDP+NGUoSmsXuFHXNkxfbTsU0dHrfZJj8fj5Y5URXA63F09/v7n2xp3v9/Pj7qPIK/WNCumeENNq6QYakxRjwNge3QAApTUOfPL7/pB/R4VVNmw6Ulp7HD1Gde92QmU5vq6k1i5G5vaKqJ91QO2vLdoWt1fGr3lFAHx9stE9TqxOtzZ/gPNEU2hFG//NrdP6peO+qSOg0/j61ZuOlOKZ7zfD6fE2c4TmHV9fhBBYsuMQ/vbVb6ipneklC4HCKjsq7OGniqGOLxL9FWo9vZLMymJkxyp86WQOlVrh8coQALonG5GoP/EBJi2pJ4n6GHhEcDuWZNbBYtBAq1b50sTo1Ig1apES17FvxEWC6fyzoOSVqCey+WfZrkQeg7aErAQzxtcuUFTj9GDJjvAWc1m68whctaMITu/f8AjYE9Er0Yxiq0MJXGhUKry5dk+DF8BCCNjt9hY3KmN7puC2iYOV6fLfbD+MTzbl1tuv0u7CP5b+jkUBi4WN69kNr101CW9fO+WEL0ZO75+BHgm+5O55pdVYue9YM6+ILFkIfLIpF6kWI1SSBBm+3EyJJn3QYijR5Nvth/DR7wdwtMqOQ+VW2MK8WdHRTemfgQXXTMKrV03EgmsmYVTAhf3KfQX482e/YOW+Y/X+lmQh8O2Ow7indnSt3/DMJLx61UR8eMPUFtd/s14btGjKW2v3QK5d/MovEiNtT7RdaSmX1wuzTgOTTguVSkI3s+GEF4xsDUkxBjx8zmiM6+mrM0IA76zbi/m/7MKBkirM/2UXPLXfCbNOHqDk6W5L0wZmKTf3nl++DTe8G1pO7WW7jipd5GkDs064rMfXlfSAvLYFUTzrgCKjLdqWTUdKYHX6vs/G9ugWkTazOf4AZ0cfYduYIRmJuH/aCOhrA7db88vw9Peb6y2yGa7A+rK7sAJ/+2o95v28E26v7EvNVfs94fLKEf+eoMiIVH+l1alUQL9+vn8nOKq0I8mKN0OrVkOSJBytXYxsf6EvDZUsBPqnxSFed+LtZkvqSZxOD51KA4e37nop1qjD9JN7Ic6kgxACRp0Gl5/UE7FRkpKnI4nm/LOdpl3pwKKvJ0cRcdmIbKzJLYQQvpFcZw7MQkwI+W2dHq+yYrckAecO7tHqZSuxOqBVqSBkAUnlyxPoD1y0RYd/QnYaXB4Zr67eCQD4bFMuDBo1LhjaEwCws6Ac/1m+DRW1i/BIEnD1mH44d3B3SLUpEU60XCpJwrUn9cMTS34HAHywYT9O6pUSlRdfAPDjnnzsLaqExaBDz0QzzhvSE2/+uhtqlQqfbcrF2J4pyDqBPJGtzT9K1CsEVADUKgkvrdyOUd2TO+1FZEOSYgzK+Q5KT8SPe/KxcP1e2Fxe1Dg9+N+qHVi57xguG94bMnyLq3z8+wEcKKlWjhFr0OK6k/rjlN6pyrSZE/kdnt4/E0t3HcGRcisOlFRj9f6C49IjdJ2pVmmxJsTotRBwI8ViQKXdBbNeGxX5Hw1aNe6cMhQfbzygLHzzxeY8vLZ6FzyyDJUkYVK/dOSkJbRLedJjjcqoZEkGjlZa8cSSDeiZaEZ2cmyDr3F6vFi+zxfY1aqlkFZRDldaXGDQ1oahGZ1/BWyKLP8CZABwap/oWICsK8pJS8BfzxqJJ5dugsPtxY5j5Xhq2SbcN234CfXliq1OvP/TVvxWe9NUq1JBVRuwTTUbYXN7ouZ7gqjFdDrgX/+KdCnanVatQveEGFQVOlFc7YTbI2N/bT5bGTLGZnWDVhWZfrBZo4NFq4PN44IhYGG4Ub0S0TfVjLIaFxLNOgZsT4DpvDOhGz4YtsXfwXusEOr0VJguOIsLhhGDtuSTHmfCxL7pWLH3GGwuD77ZcRjTR2Y3+7rle/NRUzuiY3zv1CZXiG+ptFgTkmIMKLM5EGfQwd4OHdIp/TPg8Hjx9to9AID31++Dy+tFcbUDP+45quQSSjDpcMfkoRiYGt/qZRicnoixPbvht4PFqLS7sGhLHq4c3bfV3+dEVdpdQflHb504GIPTE1Fuc+KrbYfgkQVeXb0Tj5w7GqooyYWzq6AClQ7fVEJIaPMbAR2BSpIwdUAmRndPxtvr9uDXXN/02l9zC/Hl1jyoVSp4vDJSLUZYDL4O2RkDMnDl6L4tXsCwIWqVhGvH9cc/vvPdsFi4YR/SAkYrRuuNi7bgz//4wvKtqHa4oy7/o0qSMGN0H2TGm/DSyu0orLYrMyJkAewprESp1dEu5S2otkOvVsHrlX35ZIVAhd2Fez7/BZP6ZeDMgVkYmBoflI9rzYFCZUTiKb1T2+RCI81S9z11rMrW6scnCmR1uvH7YV8wL9agxdDaNQEoMvqnxOOvZ43EP5f+DpvLi12FFXhy6SbcP21E2Kl+apxufPr7AXyzLQ+SWg2pdk5YryQLzhncHV9uPQibyxN13xNEFJ7eSbHYXVwBl+zF/qJqFFbYIQAkx+rRPbbhm9DtQSWpkKY3Y4ezGMfffo41MljbWvz5Z4kCdZ2rX2rWpcN7Y9W+Y5CFb2Gxs3O6N5nqwCsLfL3tkPL4/CE926RcSTEG/GmKL3DRXIdUkiTExMS0SqLscwZ1h9PjxYcb9qPa4cI/l26CLIRvcRmLESf3TsXcSUPadIGdq8f0xe+HS+CRBRZtyUNmXEzUTSl8Z90eJefoaX3SMDjd91V++chs/HaoGIVVduwtqsR3O4/gnNqFpiJtxb58SAC8QiBWp1XqFUemAAkmPe6cPBQT+5Zg3qod2Fdc6cupLGRfrrxqO7KTY3HbxMEY0AY3KwBgaEYiRnVPxsbDJSi3uVBuq8uva4xATtvWbFfCNaV/BoZlJqKwyo7UWGNU/e37ndonHdUONx76er1viq4kIdGkhcPjbbcbIWmxJsSbfPmzBXwBDpUkQS2p8GtuEX7NLfLl183pjgnZqbA53fho4354vDI0ahXOzGmdtun4upIeMNK2kEFbOk5rty3rDhbD7fVNXxyfndouqUmoaf26xeGBs0bhH0t/h9Xpwd6iSjz09W+YMaoPspNjm20fC6tsWLQ1D6sPFMLl8UJAggq+oPwVo/pgcr8MqFUSLhrWK6q/J6h9RLK/Qq2jd5IFqtrFyFbvKQbgS43QJ9XSKqkRgJbXk9ja9/dfD1PXwHYl8hi0JUWKxYgp/TPww+58ONxefLXtIK4a0/jIzrV5hSiu8eWVHZaZqCxM0xZCDVxIkgSLpfXKcfGwXiirceB/P+9QRpB5hYDN7cGcU3PaNGALAKmxJpw9qDsWrt+Hwmo77lu0FqkWI+6cPDQqFu/YcrRUyVkbo9fgmrH9lOf0GjVmT8jBY99uBAB8sGEfRndPRoqlZYHRUqsDBVU2ZeT1iZR5a345Ui1GFFsd0KhViOHIlHpGZiVjzqmDMPfj1XB5vZAgQS35Ptebxg9ss4Ct3zVj+2Hz0VJ45br8SRqVpCya2J5au10JV2Aai2g1rlcKUmONKK1xwqRT1y7GqGm3GyGBo5JtLg9iDTqM69kNRyqsqHK4AQCHy62Yv2YXXl65DSVWJ6y1gd3hWUno00gKhXAdX1cSTHpo1RLcXoFjzDFJx2nttiU4NUJ6qx2XTkx2ciwerA3c5ldYsWJvJVbsPQadRo1BaQlBN3cCHau0YWt+KdxeWRkwkBRjwHlDeuCCoT2DZp50hO8JanuR7q+0GqcTuPVW388vvwzoo3dR49bWO8miLEZ2uNQKCb7UCCMyEmFQt87MtpbWk1itHiaNFjaPC2Zt1/lMurpO0650YAzaUpBLhvfGir3H4JEFluw8jHMH92gwMCmEwOKtdYtwXTi0bUbZBgqlQyqEQHl5ORISElrtbtC4XilY8OtuuDxeqNUqdDPq4JYFiqodSG6DdBDHm9QvA/9ZsQ2yEPB6ZZRZHXhh+VYMy0yMaAfd5fFiwS+7lcfXjO1Xb2pMTloCpg7IxPe7j8LlkfHa6p3461kjw/5sfth9FP/6cQvcXhkmnabFQWu3V8abtSkvLAYd5pyagyQd0D8zFUnt8Fl2ND0SzUg2+3KpatUSPF6BWKMOme2Qnzg9zoSzc7rj6+2H4PHKcMsyEkyR6SC2RbvS2STFGPDn04crQVP/32l7tlEN3dxze2WszSvE0l1HsbeoEh6vjMPl1qCbcIfKalotjcPxdUUlSUiNNeFIuRVF1XZ4ZcHRj6Rozbal1OrA1iOlcMkyMuNMyG7DG+kUvl5JFsydNBg3vb9SaX8cbg82HSlBhc0CzXE3JD1eGXll1UFtVbXTjUenDcaoPt35XUQN6jT9FSGAoqK6n7uQ7glmqFUqSJIEAQFAgkatwoiMlFZ7j5bWE4NaiySdCcfs1QzadiGdpl3pwLrOcowUkqQYA84Y4Et27fLI+HJrXoP7bc0vQ16ZbzXL7GQLBrXTYjPNEULA5XK16uqG6XEmJJsNMOu1SI81wVkbOGyvEWSVdieMGrUy7djh8aLa4Y74ysBfbMlDYbWvDDlp8ZjUt+FRPVeN6YukGN8X+7Zj5Vix71hY77MtvxR/++o3FFTZYHW5Ue1w4YXlW1FqdYRd5iU7DuNYpW+Kcr+UOJw9qDt6xxkiFgyMdv7Ri74bNxJijbp2DcRdOqI3PLLvwvVweQ12FZTjpz357fLegdqiXemMpvTPwPyrJ+H5y8Zj/tWTIjIb4PhV6bVqFU7tk47HzhuDf1w4FkMzEyEApT31j9xurfa0obqSXpuT2SsLlLSg3aLOqzXblvlrdiG3tq3cWViB5XvD+66ltqeSJJh1Whi1GkiSVJv/W8Aty/X2dcu+lERqlW+B24y4GOg1atgc/C6ixrG/0vEZtRpkxpmggq99kCHQI9mEZGPDI/Jb4kTqSZLeBLfsbbWyUPRjuxJ5HGlL9Vw0rBd+3HMUbq/Asl1HcN6Qnkg8LqgVOMr2giE9O/Vdl8BptzXO9l8MyJ+r0emV4fXK8AoBu9uDeGPkAo1HKqz4srYOqFUSbjhlYKN1wKTT4KbxA/HUss0AfDlwh2Um1atTx5OFwHc7j2D+mp1werxQS76Rni7ILVo0rNTqwKebDgAAJAm44eQBzMcUgkjmVLW7Paiwu4JGGkXDKHNqXDRP0e2d5MvFvP5QMcqsTmhUKkASbX4TLjUgJUxBpS3oMVFrKK2x4/MteUpbCQG2lVEoLdYEi0ELyQmkxhpRaXfBrNdi/h8mIvG4z6nM6sCN761EjcuNOKNO2bdbDBf7IersspNisbekAg6PDLVKwuD0BMRoouNvP05rgFalhkv2QqdSR7o4RF0CR9pSPQkmPc4c6FuUxe31LYAVKLe0CtuOlQPwXYyO69V60zWiVSRHkPmDxilmI1A73TbRpMeirbntVoZAshCYv2aXkmv0giE9kdXMdPkRWck4tU8aAMDm8mLBL7uavFtXanXgn0s34e21eyDBd85eISBq8wm7vF6kWsK7EH3vt71wenyjWaYOyGzTHMydzfGjF9tLQZUNEgBT7aikWINWCdgTtURSjAF3TRmGZLMBOo0K8UZ9m9+EC8xXWVDNxcio9a3JLfKlcJIkGHUaJMTo2VZGIX9/zqzXotoRMAjAbIRUO/rf/y/JbMSdU4L3nTtpMOK5QjtRp2dzeXCswo7SaieKK53QiOgZZ2fR6mDR6FHjdjW/MxG1iuhpASiqXDi0J77ffQROj4wfdx/FBUN6Itnsu6gNHGV7/pAeUTVaUZIkxMbGtsnI30iOIPOPdtyWX4bXagOmK/cVICctAZP7te8U5JX7jmFXYQUAX9D+kuG9QnrdteP6Y8vRUlQ53NhwqAS/5hXhlN6p9fb7JbcQ83/ZBavTAwDQqFU4e1B3rD9UjOIahzK9cO3BYpw7uEdI7739WBl+yfXlxrLUrrgMtG19oROXFmuCSaeBLAskxuhhrc2V2l6pSfxYTzqXthw93lBd8adHAHw3Ioj8Wqtt2ZpfqtzcNGk1yqjM9m4rqXnhtD/H75to0sNut/O7iBrF/krHV2p14Kc9+ZBF3ei6xZsO4dIhfVqtv3Ii9UQlqZBiNGF3VSkSwe+YroDtSuRxpC01KNaow9mDfKNtPbLAF1t8ozoLq+34Nc8X/Io1aDGxkTymkSJJEkwmU6dsVJJiDJjULwO3nDZI2fbGL7txuLym3cpQZXfh3d/2Ko9vOGUAdJrQpsZYDFrMOnmA8vjNX3ejylF3l9bm8uClldvxn+XblIBtgkmHv5w5Ao+fPxbvXnc6/jxlGHolWmAx6PDuur3YeLi42ff1yDLe/HWP8viq0X1h1vtWX+3M9aUzUEYlGbSwu73tnprEj/Wk82mr0eMN1ZW0gKDtsUqOfKQ6rdG2lFod2HasHKkWI7RqFbxCRKytpNCE0/4E7svvImoO60jHV1Blg0fI0Kp8o+5Neg0cbrlVZ06caD2J15kghIDMHKddAtuVyGPQlhp1/pCeMGp9Abmf9uSjsNqOb7YfUhbxPGtQ95ADdu1FlmWUlJRAbmBRh85iQnYazhjgG13r8sp4/qetsLs97fLe7/62VwmoTshOxbDMpLBef1KvFIzt2Q0AUOVw4+21vmDqzoJy3PfFr/h5f4Gy78m9U/D0xScr75EUY8BVY/viitG+UbICwIsrtuNgWXWT7/ndjiM4UmEFAPRJjsWkfnU3GrpCfenoomFxK9YTClVDdSXeqIOh9ruU6REoUGu0LT/sPgohAItBhzmnDopoW0lti99F1JxOU0ckCeje3feviwWK0mJNiNFpYdJpYTFqoZakVp9ldqL1JFajh0mrg93rbrUyUfTqNO1KB8agLTXKrNcq089lAby9dg+W167crteocObArEgWr1EeT/sEMCPpupMGoGeiGQCQX2nD/DVN54htDWsOFGDpriPweGWYdBrMHNc/7GNIkoRZJw+ASefLzLJi7zE88OU6PPzVepRanQAAo1aNW08bhDsmDVFGxAa6fERvnNLbl0fZ4fbime83o8LmbPD9ym1OfOJffAzArFPqLz7WFepLRxepnLqBWE8oVMfXFUmSlMXHiqrt8LDTSwFOpG1xe2X8sPsoAEAlARcO6xXxtpLaFr+LqDmdoo7o9cDLL/v+6SO38HIk+GeZxRl1UEOFOIOuTWZOnEg9MWq0iNcYYPUwr21X0SnalQ6MQVtq0rmDeyBG7wuwrcsrQqXDBY9XxukDMhsMqFH70KpV+NOUocrordUHCvFjbUA9HKVWB7YfK0Op1dHkft/tPIw/f/YLDpfXIK+sGkMzEhHXwsUwEkx6zBzXD9UOF/LKqrFk52HkllWj2uFCTlo8nr74ZJzWN73RKRiSJGHOqYPQJzm29hyceO7HLXB5vPX2fe+3vXC4fdtPH5ChvIaIqD35UyQIARRXN93eEoVqbV4hqhy+kU7jeqUg0dS1ghtERJ2Rf5bZfy6fgAXXTI7KmRMpRjOcXgbyiNoDFyKjJpl0Gpw3uAfmr9mFwmo7ZCGgkiTEGbh6baSlxZowe0IOXli+DQDw1trd6JMci15JlpBe/8Puo3j2+82wuj3QqiSc2icd6XEm1DjdsDo9vv9dbpTbnNhXXAVZCKglCZAkLN+bj5nj+rX4ru/Q9ARU2F3KMb1CwOHx4tbTBikL3jVFp1HjnjOG4cGvfkOp1Ve+eT/vwNxJQ5Rg786Ccqw+UAgAiNFrMGNU3xaVlYjoRAUuRnasyob0OFMTexOF5rudR5Sfo3X2ExERhS+SC2CHIlarh0alhlv2QquKrnSJRJ0NR9pSs8b1TEGx1aEE2DQqFd74dXezozMjQZIkJCQkdJlE2Sf3TsWZOb4LNbdX4IXlW2FzNX7XUwiBPUUVeGnldvx18ToU1djhcHlQYXfhm+2H8MOuo9hwqAS7CitwpMKKcpsLdrdX+ewllYQ0ixE2l+eEEuIXVNth0Kph0mkRo9ciMy4GKklCURgj0OJNetxzxnDoNb5m7JfcIny6ybdgnlcWeOPX3cq+V47qA4uh/sjwrlZfqGVYTyhUjdWVwFx0BVXMa0s+J9K27C+pwr7iKgBAjwQzBqbGt3LpKNrwu4ia02nqiNMJ3Hqr75+z4RRo1HKtUU9iNXqYNTqmSOgCOk270oFxpC01q8LuhF6thpAFVCoJ3SwGJWgXbXcAJUmCvovlPrpmbD/sLapEbmk1CqrseH3NzqARp0IIHCqvweoDhfgltxAlNQ7Y3R54vLIvECtJUAPwCgG3LEOj9gVBdWoVzHotNGoDSmoc8MgyEk162NwemPXaE0qInxZrqk2v4UacUYdKu6tFx+yVZMHcSUPw3A9bIAB8uikX6XEmVDncOFxuVfY5fUBmg6/vivWFwsd6QqFqrK4EjrRl0Jb8TqRtWRY4yjYnixdTXQC/i6g5naaOCAEcPlz3M7Wq1qgnapUKKfoY7KspRbyu9RZJo+jTadqVDoxBW2pWWqwJiTF6VNiAWKMONteJB+3aiizLKC4uRrdu3aBSdY2B5Fq1CndOGYq/frkWNpcXq/YVwKzXYnzvVOworMAvBwpxpMIa/BqVCmqV5Et1YdTB4fYiRqfBE+ePQWa8GWa9Flp13e/vpz35yihes157wgnx/Un2X1i+FdUO9wkdc3SPbvjD2L5477d9AID/rtgGrxAQMqBRq3DDyfUXH/PrivWFwsd6QqFqrK6kBQVtWz5LgTqXlrYt1Q431uQWAPClsZqQndZWRaQowu8iag7rCIWitepJvN4IucY3QIg3DjsvtiuRx6AtNSswwNZaQbu2JLrgHdlUixGzTx2Ex77ZgMJqO15auR3/W7UDqRYjLAH5hyUJGJaRhPHZqbC5PJj38w7YXB4kmPS4c/JQDMlIavD4U/pnYFhmIgqr7EiNNbbKZ9+axzxvcA/kV9rw5Za8oNzLpw/IRL+UuCZf2xXrC4WP9YRC1VBdiTVoYdSqYXd7OdKWgrSkbVm+Nx9ur+91k/qlK4uSUufH7yJqDusIhaI16kmcVg+TWgOb140YDde76czYrkQWg7YUkrYI2lHr6pMcC6vLE7S4V2G1HUatBoMzEjC+dxpO7pWCWGPdl+rYnt1C/kzbIiF+ax1TkiRcNLQn3l67Rzl/GcDOY+UotTpYX4kooiRJQlqsCbml1SixOuD2ykGzGYhCJQuBpbu4ABkREUWWSaNDrNaAcpedQVuiNsSgLYUs2lex7OoKqmzQqlUw6bRwebwwaFRQSRL+dPrQRqdOdqbPtMTqgFGrhgDgkWV0M+rh8HijMvcyEXU9abFG5JZWQwigsNqOrPiYSBeJOqDfD5egpMa3aOfwzKSg1BtERETtKdVgRqGjOtLFIOrUOMyDOhVJkpCUlNQl8+qkxZpg0mmg16iQGR8Do1aDpBhDl1lROi3WhBi9bwpyZlwM3LIMk07TZO7lrlxfKHSsJxSqpupKYHCtkCkSCC1rW74LWIDsrEEcZduV8LuImsM6QqFozXoSq9VDBRU8srcVSkbRiO1K5DFoS52KJElQq9VdslHx5x4267WocZ7Y4l4dUUvOvyvXFwod6wmFqqm6kh4QtD3GoC0h/LYlv9KKrfllAIAUiwHDMxvOQ0+dE7+LqDmdpo5IEpCS4vvX0c8lCrVmPYnV6hGj0cHqcbdCySgadZp2pQNjegTqVGRZRlFREVJSUrrk6oZdPfdwuOff1esLhYb1hELVVF0JHGnLxcgICL9tWRaUy7Y7VLyA6lL4XUTN6TR1RK8H5s+PdCk6rdasJxqVGimGGOTWlCNO17WuO7uKTtOudGAM2hJ1Mp0pT21LdPXzJ6LoFBy0tUewJNQR2d0erNh7DACgU6swqV96hEtEREQEJOiN2FdTClkI3kwkagMMlRMRERG1MYtBixi97145R9pSuH7eXwC725czcEKfNJj12giXiIiICEjUGZGij0G+vQqyEJEuDlGnw6AtERERUTtIs/hG25ZanXB5IrdoR6nVge3HylBqdUSsDBQ6IQSW7gxMjcAFyIioE3O5gLvv9v1zuSJdGmqGQa3FkPg0JOqNOGavgmDglqhVMT0CdSoqlYr5VihkrC8UCtYTClVzdSUt1oj9JVUAgMJqO7onmJs9ZqnVgYIqG9JiTc2mfmlsX6vTjYJqOwqrbFix7xiW7DgMt1dGnFGH+6aOwJT+GWGcJbWWUNuWHQXlOFJhBQAMSI1DryRLexSPogy/i6g5naaOyDKwd2/dz9Sq2qKeWLR6DI1Lw6byYyhwVCPdGNtqx6bI6jTtSgfGoC11KkIIeL1eSJLEFQ6pWawvFArWEwpVc3UlMK/tsSpbs0Hbn/bk498/bUGNww29Vo0/jO6LMT27Nbjv+oPFeH/DPthcHqhVEkZ1T4ZRq0FBlQ01Tg8AwOOVkVdWDVkIqCUJRdV2PLFkI4ZmJCDZbDyBM6eWCLVt4ShbAvhdRM1jHaFQtFU9idMZMDQ+FZvKj6HQUYNUQ/M3pin6sV2JPAZtqVMRQqC0tBQpKSlsVKhZrC8UCtYTClVzdSU9IGhb2MxiZKVWB55c+jtKrQ6oJQmVDhf+s2IbeiVaoFEHj3Y4PhjrFQIr9h6rt69blpV9JEmCGkCF3Ylnf9iMB88ezTyp7SyUtqXU6sBvh4oBAPFGHcb2TGnPIlIU4XcRNYd1hELRlvUkUW/CsIQ0/F5+DMUOK7oZYlr1+NT+2K5EHsc4ExEREbWDtLjgkbaNEULgvd/2KgFbSZKgliTIQsDdwFTResHYgH2TYvTISYvHlP4ZuGJkNpLNBsTotbAYtPDWrvS8v7gaf/1ynZK6gdqWP6dwWQg5hRdtzoPN5YHHK+OMAZnQqtl1JyKi6JWsj8Gw+DRAEihzcuFVohPFkbZERERE7SDNUpeCoKCRoK3L48W8n3dg1b4CqGpHzZq1GrhlGWaNGucO7o4YXfCIWKvLjYXr98Pp8cKs18DpkWHRazFvxmlBgWIASI+LwQvLt8Lm8iDFbESMXgONWoXiGgce+Xo9rjt5AM7onxE1oynCyekb6fdval+vLGB1uvH97qN4fc1O2N1e6DVqnNc/BZNyNJAayBW3/mARXlmzEx6vDJUkQa9Rt+q5ERERtYVUgxlD4tKwpbwAFS474nVMwUTUUgzaUqcTLRea1DGwvlAoWE8oVE3VFf8I12qHu8GgbbnNl6rgQEk1NGoVUi1GODxeqCQJCTo97pw8tNFFw/p1i1eCsQkm377HB2wBYEr/DAzLTERhlR2psb6LqOd/2op9xVXwyALz1+zC7sIK3HjKQBi0bRMkPD646ZUFrC43rE4PalxuWJ1u1DjdWJtXhK+3H4LHKxCj1+BPU4birJzubVKm49lcHny0cT/eWbcXTo8XOrUKk/tnoH9KXIP77ymqxE978uHyeqGWVBiSnoA4k145F7vbWy+NRZXDhbc2HsSKg2XQqoN/18fvq1ZJmP/LLozPTo1I8JqiA7+LqDmsIxSK9qgnmaZYeIWMLeUFUEkqxGr1bf6e1DbYrkQWg7bUqahUKqSmpka6GNRBsL5QKFhPKFSh1JW0WBOqHZUot7ngcHuVwGheaTWe+X4zymxOAIBBq8Y9Z4xBrySLEmBtKlh3fDC2qX2TYgxBzz90zmi8v34vluzwLXj18/4C5JVV464pQ5ER1zr56NxeGXml1fhyax6+3HoQDrcXkgRkxJmg19Tvjh4ftLS63Hhw8W/4Zvsh5KQloG+3OPRNjkVWQgw0taNUQx0Ve/x+bq+MQ+U12Fdcif3FVdhfUoXDZTXIDXh/u9uDxVsPhpRT2CG8+O1QcUg5hb1CwCMLHB8fP37fJLMBNpcHhVV2Bm27KH4XUXM6VR2JjY10CTqt9qwnPWLi4ZFlbK8sYl7ODqpTtSsdFIO21KkIIeByuaDT6XhHiJrF+kKhYD2hUIVSV9IsRuwtqgTgS5HQK8mCdQeL8NLK7XB5fPlqk2L0uHfqcPRMtNQ+Di1Id3wwNlRatQrXnTQA/brF4bU1u+Bwe3Gk3IoHFv+Gq0b3QWZ8TFjpAVItRtjdXuwvqcL+4irsK6nCobJquDzBwU2PLHC43NpgILSxAOfBshoUVTuwYu+x2rJL6JUUCyEE1uYVwe2VodeocfnIbIzqnlyvjBsPl+CT3w/A7vZAkiT0SbbA6ZHhlUXQfq5G3t8tyyGX1SNkJBr0iNFrYdZroZF8o6ndXhkmnRp2txdmtRoXDukBs0EXdEyr0413fvON8o036OBwe2HWa5XR0dT18LuImtNp6ojBALz3XqRL0Wm1dz3pbU6ADIEdlUVwer1t/n7UujpNu9KBddqg7UsvvYRnnnkGBQUFGD58OF588UWMGzcu0sWiNiaEQHl5OVc3pJCwvlAoWE8oVKHUlcCUBYXVNmw+WooPNuxXtvVLicOfTx+GOKOuoZe3qfHZaeiZaMHzP23FkQoriqvteGDxb9CqVdBr1JjYNw19uzWcHmBfcSVW7CuAw+2BLARSzEZYjgtEBgU3VRK08C2YlhZnRGacGWa9BubaAKcA8NrqnXB6fKORqxxuaADojg+YegV2Hiuvl3bglZ931AsGHz8i1isEthwtq7efWiWhb7dYVNidkGUBi0EHq9MNo06D+6YOr/fZVNpdeHzJRthdHt++Ljcsei1ev2oikszBQdbT+uYraSy6mXW4dngWLh47AKoGctr2SopV9jXrtbhz8lCOsu3C+F1EzWEdoVC0dz2RJAnZ5gR4hRc7Kkva/P2odbFdibxOGbT98MMPcffdd2PevHk46aST8Pzzz+Oss87C7t27kZKSEuniERERUReVZjHC45XhlmW8vmYXapwe5bkJ2amYfeogaNWRm0SYGR+Dx88fixeXb8VHvx+ALAQ8XhlOjxffbD+MXokVzaYH8AqBwmo7jFrfImdS7XHTY034dscheGSBRJMelQ4XzHotHjl3TIPByOQYgxK0TLUYcefkoRifnYqDZdXYV1yFAyW+Ubx5pdUhjYptbERsvEmHkVnJ6NMtFn2SY9Ez0QKtWoWf9tQFWONr8wSPz05r8Pd239QRyr6xBp0vwGquPyo2MI1FilkPj7Wq0c8inJQXRERE0UolqdDPkgxZBjQqLqpJFI5OGbT917/+hZtvvhmzZs0CAMybNw9ff/01FixYgPvvvz/CpSMiIqKu6lB5jRLgPFphRarFNyL1ilHZuHhYr6gYxWDQqnHO4B5YvP0QHG4PJISXHkCnlgBIOGNAJib2TUfvZAuMWl+Xc2T3ZLywfCuqne5mR482FrTsnxKP/inxyn6Hy2tw8/srUeN0w6D1pR2waNS4bERvxOi1yn5Wpxtv/robDo8vPYHbIyPOqMM/LzqpwTKEEzRtSU5hWZZR1ETQNnBfIqIuw+UCHn7Y9/OjjwK69p95Qq1PJamQE88BdETh6nRBW5fLhQ0bNuAvf/mLsk2lUmHq1Kn45ZdfGnyN0+mE0+lUHldV+TrQsixDln355aTaCxEhBISoy3vW3Hb/61u6XaVS1Tt2uNtbWvaOeE5CCGg0Ggghgt63I59TZ/ycouWcZFmGunbF7s5yTi3ZznNqejsAqNXqBtuUjnpOnfFzioZzaqpNkSQJZTYn3l+/L2hEalGNHXdOGYqpAzKDXhPpc0qzGJBg1KNGJcGo1aDG5YZJq8Ffpo1Q0gP43hOosLnw8DfrYa8dkVpTG5CdPrI3Ekx65XcjSRKm9M/A0PR4FFTbkWYxIjHGACFEo+eUFGNAQu37+Z8/vuyZcSbcO3UYXlyxvTbtgAFzJw3GlH4Z9fbPiDMp+8Wb9Lhj0hAkGHWN9vcSjDokGOvyuDVV9/z7+vdr7nPy1xdZlvn3xHMKaXvgd1FnOafO+DlF6pyaa1M6zDnJMsS2bYAQEB4PULtYZYc+pyiqe0L4rpc70zl1xs8pWs6pub5tRzynE9nemud0/HON6XRB25KSEni93nor3KWmpmLXrl0NvubJJ5/Eo48+Wm97cXExHA4HAMBoNCIuLg5VVVWw2+3KPjExMbBYLCgvL4fL5VK2x8bGwmQyoaysDB5P3dTHhIQE6PV6FBcXB1WCpKQkqNVqFBUVBZUhJSUFXq8XpaWlyjZJkpCamgqXy4Xy8nJlu0ajQXJyMux2uxJ4BgCdTofExETU1NTAarUq2zvrOSUnJ6OysrJTnVNn/Jyi6ZxUKhWcTmenOqfO+DlF8pwkSUJJSV0ers5wTp3xc4qWc1KpVKiurq53TgU2L2xON/QaFTxeAY1KgkmnQWZcTNSdk8dahetGZGHBhjw43B7EG/X440l90dMoAPhudBsNvs+psrISN4/uiQUb8lBtdyKmdgSt5LKjqKay3jnBaUOyygOP1Y0ia1WrnNOQeC3mXz0Jh0srYfA6EW/UoKioqN7nNDhOg39Oy0G5S0b/rDToZHfQ8SNR90pKSvj3xHNq9pwqKyvh9XqV76LOcE6d8XOKhnOqqKjo2OcUFwdZluF2u1FRVAQYDJ3yc4rkOSUnJ6OwsLBTnVNn/Jyi6ZxUKhVjLK18TtXV1QiFJI4PT3dw+fn5yMzMxJo1a3DKKaco2++77z6sWLECa9eurfeahkbadu/eHeXl5YiNjQUQHZH4lm6P5rsLrX1OAOBwOGAwBE8l7Mjn1Bk/p2g5JyEE7HY7YmJilMcd/Zxasp3n1PR2ALBarTAajcrjjn5OnfFzioZzEkLA4XD4ApNAvTKW2Zy48d0VqHK6oFOr4PbKsBh0mH/1JCSa9FF5TmVWBwprHEiLNTVaRv/+ZVYHCqrtSI81IclsjNrPqaGyn+j2lpyT/zvIaDRCrVZ3inNqadl5TqGV3WazKd9FneGcOuPnFMlzaq5N6TDn5HJBTJ/uG2n70UdA7XVdZ/mcmtve1ucE+K6X9Xo9JElqdv+OcE6d8XOKlnMSoum+bUc8pxPZ3prnVFXlG7hQWVmpxB0b0ulG2iYnJ0OtVqOwsDBoe2FhIdLSGl48Qq/XQ6/X19uuUqmgUgXnbfP/8o/X2PbjX9+S7eG+Z1tvj+ZzkmUZVVVVMBgMYb1vNJ9TS7fznJo/J1mWUVNTA5PJBJVK1SnOKRq2d7ZzOr6eNFf2xrZH0zmFW/bGtvOc6rcp1dXVyoiE4/dPijHgzilDlQWrLP4Fq2pzlkbjOSVbTEi2mIKea2z/hvaNxnNqi+0tOafAtiWSZefn1DHOCUCD30Ud+Zw64+cUyXNq7zalTc/J9yQklQoIeF2HPqcoqXv+6+WUlJQGy98Rz6kl23lOrdO3beo40XpOJ7K9Nc+psdccr9MFbXU6HUaPHo0ffvgBF198MQBfRfvhhx9w++23R7ZwRERE1KWFs2AVERERERF1XZ0uaAsAd999N6677jqMGTMG48aNw/PPPw+r1YpZs2ZFumhERETUxSXFGBisJSIiIiKiJnXKoO2MGTNQXFyMhx56CAUFBRgxYgSWLFlSb3Ey6nwkSYJOp2twKDvR8VhfKBSsJxQq1hUKB+sLhYP1hZrTqepIA6kLqXV0qnpCbY71JfI63UJkraGqqkpZDbmphMBEREREREREREREoQo17hha5luiDkIIgerq6norCRI1hPWFQsF6QqFiXaFwsL5QOFhfqDmsIxQK1hMKB+tL5DFoS52KEAJWq5WNCoWE9YVCwXpCoWJdoXCwvlA4WF+oOawjFArWEwoH60vkdcqctkRERERERETUwbhcwJNP+n7+y18AnS6y5SEiiiAGbYmIiIiIiIgo8mQZWL++7mcioi6M6RGoU5EkCUajkasbUkhYXygUrCcUKtYVCgfrC4WD9YWawzpCoWA9oXCwvkQeR9pSpyJJEuLi4iJdDOogWF8oFKwnFCrWFQoH6wuFg/WFmsM6QqFgPaFwsL5EHkfaUqcihEBlZSUTZVNIWF8oFKwnFCrWFQoH6wuFg/WFmsM6QqFgPaFwsL5EHoO21KkIIWC329moUEhYXygUrCcUKtYVCgfrC4WD9YWawzpCoWA9oXCwvkQeg7ZEREREREREREREUYQ5bRvgv4tQVVUV4ZJQuGRZRnV1NQwGA1Qq3pOgprG+UChYTyhUrCsUDtYXCgfrCzWn09QRhwNwu30/V1UBLldky9PJdJp6Qu2C9aXt+OONzY1iZtC2AdXV1QCA7t27R7gkRERERERERF1QamqkS0BE1Kaqq6ubXOxNEkxOUY8sy8jPz4fFYoEkSZEuDoWhqqoK3bt3x+HDhxEbGxvp4lCUY32hULCeUKhYVygcrC8UDtYXag7rCIWC9YTCwfrSdoQQqK6uRkZGRpOjmDnStgEqlQpZWVmRLgadgNjYWDYqFDLWFwoF6wmFinWFwsH6QuFgfaHmsI5QKFhPKBysL22jqRG2fkxKQURERERERERERBRFGLQlIiIiIiIiIiIiiiIM2lKnotfr8fDDD0Ov10e6KNQBsL5QKFhPKFSsKxQO1hcKB+sLNYd1hELBekLhYH2JPC5ERkRERERERERERBRFONKWiIiIiIiIiIiIKIowaEtEREREREREREQURRi0JSIiIiIiIiIiIooiDNoSERERERERERERRREGbYmIqEuSZTnSRaAO4Ndff410EYiIqAtjf4VCwf4KUefEoC1Ftfz8fOTl5QEAPvnkEzzxxBORLRBFPSFEgz8THU+l8n0FPvLII1iwYEGES0PRaP78+Rg/fjw+/fTTSBeFOgD2WShc7LNQKNhfoeawv0LhYH+lY2HQlqKWw+HAKaecgjvuuAMvvfQSrrjiCvTs2TPSxaIoJssyJElSHgf+TOQXOGLlo48+woIFC5CTkxPBElG0mjJlCubOnYubbroJn3zySaSLQ1GMfRYKF/ss1Bz2VyhU7K9QqNhf6Xgkwdu6FMUKCgrQr18/2O12PPXUU/jzn/8MwDcagZ1basyLL76IX3/9FVlZWTjnnHMwefLkSBeJotDy5cvx4YcfYuDAgbjzzjvZrlCDDh06hGeffRZvvfUW5s+fj8svvzzSRaIoxT4LtQT7LNQc9lcoFOyvUKjYX+lYONKWopIQAh6PBzExMXC5XNBoNPjtt9+Qm5sLwDcagfcbyC9wJMIjjzyCRx99FLIsY+XKlZgzZw4WLlwYwdJRNNqyZQtuuukmvPvuu7DZbADYrlCdwDalR48euPvuu3Hdddfhxhtv5AgWqod9FgoH+ywUDvZXqCnsr1A42F/pmBi0pajjv8OTm5sLk8mEqqoqbN++HV9//TXuueceHDhwAACnkVEdf66vrVu3wul0YvHixVi4cCHmz5+PadOm4d5778X7778f4VJSJPk7IP7/hw0bhscffxyZmZlYtGgRNm7cCIDtCvn425T33nsPVqsVvXr14oUQNYh9FgoX+yzUFPZXKBzsr1Co2F/puBi0pajib0w+//xzXHjhhXj44YdhtVrRp08frFmzBkuXLsV9992H/fv3AwCefPJJ/OMf/4hwqSkaLF68GGeeeSY+//xzpKenAwAGDRqEuXPn4tJLL8X//d//cfRKFxWYN9DpdCoXQldddRUefPBBOJ1O/Pe//8XWrVsjWUyKMkVFRZgzZw7OPfdc2Gy2ehdCXOyD2GehlmKfhRrC/gq1BPsr1Bz2Vzo4QRRlvv32W6HX68Urr7wiDh48KIQQwuv1CiGE2LJli0hISBDjx48XF154oYiJiRHr16+PZHEpSqxYsUJceeWVwmAwiG+++SbouT179og777xTqNVqsXTp0giVkCJBlmXl56eeekpMnTpVXHjhheKuu+5Str/11lti1KhR4oYbbhBbtmyJRDEpCgTWFb9NmzaJ7OxsMWXKFGG1WoUQQuTm5oo77rhDJCQkiLfffru9i0lRhn0Wagn2Weh47K9QqNhfoZZgf6Xj4kJkFFUcDgdmzZqFHj164KmnnlLuCnm9XkiSBJVKhZ07d+Lf//43JEnC3LlzMWTIkEgXm9qZLMvKdKBA69atw1NPPYUdO3bgP//5D6ZNm6Y8t3PnTnz33XeYO3cu1Gp1exaXIkQEJNN/5pln8Pjjj+P2229HSUkJvv32W6SmpmLJkiVITk7GG2+8gf/973/IysrCM888gz59+kS49BRp/vqzefNmXHTRRcjOzsZXX30Fk8mEvLw8PPTQQygoKMDSpUsjXVSKEPZZKBTss1Bz2F+hE8H+CjWH/ZWOjUFbiioulwtjxozBBRdcgL///e8AgjsypaWlSEpKgsvlgkqlgkajiWRxKQICL342btwIj8cDnU6HESNGAABWr16Nl19+GVu2bMG///1vTJ06td4xvF4vL4K6kNWrV+Odd97BBRdcgPPOOw8AsG/fPlx66aUwm81Ys2YNAGDevHlYt24dXn/99QYvsKlzCmxTnnvuOaxcuRKLFi0K2mfTpk0477zzMHLkSHzwwQcwm80oKChASkoK60oXxj4LNYd9FgoH+yvUFPZXqKXYX+nY+JdLUcXlciEjIwMVFRVKLif/KoZ79uzBU089haKiIuh0OjYmXZAQQulwPPjgg7j22mtxwQUX4LbbbsN9990HAJgwYQJuueUWDBs2DPfccw+++uqresfhxU/X8dVXX+GWW27BV199hdTUVAC+Tm/fvn3x9ttvIy8vD2+//TYAYM6cOViwYAFUKlXQarzUeX366ad46623YLfbAQB9+vTB999/j+uuu07ZR5ZljBgxAnfeeSe++eYbTJ06FQ6HA2lpaawrXRz7LNQU9lkoHOyvUFPYX6ETwf5Kx8agLUXEvn378MADD+DMM8/EWWedhZtvvhkHDx6E2WzGFVdcgXnz5uGDDz6A0+kE4FvF8J133sHKlSsjXHKKJP/dwCeeeAKvvfYaXnrpJWzevBmjR4/Gs88+izlz5gAATj31VNx6661IT0/HRx99FMkiU4RlZ2djxIgRKCkpUUYj+C+ie/TogdjYWFRUVAS9JvBCmzq3ZcuWKYt0uN1uXHzxxfj000+xaNEiXHPNNQDq6ktKSgquv/569OrVC1qtVjkG60rnxz4LtQT7LBQO9leoKeyvUCjYX+mcGEandrdlyxZMnToVEyZMQO/evVFQUICvvvoKX3/9Nf7973/jhhtuwKFDh3DjjTdixYoVMBgMsFqt+Pzzz7Fy5UqkpKRE+hSonQVOB9qyZQu+//57vPfee5g0aRK+++47vPnmm5g5cyY++ugjaDQa/Pe//8WECRPw1FNPMR9PF1JWVgaTyQSDwaCswDxo0CA89thj0Gg0+PLLL5GSkoK5c+cCACwWCzQaDTweT9Bx/Bfa1PnNmzcPBoMBN910E2RZxpVXXomzzz4b77//Pq6++mpcffXVePrpp6HT6fDVV1/h1FNPxZ/+9CcAnLLcVbDPQuFin4Waw/4KhYv9FWoO+yudWPuteUYkxMGDB0WPHj3E/fffH7Ty5fbt28WUKVNEYmKi+P7774UQQrz++uviuuuuExMnThQ33XST2LZtW6SKTRH0ySefiAULFgibzSaEEMLtdovnn39elJWVieXLl4v09HTx6quvCqfTKaZPny4kSRIzZswIOoZ/ZUzqvD788EPRv39/cfPNN4uVK1fWe3737t1i1qxZIisrS1xzzTXi4YcfFpdccono27evcLvdESgxRZrH41F+vv3224VerxdvvfWWcDqdQgghfvjhB5GRkSG6desmevbsKYYNG8a60sWwz0LhYp+FmsP+CoWL/RVqDvsrnRuDttSuXnnlFXH66aeLqqoqIYQIalSOHDkixo0bJ4YOHaps83g8QpZl4XK52r2sFB1mz54tJEkS77zzjqiurhZC1F3Q3HHHHWL27NnC4XAIIYT461//Ks4++2wxffp0XvR0IW63W9x6661i0KBB4qWXXhJxcXHi9ttvFy+//LIQoq6+7Nq1S1x//fXCYrGISZMmiTfeeEM5RmCHmLqOxi6E/G1KWVmZWLBggfjggw+UCyDWla6DfRYKF/ss1BT2V6il2F+hprC/0rkxPQK1q02bNsHlcsFisQAIntaTnp6OO+64AzfeeCNWr16NCRMmQKVSQZKkoHw81LX4pwPdfPPNkGUZ06dPh9FohCzL2LZtG8xmM/R6PZxOJ3bv3o3LL78cN954I4DgKYrUeWk0Gvzxj3/EZ599hqlTp2L8+PFYtGgRXn75ZXz66ae45JJLMGPGDAwYMACPP/44AODIkSNKPieAUwy7qsDpgi+++CIA4I9//CMA4NJLL0VCQgJmzZql7MMphl0L+ywULvZZqCnsr1BLsb9CTWF/pXNj0JbalV6vx+HDh+FwOGAwGJSVCwFfcvSpU6fC5XKhpKQEADsmXZ2/w/H888/D6/Vi9uzZAIDLL78cJpMJV199NR5++GGcc845qKiogNVqxYcffgiAizN0JbIsY/jw4bj88suxcOFCPPzwwxgxYgTuuOMOJCUl4dChQ3jsscfwl7/8Baeccgqefvpp/N///R/effdd2O12/OlPf2Jd6QKOv4Dxf//s3r0biYmJ6Natm3IhNHv2bEiShBkzZkCn0ymv4QVQ18I+C4WDfRZqDvsrFIrA75rAx+yvUGPYX+nc2OpTuxBCAABOOeUU1NTU4MUXX4TH44EkSUpSfa/Xi2PHjmHIkCHo169fJItLUUKtVsPr9QLw3VW+6aabMHv2bHzyySeQZRkXXnghHn30UcTGxmLMmDHYsGGD8hp+GXUd/guYkSNHYt68eUp7M23aNJx22mn49ttvcfvtt+Oll17CU089hW7duuH+++9HWloavv3223qrMVPnsnXrVgDB7Ym/M/vpp59i1KhROHLkCGRZBlDX1syZMwerVq0CAOU56hrYZ6GWYJ+FmsP+CjXl66+/RllZWYMBW/ZXqCHsr3QREUjJQF1YdXW1GD9+vEhPTxevvfZavSTpf/nLX8SoUaNEcXFxhEpI0c6fx+nNN99sMAccE+93PYF5my666CJx++23iyFDhohTTz01qC3ZuXNnUH6vffv2ifz8/HYtK7WvTz75REiSJGbPnq1s89eBxYsXC41Go+QSDHxOCCFmzpwpevfuLex2e/sVmKIK+yx0othnoUDsr1BjXnnlFSFJkvj555/rPffll1+yv0JNYn+lc5OEqA3PE7Uxt9sNrVaL0tJSnHbaaSgtLcW0adNwxx13IC8vD7/++itee+01rFq1CiNGjIh0cSkCQpm+DABz587Fa6+9htdeew3Tp0+HwWAI2p+6rpdeeglz587FZZddhldffRUJCQn16gXzfHUdL730El5++WUkJCRg8ODBeOWVVwAANpsN8+bNQ2JiIq6//vqg1/jrxw8//IB7770XixYtQvfu3SNQeook9lmoOcd/t7DPQuFgf4X8Xn31Vdx222344IMPcNlllwU9J8synnvuOSQnJwflrAXYXyEf9lc6P6ZHoDZx/L0Ar9erNCZJSUlYs2YNLrzwQqxZswYTJkzAgw8+iF27dmHNmjVsTLqglkxfvvnmmzFnzhysXr0agK9Tw4ufzs9fP/z8bc2uXbvgdDoxa9Ys9OnTB7169UJCQgKA+nmbeAHUdZjNZsTFxeGyyy7D6tWrlRyTJpMJV111Vb2ALVBXPxYvXoyKigplUQfqvI6fTso+CzWlJVOY2Wfpeo6/FmJ/hRqycOFCzJkzB9988w0uu+wy5OXl4f3338f999+PxYsX49ixY7j33nvrBWwB9le6IsZYuqj2H9xLnZl/qoZ/Cpgsy8rw/NzcXJGRkSEWLVokhBDC5XKJ6upqsXHjRlFWViaqqqoiU2iKKE5fplBs2bJF+dlfB/zTDD/55BNhMpnE2rVrhRBCvPjii+KUU04RO3fubP+CUlT59ddfxTXXXCNcLpd47rnnxIgRI8TNN98sRo4cKT7++OMmpybPmzdPrF+/vh1LS+0tcJqgv13x/88+CzWEU5ipOV999ZUoLS0N2sb+CjXE4XCIP/3pT0KSJJGbmyuOHj0q+vbtKyZMmCB69OghcnJyxOTJk4P6wA1hf6Xz27dvnygrKwvaxv5K18GgLbWa3bt3iz/96U/i0ksvFY8++qg4cOCA8tyhQ4dEcnKyuOmmm4Qsy0E5nQJ/pq7nv//9rxg0aJCYMGGC+OMf/6hst1qt4rnnnhNvvPFGvdf4v6S+//57MXLkSHHo0KH2Ki5FQLiB/fXr1wtJksS7777b7mWl6FJcXCyGDRsmjhw5ImRZFs8++6wwm80iISFBlJeXCyGCgyrUdezevVtYLBZx8803K9v8dYF9FmrIK6+8IjQajfjkk0/qPef1esXTTz8tFixYUO859lm6jnCD+uyvUGFhobj55puFJEkiPT1dPPjgg+Lo0aNCCF+dmTJlirjxxhuF0+mMcEkpUjZt2iQkSRLz58+v9xz7K10D0yNQq9i6dSvGjx+P8vJyyLKMb7/9FgsXLoQQAm63G4sWLcI111yDV199FZIkBU3/4fSwro3Tl6k5BQUFyMnJwbZt25T6oVarYbPZsGfPHrz22mu45ZZblP1Hjx6N1157DTNmzIhUkSkKeDwe6HQ65XtIkiQsWLAAqampyMjIwN/+9jcAnH7aVe3YsQNGoxFbt24NaldcLhe+/PJLzJw5E/PmzWOfhQBwCjM1z5+X9OOPP8aECROCnpNlGbt27cKrr77K/goFSUlJwRNPPIE77rgD48ePx+233460tDQAwAUXXICTTjoJ33//PWw2W4RLSpGwefNmTJgwAffddx9uuOGGes9/8cUXjLF0AZpIF4A6vgMHDuCCCy7AnDlz8MQTTwAAbrrpJhQWFkKSJGi1Wtx+++3wer1sPKiegQMHok+fPrj99tshhMA777yDP/7xj1i/fj3++te/4uKLL4ZG03BTlZOTg5kzZyI+Pr59C03tKjCwP3/+fMyePRuvvPKKEthPT09X9hW1eQVvvPFGAL7AXWP1hzqPNWvWYMuWLfB6vRg2bBhOO+00aDQaxMbGYsqUKVi9ejUuvvhipKSk4PXXX8c333yDv//97+jZsyfuueeeSBefIkCv1yM+Ph4XX3wx3nvvPcyZMwfz5s2DTqfDRRddhKysrEgXkaKE0+nEunXrAAD9+vVDfn4+pk2bhtTUVBw+fBhffvklUlNT8Z///AdDhw5t9Djss3Re/qD+d999h2nTpiEvL0/5XpowYQJGjRqFe++9N+g17K90TYH9laFDh2LixIlISUnB/fffj7KyMqSmpgKoqw89evRAdnY2jEZjhEtO7W3Xrl0YM2YMHnroIfztb3+DLMtYvnw59u3bhyFDhqBfv36YO3cuc6R3AfxmoBPi9XqxbNkynHHGGfjzn/+sdECMRiO2bduGSZMmoWfPnpgzZw7Gjx/PlXKpnj59+mDLli0oKirCXXfdBSEEHnnkEWi1WkydOhUajabR1XP9o6OocwsnsH98+8ILoM5vwYIFeOCBBzBw4EAcOXIEFosFjzzyCC688EIAvoDLzJkzMW3aNLzzzjtISUnBzJkzkZKSgssvvzzCpadIGTp0KEaPHo2bbroJOp0Ob775Ju6++25UVlZi3LhxuOGGG6DVaiNdTIoCer0ef/nLX2C1WpGdnY20tDTceOONuOWWW5CRkYHFixfj3//+N1544QW8/PLL0Ol0DR6HfZbOqaVBffZXup6G+isPP/wwLrroIqSlpSkjbAFfffDPVs3OzoZer49gyam9ybKMjz76CF6vV+mrTps2DaWlpcjLy0NSUhJ69+6Nf/3rXxg2bFiES0ttjekR6ISo1WqceeaZuPvuu5GQkABJkvDYY4/h9ddfx9SpUzF58mS4XC7MnDkTubm5DNhSEE5fplAcH9i/5pprsHDhQuTl5QUF9qnrWbx4Mf7v//4Pzz//PH788UcsWrQIffv2xfLly5V9XnjhBfz973/Hm2++iZSUFAghEB8fjxkzZkCtVrPudFGJiYnYvn07Dh8+jNmzZ+P222/H22+/jTfeeAPjx4+HVqtl3SAFpzBTY/xB/ZtuugnZ2dkYM2YMrrzySnz00Uc4ePAgnnrqKUiShBdeeAEulyvSxaUIaay/smLFCgC+kdd+drsdGzduxPnnn4+CggLMmzev3j7UualUKsyePRs333wzRo4ciaFDhyI+Ph5vvfUWiouL8eyzz0KtVuOJJ55ATU1NpItLbYy39OiE9e7dW/kScTqdWLt2LT755BOcd955AICff/4Zl112Gfbt24fevXtHsqgUQZy+TC3RVGDfYDDgb3/7G1588UUG9rugyspKfPLJJ7j++uuVfICDBg3CKaecgv/973/4+9//Dr1er1xQ+x1/85B1p+txu93Q6/VIS0tDTU0NTCYTfvjhB7jdbvTt2xevv/46XnjhBdaNLoxTmCkc/qC+yWTCkSNHcPvtt6Nbt24AfEH9NWvWYOHChbDZbI2OxKbOK5T+SmDbsXr1arz22msAgN9++63JWYfUeaWmpuKJJ56ARqPBunXr8MQTTyAnJwcAcMkllyg3hSorK2E2myNcWmpLDNpS2PLz87Fx40a4XC707NkTo0ePhiRJ8Hq90Ov1WLx4MVQqFWRZhkqlQmJiIlJTU5GYmBjpolOEcPoyhYKBfQqHSqXC4MGDMXz4cAB1+QFzcnKUxRhUquAJRf7vJeo6AvssvXr1wqhRo5S0B6NHj8a+ffvw6quvYuXKlVi8eDG2bt2Kf/7zn9BoNHjuueciXHqKBE5hpuYwqE/hCKW/Emjq1KmIjY3FmDFjoFKpmO+4iwjsr/To0QNjxoxBt27d8OCDD+LgwYPo06cPACgB/L59+yIhIYE3groCQRSGLVu2iOzsbDFu3DiRnJwsxowZIz7++OOgfWRZDnp8//33i7Fjx4ri4uL2LCpFiS+//FIkJyeLDz74QMiyLLZv3y6mT58u7rrrLmUfh8Mh/vGPf4j8/HwhRP065PF42rXM1P7mz58v0tLSxOTJk0Xfvn3FyJEjxaJFi5TnZ8+eLSRJEmeeeaYoLCwUQghRXl4uPvjgA9aPLuzYsWPKz/52Y9OmTWLo0KGiqqpKeW7p0qXtXjaKvOb6LI888oiQJEn07t1bbNiwQQjha1defvllsX///kgVmyKouT5LYP/EZrOJDRs2iDPPPFMMHz5cuN3uevtQ59NQf+WLL75odH+XyyXOOussceONN7ZjKSnahNpf+fbbb4Ne5/V626eAFFEN9Vc++ugj5fmGvlfuvPNOMW3aNFFTU9OeRaUI4HATCtn+/ftx7rnn4vLLL8fSpUuxZMkSDB48GN9++y28Xq+SIsF/t/DQoUO477778Morr+D1119HcnJyJItPEXD8dCBJkpTpQF999RXsdjtkWVamL6enpwPg9OWuhnlJKVS//PILFi1ahAULFsBqtSIlJQUAglbOraqqQlVVlTLi7ZxzzsE999zDXHBdTFN9Fo/HAwB44IEHcMstt+DDDz/EqFGjlHZl9uzZyM7OjvAZUHsLpc8S2D9ZvXo1nnrqKQDBU5i5fkPnxbykFKqW9lf+7//+D0IIpZ5wdlDn11h/ZcmSJUqMJfB75dChQ7j33nvxzjvv4LnnnkNMTEwES0/tga0AhcTlcuHll1/G+PHj8fjjjyMuLg6jR4/GxIkTsWjRIlRUVAQ1JuvXr8dTTz2FpUuX4qeffuKqhl2UfzrQ1KlTAdR1VJubvkxdBwP7FKrXXnsN559/Pv72t7/hvvvuw/Dhw/HWW2+htLQUKpVKaV8cDgdUKhXcbjcuuugi5ObmYv369ZAkiRfLXURzfZbKykoAvqntL730EsaOHQugrl3hRXLXFEqfJdDUqVPx5z//Gd9++y20Wi08Hg+/izoxBvUpVK3RX6GuIdwYy7p16/Doo4/iq6++wg8//IChQ4dGsPTUXpgchUIiyzKysrKQk5OjLAokSRLGjx8Ps9kMt9sdtP+YMWNgt9vx4IMPKkEW6nosFguuvfbaoPxvAJCeng69Xg+32w2DwQAAWLZsGaZNm8aL5S6GeUkpFJs2bcIjjzyC1157DZMmTUJMTAz++Mc/4tlnn0VeXl7Qoi8pKSmIiYnBpEmTUFFRgZ07dyoBFeaE6xrC7bP4X8N2pWsLp8+yZMkSnH322Rg3bhwAX/1h+9K5MS8phYL9FQpHuP2VcePGobq6Go899hgyMzMjVGpqb+ydUkgMBgMuvvhi3HTTTUHb4+PjodVqgxqUDRs2AABOO+00Bmy7IE5fpnD4L5LPOuusoO2BF8l+y5YtA8BRcF1RRUUFNBoNRowYgaSkJBgMBrz99tu44IIL8Nlnn+G9996D0+kEAFitVmzfvh1CCF4AdVHh9Fl+//13AGxXuipOYaZQhdNfWbJkCQBfgMW/ODO/g7oG9lcoHC2JsZxxxhkM2HYx7GFQo44dO4Z169ZhyZIlkGUZvXv3BoCgqT2VlZUoLy9XXvPQQw9h2rRpKC0tZQCuC+L0ZQoFA/sULo/HA4/Ho1zoOBwOAMA///lPTJw4ES+88AKOHDkCAEhLS8MjjzyCtWvX8gKoC2lpn+WMM85gn6WL4hRmag6D+hQu9leoOYyxUNjafKkz6pA2b94sevbsKfr37y/i4uLEwIEDxfvvvy9KS0uFEHUrGO7evVt069ZNlJWViccff1wYjUaxfv36SBadIuT3338XGRkZ4tNPPxUlJSXCbreLmTNnikGDBomHHnpIFBUVKftu2rRJDBkyRIwePVr06dNHuFwuIYRQVl6mzuvVV18ViYmJYujQoSIpKUn06dNHLFiwQJSUlAgh6tqWpUuXit69e4uamhpx4YUXigEDBij1hCtzd02DBw8WZ511lvLY4XAoP+fk5Ijbbrut3mvYpnQN7LNQuNhnoeawv0Itxf4KNYb9FWoJ3vajeoqLizFjxgxcffXV+Pbbb7Fjxw4MHz4cjz/+OP7zn/+guLhYuQsUHx+PrKws3HLLLXj88cexatUqjB49OsJnQJHA6UDUnMA8Xz/99BOOHDmC8ePH49lnn63XtgTm+dq+fTu2bt2q1BOObur88vPzkZeXh+LiYmXbq6++io0bN+Lqq68GAOj1emXhwqFDhzZYL9imdH7ss1BLsM9CTWF/hULF/gqFiv0VaikGbame4uJiOBwOXHrppcjOzkZGRgY++OADXHjhhfjss8/w5ptvwmazAQBKS0uxadMmfPnll1i7di0bky6M04GoObxIplC89957OP/88zFlyhQMGDAAb7/9NgBgxIgReOGFF7B06VJceumlqKmpgdPphBAChw4dgtlsjnDJKRLYZ6GWYJ+FmsL+CoWC/RUKB/sr1GKRHOZL0WnTpk0iKytLrFy5UgghhM1mU5674447RO/evcXmzZuFEEIcO3ZM3HbbbWLnzp0RKStFF04HoqYsW7ZMZGRkiB07dgghhLDb7cpzt956q+jVq5fYt2+fEEKI/fv3i0cffVSpH6wnXcO7774rzGazeP3118WqVavEAw88IAwGg/IdY7PZxDfffCN69uwpsrOzxcknnyxOOukkkZOTwzrSRbHPQi3FPgs1hv0Vag77KxQu9leopSQhmMmY6hs3bhzMZjN+/PFHAIDT6VQS7I8dOxZ9+/bFwoULAfhGJxgMhoiVlSIjPz8fLpcLMTEx6NatGwBgzZo1uPjiizFt2jS89957AHyLNahUKsyYMQMpKSl48cUXI1lsirAhQ4YgKytLWVk5sG0ZNGgQTj/9dPz3v/8Neg1HrHQNO3fuxPXXX48bb7wRf/zjH5XtY8aMwZVXXol77rlH2eZ0OvHiiy/CbrfDYDDgrrvugkajYV3pothnoeawz0LhYn+FGsP+CrUU+yvUEkyPQLBaraiurkZVVZWy7ZVXXsH27dvxhz/8AYAvF4/H4wEATJw4EVarVdmXjUnXw+lAFArm+aJw+NuHiRMnAoCyOm5SUhIKCwuVbbIsQ6/X45577sHf/vY33HvvvdBoNPB6vawrXQD7LBQu9lmoOeyvUDjYX6FQsL9CrYVB2y5ux44duPTSSzFp0iTk5OQoIw1ycnLwwgsvYNmyZZg+fTrcbjdUKl91KSoqQkxMDDweDzhQu+t57733MGfOHNx222145513cOutt2L27NnYtWsXTCYTLr74Yrz99tvYuHEjhg8fjtNPPx2nnHIKKisr8fjjj0e6+NROeJFM4erevTs+++wzDBw4EADgdrsBABkZGTAajQAASZKgUqlQVlZW7/Vqtbr9CksRwT4LhYt9FmoO+ysULvZXqDnsr1BrYnqELmzHjh2YOHEirr32WowZMwYbNmzAiy++iLVr12LkyJGw2Wz44YcfcOutt8JsNmPgwIHQ6XT4+uuv8euvv2LIkCGRPgVqZ5wORKHwXyQ///zzGDBgAJYsWYLnnnsOv//+OwYOHAi73Y7ly5fjlltugVqtRkpKCoQQqKqqwpYtW1g/SOmsSpKEa6+9FhaLBS+99BKEELjyyisxbdo03HTTTREuJbUn9lkoXOyzUHPYX6ETxf4KHY/9FWptDNp2UWVlZbjqqqswcOBAvPDCC8r2KVOmYOjQofjPf/6jbKuursYTTzyBsrIyGAwG3HLLLRg0aFAkik0RdvjwYVx++eV46623MHDgQAghIEkSzjrrLAwbNgzPPPMMhBAQQih3DQN5vV7eXe7keJFMre0Pf/gDEhIS8NJLL+G8887D5s2bkZubC61WG+miUTthn4Vagn0Wagr7K9Ta2F8h9leoLfBbpotyu92oqKjA5ZdfDqBu4YXevXsr0zj8HVmLxYKnnnoqaD/qmvzTgTIzMwH46pFOp6s3HUiSJJSVlSExMTHo9bz46fwayvMlSVK9PF9CCCXPVyDm+SI///dNbGwszGYzZsyYgb179yoXQLxY7jrYZ6GWYJ+FmsL+CrUW9lfIj/0VagusGV1Uamoq3n33XZx22mkAfB0PAMjMzFQaDH8unsDk2Q0l3aeuxX/xI4RQ7hx7vV6UlpYq22fMmIHPPvssYmWkyGGeL2ot/u8ij8eDZ555Bvv27cP27dt5AdQFsc9CLcU+CzWG/RVqLeyvkB/7K9QWGLTtwvr16wfAd2fH35EVQqCoqEjZ58knn8Trr7+urGrIBoX8/KNTACj1AwDOP/98rF69Gtddd12kikYRxotkak3XX389+vbti7Vr1/ICqAtjn4VOBPss1BD2V6g1sb9CAPsr1PrYihBUKpUyJcj/GAAeeughPPHEE/j999/5hUMN4nQgakpgB+T4i+TNmzfj3XffjUSxqIM59dRTsXv3bkiSxDaF2GehFmOfhRrD/gq1BvZXKBD7K9RaONKWANStfKnRaNC9e3c8++yzePrpp7F+/XoMHz48wqWjaMXpQNQcWZYBoMmLZKLmSJIEIQTbFALAPgu1DPss1BT2V6g1sL9CgdhfodbA1oQA1HVktVotXnvtNcTGxuLnn3/GqFGjIlwy6giuv/56rFy5EmvXruVquhTk+IvkkSNH8iKZWoRTx8iPfRY6EeyzUEPYX6HWwv4K+bG/Qq1BEv7wPxGA9evXY9y4cdi2bRsGDRoU6eJQB+Kf/sGOLTXk559/xg033IAdO3bwIpmIWgX7LNRS7LNQY9hfIaLWxv4KnQgGbakeq9WKmJiYSBeDOqDAvD1Ex+NFMhG1NvZZqKXYZ6HGsL9CRK2N/RVqKQZtiYio3fAimYiIiKId+ytERBQNGLQlIiIiIiIiIiIiiiKqSBeAiIiIiIiIiIiIiOowaEtEREREREREREQURRi0JSIiIiIiIiIiIooiDNoSERERERERERERRREGbYmIiIiIiIiIiIiiCIO2RERERERERERERFGEQVsiIiIi6lIeeeQRSJKk/NNqtYiPj0dOTg6uvPJKLFmy5ISOv2nTJjzyyCN45JFHsHz58tYpNBERERF1KZpIF4CIiIiIKJI8Hg8qKytRWVmJXbt24cMPP8QFF1yA9957DxaLJezjbdq0CY8++qjyePLkya1YWiIiIiLqCjjSloiIiIi6rHPOOQerVq3CokWLMHfuXOh0OgDA4sWLMXPmzAiXjoiIiIi6KgZtiYiIiKjLSklJwamnnooLL7wQ//nPf/Dpp58qzy1atAg//PADAGD+/Pk466yz0KNHD8TExMBgMKBfv36YO3cuSkpKlNf06tULs2bNUh4/+uijShqGRx55RNmem5uLm2++GT179oRer0dKSgpmzJiBnTt3tv1JExEREVHUY9CWiIiIiKjW+eefj6lTpyqPFy5cCAD4+OOPsXTpUhw+fBg2mw1OpxP79u3Df//7X0ycOBEOhyPk99i4cSNGjRqF119/HYcOHYLL5UJxcTE++ugjjBs3DuvWrWv18yIiIiKijoVBWyIiIiKiAKeccory86ZNmwAAM2bMwIIFC/D1119j+fLl+Prrr3HttdcCAHbu3InPPvsMAPDJJ5/gr3/9q/L6WbNmYdWqVVi1ahVuuOEGCCFw3XXXoaKiAgDw5z//GUuXLsVTTz0FtVqNmpoazJo1C0KI9jlZIiIiIopKXIiMiIiIiChAenq68nNlZSUAYOrUqXj88cfx/fffIz8/H06nM+g169evxx/+8AeMGTMG27ZtU7b36NEDp556qvJ406ZNyvMjRozAxRdfDAAYP348xo0bh19++QU7duzAxo0bMXr06LY6RSIiIiKKcgzaEhEREREFOHr0qPJzXFwcqqurMX78eBw5cqTR1/hHzjZnz549ys+bNm3Caaed1uB+O3fuZNCWiIiIqAtjegQiIiIiogCrV69Wfh4xYgQ+//xzJWA7cOBAfPjhh1i1ahX+/e9/K/vJstyqZbBara16PCIiIiLqWDjSloiIiIio1hdffIHly5crj2fMmIH169crj2+77TZcccUVAICff/65wWOoVHXjIo4P5vbv31/5edKkSUHv5Wez2WAymVpSfCIiIiLqJBi0JSIiIqIuq6ioCD///DPKysqwbNkyvPrqq8pzF1xwAaZNm4bi4mJl24IFC5CdnY19+/bhiSeeaPCYCQkJys9LlizBxIkTYTAYMHToUAwfPhxDhgzBtm3bsGLFClx77bWYPn06tFot8vLysG7dOnz++ecoLy9vu5MmIiIioqgnCS5NS0RERERdyCOPPIJHH320yX3OO+88LFy4EBaLBdXV1RgwYACOHTsWtM+ECROUVArXXXcd3nzzTQBASUkJsrKy6i1W9tNPP2Hy5MnYuHEjzjjjjCbz4LKLTkRERNS1MactEREREXVpKpUKFosF/fv3x/Tp07F48WIsXrwYFosFAGCxWLBs2TKcfvrpMJvNyMzMxGOPPYbHHnusweMlJyfjiy++wMiRI2E0Gus9P2rUKGzatAlz5sxBdnY2dDod4uPjMWTIEMyZMwc//PBDm54vEREREUU/jrQlIiIiIiIiIiIiiiIcaUtEREREREREREQURRi0JSIiIiIiIiIiIooiDNoSERERERERERERRREGbYmIiIiIiIiIiIiiCIO2RERERERERERERFGEQVsiIiIiIiIiIiKiKMKgLREREREREREREVEUYdCWiIiIiIiIiIiIKIowaEtEREREREREREQURRi0JSIiIiIiIiIiIooiDNoSERERERERERERRREGbYmIiIiIiIiIiIiiCIO2RERERERERERERFGEQVsiIiIiIiIiIiKiKMKgLREREREREREREVEUYdCWiIiIiIiIiIiIKIowaEtEREREREREREQURRi0JSIiIiIiIiIiIooiDNoSEREREXUy119/PSRJgiRJmDx5cqSL0yFNnjxZ+R1ef/31kS4OERERdTEM2hIRERG1guXLlysBnqb+MfgTnhMNnPXq1Sukz4Va19atW4N+vx999FHQ83a7HXq9Xnl+4sSJ9Y4xd+5c5fm0tLT2KjoRERFRVGDQloiIiIiIWtWQIUOQmJioPF65cmXQ82vXroXL5VIer1u3Dk6nM2ifFStWKD+fdtppbVRSIiIiouikiXQBiIiIiDqjGTNmYMyYMfW2DxkypE3ft6qqCrGxsW36Hh1VdnY2brnllhM6hsvlghACer2+yf3a8nPoCJ+xJEk49dRT8eWXXwKoH7Q9/rHT6cS6deuU4Gx5eTm2bdumPM+gLREREXU1HGlLRERE1AbOPvts3HPPPfX+nX322UH7lZeX47HHHsOYMWMQFxcHnU6HzMxMXHrppVi2bFm947755ptB085tNhseeOABZGdnQ6vV4qGHHlL2dTqd+O9//4uJEyciMTEROp0O6enpmD59On755ZdGy/7bb79h1qxZ6Nu3L0wmE8xmM/r3749Zs2Zh//79yn7Lly/HjTfeiFGjRiE9PR16vR4mkwl9+/bFrFmzsHXr1nrHtlqteOyxxzBq1ChYLBZotVqkpKRgxIgRuPnmm7FkyRIAwCOPPAJJkoJGW7711ltB556Xlxfy5wEA3bt3b/Azueeee4L2Oz4lw7Zt23DxxRcjKSkJer0eO3fuRF5eXlBZli9fjvnz52PUqFEwGo31pvt/+umnOO+885CWlgadToeEhASMHz8ezz33HGw2W72yBh77zTffxKJFizB+/HiYzWb06NEjrPMGgKKiItx0001IS0uDwWDAqFGj8MEHHyjPy7KM7Oxs5T3/+te/1jvGvffeqzw/aNCgZt8z8Hewbds2lJeXK49XrVoFAEhPT6+3zf+zEKLBYwHA4sWLcdFFFyE9PV35fZ5++ul47733gl4X6MCBA7jjjjuQk5ODmJgYGI1GDBo0CPfffz9KSkqaPR+/goICDBw4UPldZGdnIzc3N+TXExEREYVEEBEREdEJ++mnnwQA5d8bb7zR7Gt27NghsrKygl53/L8777wz6DVvvPFG0POnnXZag/sXFRWJESNGNHpclUolnn/++XplevTRR4UkSY2+7vPPP1f2/fOf/9xk2XU6nVi2bFnQ8SdPntzka2bMmCGEEOLhhx9ucj8AIjc3t9nfcc+ePZX9J02a1Oz+QggxadIk5TUjR44UMTExQe/7+++/i9zc3CY/h+HDhwshhPB4POKKK65o8jxycnJEfn5+UBmaOnZcXFyz53Ddddcp+w8aNEj06tWrwfd+7rnnlNc888wzyvaMjAzh8Xga/V0+/fTTzZZh3bp1Qe/15ZdfCiGEcLvdyu/01ltvFdnZ2QKAOPvss5XXBtatuLg44fV6hRBCeL1eMXPmzCZ/n9OnT69X9i+++EKYTKZGX5OZmSl27NgR9JrAenDdddcJIXx/V4MHD1a29+vXTxw+fLjZ3wURERFRuJgegYiIiKgNLFmypMHRezNmzED37t3h8XhwySWX4MiRIwAAtVqNmTNnIisrC1988YUyNfyFF17AqFGjcO211zb4PqtWrcJJJ52EadOmwWq1KqMwZ86ciU2bNgEALBYL/vCHPyArKwurV6/GkiVLIMsy7rrrLowZMwYTJkwAAHz88cd4+OGHlWObTCZceeWV6NmzJ3Jzc7F48eKg946JicGkSZMwdOhQJCYmwmg0orS0FF9//TV27twJl8uFO+64Azt27AAA7Ny5E8uXLwcAqFQqXHvttejfvz9KSkqQm5urPAcAZ555JsxmM/73v//hwIEDAIAxY8ZgxowZyj6BOVNDcfjwYTz77LP1tg8ZMqTeCGi/33//HRqNBjNnzkS/fv2wa9cuGAyGevutWrUKPXv2xGWXXQaTyYSioiIAwD/+8Y+gRbhOPvlknHnmmdi5cyc+/vhj5fdy9dVX48cff2ywDKtWrUJycjKuvPJKJCUlYfv27WGd944dOxAXF4e77roLkiRhwYIFqKioAADcf//9uPDCC9G3b1/ceOONePjhh2Gz2ZCfn4+vv/4aF154IQBfztmDBw8CgPL7aM6oUaNgNptRU1MDwJcS4YILLsDGjRthtVoB+NIe2Gw2HDhwAGvWrIHX64VarQ5KnzBhwgSoVL4Jgk8//TTeeecdAL7RyJdddhmGDx+O3NxcvPPOO3C73fj4448xYsQIZbRwbm4urrrqKtjtdgDA4MGDcckll0CWZbz33ns4ePAgjh49issuuwxbt26FWq1u8HzKysowbdo05fc/aNAg/PDDD1wkjYiIiNpGpKPGRERERJ3B8SNtG/v3008/CSGE+Pzzz4O2v/zyy8qxbDZb0KhG/6hNIeqPtL300kuVUYh+mzdvDtrnxx9/DHr+3HPPVZ675JJLlO2jRo1StsfExIjdu3cHva6mpkYUFhYGbfN6vWLt2rXizTffFM8//7x45plnxN133x30/ocOHRJCCLFx48ag0aWyLAcdy+PxiLy8vKBtDY12DEfg77Gxf8cfN/A9AYgvvvii3nGPH2nbu3dvUV5eXu93k5iYqOxzyimnBI0Ave++++qN4PUL3B4bGysOHjwY1nkHjrQFIFavXq08t3r16qDnHnjgAeW5m2++Wdl+wQUXKNsDR74Gbm/OmWeeqbxu3LhxQgghnn32WWXbkSNHgur0hg0bRHV1tdBoNMq2J598Uvl9JicnK9sfeuihoPd6+umnleeSkpKUv4u77rpL2d6/f39ht9uV1+Tn5wu1Wq08v2jRIuW5wHpw8cUXi9GjRwf9TRYXF4f8eyAiIiIKF0faEhEREUXA8TllA0fSGo1GXHHFFXjmmWcAAFu2bIHNZoPJZKp3nL/+9a/KKES/1atXBz0+/fTTGy3HmjVrAAA2mw2///57UHn69+8ftG9MTAxiYmKUx8uWLcNNN92EQ4cONXp8ADhy5Ai6d++OnJwcJCUlobS0FDt37kTfvn0xcuRI9O/fH8OGDcPUqVPRs2fPJo/V3oYMGYKLLrqo2f1uu+02xMfHB23bvXs3ysrKlMfXXHNN0CjO6667Dk8//bTy+JdffsGIESPqHfvaa69tUR5bv+zsbIwfP155PH78ePTu3VvJw7phwwblublz5+K1114DAHzzzTfIz89HRkYGPvnkE2WfWbNmhfzeEydOxNKlSwFAGWHrz12bnZ2NzMzMoHy1q1atQklJCTwej7LNvwjZ7t27g0avP/bYY3jssccafN/S0lLs2bMHAwcODPp72LNnD4xGY6PlXbNmjTK6ONAXX3yh/Dx27Fh89913SEhIaOrUiYiIiE4IFyIjIiIiagNvvPEGhBD1/k2ePBkAgoJ5ZrM5KBgKAKmpqcrPQghlOvvxBg4cWG9b4LGbU1xcDMC3IJoIWMCpd+/eTb4uPz8fF198cbMBW8C3IBoAGAwGfPTRR0oA8sCBA/j000/x5JNP4qqrrkJmZib+9a9/hVz2cE2aNKnBz+TNN99s9DUN/X5D3e/4zyHwM23oceBCXS0pQ2NSUlLqbQt878C6NXToUKWOer1evPHGG1i7dq2SGqFbt244//zzQ37vwICsx+PBmjVr8PPPPwOoC8ZmZ2cjKysLgC+FQuDicwaDAWPHjgUQXr0G6up2S/4empKSkgKz2RxWWYiIiIjCxZG2RERERBEQmI+1pqYGVqs1KHBbWFio/CxJUr1RnH7HB3uPPzbgG5HY1OhCAEhISIAkSUrg1j8KszGLFy+GzWZTHj/33HO48cYbERcXhx07dmDw4MENvu70009Hbm4uNm7ciE2bNmHfvn1Ys2YNVq1aBZfLhXvvvVfJsRoNGvr9hrrf8Z9D4Gfa0OPGRm6GWobG+PPrNvbex9etuXPnKvmFFyxYgNLSUuW5a665BlqtNuT3HjduHAwGAxwOBwBg3rx5yvH8QVvAF9x9//338fPPPweV96STToJOpwNQ//d53XXXYciQIY2+d69eveq9bvDgwbj++usbfU1jx+vbty9yc3Ph9Xrx9ddfY+bMmXj//ffrjXInIiIiai0M2hIRERFFQOB0dQB4++23ccsttwAA7HZ70OJVw4cPbzA1QqjHTk5OVo4daPv27croTpPJhJEjR2Ljxo0AgHfeeQd33313UPDUbrejuroaKSkpQYE8wDdlPi4uDgCCyh7I4XAgNzcXOTk5GDNmDMaMGQPAN5I4ISEBlZWVkGUZmzdvVt43MEAYGCTuCAYMGIDExERlpOe7776L2bNnKykS3nrrraD9j//cWot/kS//8desWRMUlB89enTQ/hdddBF69OiBQ4cO4cCBA/jf//6nPHfDDTeE9d56vR7jxo1TFhb7/PPPlecaCtoWFRUFjXYNHKk7YMAAJb0G4KuP99xzT733LCoqwurVq9G9e3cAvt/runXrAADHjh1TRnUH8ng8WLx4MU466aQGz2PChAm4//77cdNNNwEAPvzwQ1j+v707j2+iwP8//p6kbdpiW3rQlkJBUBEUBBVE0FVRFFFRXETxh4q3q7Au4qq4goCieIsnrPtVwBNkFXR1PRBQPJBTPFkORUGwQKG0tLRpm8zvj5Ih6QFtmjbT5vV8PHyYfmYy+Xz6mSSTT4dJQoJ1KQkAAIBQY2gLAAAQBueff76OPvporVu3TlLF2Y0rVqxQmzZtNH/+fOufo0vSbbfdVqdtd+/eXWeffbYWLFggSRo1apQ++OADnXjiiXI4HPrtt9/01Vdfae3atZowYYJOPfVUSdLYsWN16aWXSqo4+7dHjx4aNmyY2rdvry1btui9997T888/r8GDB+voo4+uUs/AgQP13XffBVz/1N+ePXt0zDHH6Nhjj9VJJ52krKwsxcXF6YsvvlB+fr61nv+Zn/7Dtffff19jx45VWlqa0tLSDnrGZHW2bNmixx57rNpll112mTXkCxWHw6HbbrtN48ePl1RxzdpTTz1V55xzjv73v/8FDLf79eun7t27h/Tx/Z133nm69tprZRiGXnrpJSseFRVV5ffodDp188036+6775Yk6yzZnj17HvTM1pqcdtpp1tDWdyZ3RkZGwDWTTz/9dOu2/2U6/Ae7DodDY8aM0T333COp4o8Dv/zyi84++2wlJCQoJydHK1eu1LJly3Tqqafq4osvllTx3Jo+fbpKSkq0e/du9ejRQ0OHDlV2drYKCwv1008/6dNPP9WePXu0adOmGs94vu6665STk6Nx48ZJkv7v//5PCQkJDXpJDwAAEMEa/7vPAAAAmp/Fixdb3ywvyZwxY8Yh7/PTTz+Zbdu2Dbhf5f9uvfXWgPvMmDEjYHlNtm/fbvbo0eOg25ZkTpgwIeB+EydONA3DqHH9efPmmaZpmqWlpWa3bt2qXWfEiBEBPy9evNg0TdP8448/DpnPSSedZJaVlVn5vPPOO9Wud+yxx9aqL+3btz/kY/rnaJqmefrppwfUUp1NmzbVeH9/5eXl5tChQw/62F26dDG3bt0acL+67kuV+ffgqKOOMrOysqp97Icffrja++fm5pqxsbEB6z733HN1zsM0TfPjjz+u8riXXHJJlfXS09MD1omKijILCwsD1vF4POaVV155yH6efvrpAfebN2+e2aJFi0Peb9OmTdZ9atoPRo0aFXCfe++9N6jfCwAAwMFwESYAAIAw6dKli7799ltNnDhRJ5xwgg477DBFRUWpdevWuvjii/XRRx/pqaeeCmrb6enpWrZsmaZNm6YzzzxTaWlpcjqdatGihTp37qwrrrhCr732mu64446A+02YMEFff/21RowYoY4dOyo2Nlbx8fHq2LGjrrzySutMy+joaC1atEhXX321UlNT5XK51LVrV73wwguaOHFitTklJyfr2Wef1eWXX65jjjlGKSkpcjqdSkxMVM+ePXX//fdr4cKFioo68I/BLrzwQj377LPq0qWLdW3TpsTpdOrNN9/U3Llzdd555yk9PV1RUVFKSkpS79699eijj2rFihXKyspqsByysrK0fPlyjRgxQq1atZLL5VKPHj302muv6c4776z2Pqmpqfp//+//WT/HxsYG/FwXffv2DeipFHgGrY//pRAk6fjjj69yPV+Hw6GXX35Z77//voYMGaK2bdsqJiZGLpdL7du316BBgzR16lS98cYbAfcbPHiwfvjhB40ZM0bdunXTYYcdJqfTqdTUVPXp00d33HGHvvzyS+s6uAfz1FNPaejQodbP9913H2fbAgCAkDNM0+/fHwEAAACApIceesi6RMKwYcOqDEIBAADQcLimLQAAAABJUk5OjtauXavffvst4Pq/o0aNCmNWAAAAkYehLQAAAABJ0ocffqhrrrkmIDZ06FCdcsopYcoIAAAgMnFNWwAAAAABHA6H2rVrp7vuukuzZs0KdzoAAAARh2vaAgAAAAAAAICNcKYtAAAAAAAAANgIQ1sAAAAAAAAAsBGGtgAAAAAAAABgIwxtAQAAAAAAAMBGGNoCAAAAAAAAgI0wtAUAAAAAAAAAG2FoCwAAAAAAAAA2wtAWAAAAAAAAAGyEoS0AAAAAAAAA2AhDWwAAAAAAAACwEYa2AAAAAAAAAGAjDG0BAAAAAAAAwEYY2gIAAAAAAACAjTC0BQAAAAAAAAAbYWgLAAAAAAAAADYSFe4E7Mjr9Wrbtm1KSEiQYRjhTgcAAAAAAABAM2Capvbu3ausrCw5HDWfT8vQthrbtm1TdnZ2uNMAAAAAAAAA0Axt2bJFbdu2rXE5Q9tqJCQkSKr45SUmJoY5GwAAAAAAAADNQUFBgbKzs635Y00Y2lbDd0mExMREhrYAAAAAAAAAQupQl2Tli8gAAAAAAAAAwEZsNbRdsmSJBg0apKysLBmGofnz59e47l/+8hcZhqGpU6cGxHfv3q3hw4crMTFRLVu21HXXXafCwsKGTRwAAAAAAAAAQsRWQ9uioiJ1795dzz333EHXmzdvnr7++mtlZWVVWTZ8+HD9+OOPWrBggd577z0tWbJEN954Y0OlDAAAAAAAAAAhZatr2g4cOFADBw486Dpbt27VX//6V3300Uc6//zzA5atXbtWH374oVasWKGePXtKkp555hmdd955euyxx6od8gIAAAAAAACAndjqTNtD8Xq9uvLKK3XHHXfo2GOPrbJ86dKlatmypTWwlaT+/fvL4XBo2bJljZkqAAAAAAAAAATFVmfaHsrDDz+sqKgo3XrrrdUuz8nJUXp6ekAsKipKKSkpysnJqXG7brdbbrfb+rmgoEBSxZDY6/VKqvhGN8MwZJqmTNO01j1U3Hf/YOMOh6PKtusaDzZ3aqImaqImaqImaqImaqImaqImaqImaqImaqImagpdTZWX1aTJDG1XrVqlp556SqtXr5ZhGCHd9pQpUzRp0qQq8Z07d6qkpESSFBcXp6SkJBUUFKi4uNhap0WLFkpISFBeXp5KS0uteGJiouLj47V7926Vl5db8eTkZLlcLu3cuTNgJ0hNTZXT6dSOHTsCckhPT5fH49GuXbusmGEYysjIUGlpqfLy8qx4VFSU0tLSVFxcbA2eJSkmJkYpKSkqLCxUUVGRFacmaqImaqImaqImaqImaqImaqImaqImaqImaqKmxqtp7969qg3DrDyetgnDMDRv3jwNHjxYkjR16lSNGTNGDseBKzp4PB45HA5lZ2fr119/1UsvvaTbb789oHnl5eWKjY3V3LlzdfHFF1f7WNWdaZudna28vDwlJiZa+YR7Eh9s3M5/XaAmaqImaqImaqImaqImaqImaqImaqImaqImaoqUmgoKCpScnKz8/Hxr7lidJjO03bVrl/7444+AdQYMGKArr7xS11xzjY4++mitXbtWxxxzjFauXKkTTzxRkvTxxx/r3HPP1e+//17rLyIrKChQUlLSIX95AAAAAAAAAFBbtZ072uryCIWFhdq4caP186ZNm7RmzRqlpKSoXbt2Sk1NDVg/OjpamZmZOvrooyVJXbp00bnnnqsbbrhB06dPV1lZmUaNGqVhw4bVemALAAAAAAAAAOHkOPQqjWflypU6/vjjdfzxx0uSxowZo+OPP1733ntvrbfx2muvqXPnzjrrrLN03nnn6dRTT9ULL7zQUCkDAAAAAAAAQEjZ9vII4cTlEQAAAAAAAACEWpO8PAIal2maAV/AhvpxuVwyDCPcaQAAAAAAAKCJY2gbwdxut4YOHRruNJqNuXPnKjY2NtxpAAAAAAAAoIljaAut2PV7uFNo8nqltg13CgAAAAAAAGgmGNpCktRz3M1yRLM71JW3rFwrJ08LdxoAAAAAAABoRpjSQZLkiI6S0xUT7jQAAAAAAACAiOcIdwIAAAAAAAAAgAMY2gIAAAAAAACAjTC0BQAAAAAAAAAbYWgLAAAAAAAAADbC0BYAAAAAAAAAbIShLQAAAAAAAADYCENbAAAAAAAAALARhrYAAAAAAAAAYCMMbQEAAAAAAADARhjaAgAAAAAAAICNMLQFAAAAAAAAABthaAsAAAAAAAAANsLQFgAAAAAAAABshKEtAAAAAAAAANgIQ1sAAAAAAAAAsBGGtgAAAAAAAABgIwxtAQAAAAAAAMBGGNoCAAAAAAAAgI0wtAUAAAAAAAAAG2FoCwAAAAAAAAA2wtAWAAAAAAAAAGyEoS0AAAAAAAAA2AhDWwAAAAAAAACwEYa2AAAAAAAAAGAjDG0BAAAAAAAAwEYY2gIAAAAAAACAjTC0BQAAAAAAAAAbYWgLAAAAAAAAADbC0BYAAAAAAAAAbIShLQAAAAAAAADYSFS4EwBwgGmacrvd4U6j2XC5XDIMI9xpAAAAAAAA1AlDW8BG3G63hg4dGu40mo25c+cqNjY23GkAAAAAAADUCUNbwIZW7Po93Ck0eb1S24Y7BQAAAAAAgKAwtAVsque4m+WI5ilaV96ycq2cPC3caQAAAAAAAASNiRBgU47oKDldMeFOAwAAAAAAAI3MEe4E/C1ZskSDBg1SVlaWDMPQ/PnzrWVlZWW666671K1bN7Vo0UJZWVm66qqrtG3btoBt7N69W8OHD1diYqJatmyp6667ToWFhY1cCQAAAAAAAAAEx1ZD26KiInXv3l3PPfdclWX79u3T6tWrNX78eK1evVpvv/221q1bpwsvvDBgveHDh+vHH3/UggUL9N5772nJkiW68cYbG6sEAAAAAAAAAKgXW10eYeDAgRo4cGC1y5KSkrRgwYKA2LPPPquTTjpJmzdvVrt27bR27Vp9+OGHWrFihXr27ClJeuaZZ3TeeefpscceU1ZWVoPXAAAAAAAAAAD1YauhbV3l5+fLMAy1bNlSkrR06VK1bNnSGthKUv/+/eVwOLRs2TJdfPHF1W7H7XbL7XZbPxcUFEiSvF6vvF6vJMkwDBmGIdM0ZZqmte6h4r77Bxt3OBxVtl3XeE05+m4bhiHDlIz9i0xJMg78bK0fqrhRsdBQw8UbLPdKccOUHEbFCeumadarf4ZxoBKH4QjsSSPWZMWbaJ/8b/s/h6WGfT41x9cIaqImaqImaqImaqImaqImaqImaqImagptTZWX1aTJDm1LSkp011136fLLL1diYqIkKScnR+np6QHrRUVFKSUlRTk5OTVua8qUKZo0aVKV+M6dO1VSUiJJiouLU1JSkgoKClRcXGyt06JFCyUkJCgvL0+lpaVWPDExUfHx8dq9e7fKy8uteHJyslwul3bu3BmwE6SmpsrpdGrHjh0BOaSnp8vj8WjXrl1WzDAMZWRkqLS0VHl5eQG1pqWlqbi42Bo8S1JMTIxSUlJUWFiooqIiK+5wVAwb26Slq60nWo4ypySpwOlVgdNUmschl/fAqC0vyqsiw1RGuVNRfs+PnVFeuQ1TWeXOgIFZTrRHHlNqs3+7PlujPXJKyvSLm0ZF3GUaalV+4Kod5UbFdlqYhpL94m6HqZ1RXiV6DSV6DsSLHKbyorxq6XGohV/uDVWT1xOt4o5HysgvlsfjCehfMH2Kj49XUlKSuraMt3rS2DU19T55PdFaExMjwzCUm5urmJgDX+bWkM+n5vgaQU3URE3URE3URE3URE3URE3URE3URE2hrWnv3r2qDcOsPJ62CcMwNG/ePA0ePLjKsrKyMg0ZMkS///67Pv30U2to++CDD2rWrFlat25dwPrp6emaNGmSbr755mofq7ozbbOzs5WXl2dt2w6T+GDjNeXodrt16aWXauXurTppwig5XRXDLVMSZ3DWLu5xl2rFpOd0YkqW3nzzTblcroD169ont9utoUOHatXubeo1YeSBnnCmba3jHneplk18Rr1S22rOnDmKjY21ljX3v9ZREzVREzVREzVREzVREzVREzVREzVRk71rKigoUHJysvLz8625Y3Wa3Jm2ZWVluvTSS/Xbb79p0aJFAcVlZmZWmWSXl5dr9+7dyszMrHGbLperyrBNqviF+s5G9fH98iurKV75/sHE6/qYtY37bpumKdPYP1zzU/nnkMaN/QO3Boo3aO5+cdOQvGbFE9EwjJD0T6rYZuWeNFZNgUk2vT753w7Fc7ih43Z+jQg2Tk3URE3UdLA4NVETNVHTweLURE3URE0Hi1MTNTWHmmq6T5Vt1Gotm/ANbDds2KBPPvlEqampAcv79OmjPXv2aNWqVVZs0aJF8nq96t27d2OnCwAAAAAAAAB1ZqszbQsLC7Vx40br502bNmnNmjVKSUlR69atdckll2j16tV677335PF4rOvUpqSkKCYmRl26dNG5556rG264QdOnT1dZWZlGjRqlYcOGKSsrK1xlAQAAAAAAAECt2Wpou3LlSvXr18/6ecyYMZKkESNGaOLEiXr33XclST169Ai43+LFi3XGGWdIkl577TWNGjVKZ511lhwOh4YMGaKnn366UfIHAAAAAAAAgPqy1dD2jDPOqHIxYX8HW+aTkpKi119/PZRpAQAAAAAAAECjsdXQFgAAAPVnmqbcbne402g2XC5XtV9IAQAAADQUhrYAAADNjNvt1tChQ8OdRrMxd+5cxcbGhjsNAAAARBCGtgAAAM3Uil2/hzuFJq9XattwpwAAAIAIxNAWAACgGes57mY5ojnkqytvWblWTp4W7jQAAAAQoYI+gt+xY4d++ukn5ebmSpLS0tJ0zDHHKD09PWTJAQAAoH4c0VFyumLCnQYAAACAOqjT0Pann37SzJkzNW/ePP3yyy/VrtOxY0cNGTJEI0aMUJcuXUKSJAAAAAAAAABECkdtVlq1apXOP/98devWTY8//rh+/vlnmaZZ7X8///yzHn30UXXt2lWDBg3S6tWrG7oGAAAAAAAAAGg2anWmba9evWQYhkzTlMPhUPfu3XXCCSfoyCOPVHJyskzTVF5enjZu3KhvvvlG3333nbxer95//3198MEHKi8vb+g6AAAAAAAAAKBZqPXlEXr27Knrr79egwcPVqtWrQ667s6dOzV//nz961//0sqVK+udJAAAAAAAAABEiloNbb/44gv17du31htt1aqVbrjhBt1www366quvgk4OAAAAAAAAACJNra5pW5eBbSjvCwAAAAAAAACRplZDWwAAAAAAAABA46jV5RE6duxY5w0bhqGff/65zvcDAAAAAAAAgEhWq6Htr7/+KsMwar1R0zTrtD4AAAAAAAAAoEKthrZSxSAWAAAAAAAAANCwajW09Xq9DZ0HAAAAAAAAAEB8ERkAAAAAAAAA2EqtL49QnW3btmn16tXas2dPtWfjXnXVVfXZPAAAAAAAAABEnKCGth6PRzfddJNmzpxZ47VuDcNgaAsAAAAAAAAAdRTU0Hbq1Kl66aWXQp0LAAAAAAAAAES8oK5p+/rrr8swDPXu3VvSgbNqBwwYIEnq27ev7r333tBlCQAAAAAAAAARIqgzbdevXy9Juuuuu/TnP/9ZknTjjTeqb9++uu222/TMM8/o9ttvD12WAAAAABBCpmnK7XaHO41mw+VyyTCMcKcBAECzEdTQtqysTJKUmpqqqKgoeTwe7d27V5J03nnn6amnntLEiRN18cUXhy5TAAAAAAgRt9utoUOHhjuNZmPu3LmKjY0NdxoAADQbQQ1tU1JStH37dpWUlCgtLU3bt2/XtGnTlJ2drVmzZkmSNm7cGNJEAQAAACDUVuz6PdwpNHm9UtuGOwUAAJqdoIa2HTp00Pbt25WXl6fevXvrnXfe0X/+8x/95z//kVRxjdujjjoqpIkCAAAAQEPoOe5mOaKD+mgU0bxl5Vo5eVq40wAAoFkK6sjk5JNP1urVq7Vhwwbdcccd+u9//2tdMkGqGNref//9IUsSAAAAABqKIzpKTldMuNMAAACwBDW0ffzxx/X4449bP3/xxReaPn26tm7dqvbt2+v6669Xr169QpYkAAAAAAAAAESKkPwboF69ejGkBQAAAAAAAIAQCGpou3nz5lqt165du2A2DwAAAAAAAAARK6ih7eGHHy7DMA66jmEYKi8vDyopAAAAAAAAAIhUQV8ewTTNUOYBAAAAAAAAAFCQQ9vTTjutypm2ubm5+t///iev16u2bdvqiCOOCEmCAAAAAAAAABBJghrafvrpp9XGf/31V5133nnaunWrpk6dWo+0AAAAAAAAACAyOUK5scMPP1y33HKL9u7dq7///e+h3DQAAAAAAAAARISQDm09Ho+WLFkiSfrqq69CuWkAAAAAAAAAiAhBXR6hY8eOVWIej0e7du1ScXGxJCkhIaF+mQEAAAAAAABABApqaPvrr79W+SIySTJN07p93XXXBZ8VAAAAAAAAAESooIa2UuCA1icpKUlHHnmkbrzxRl1//fX1SgwAAAAAAAAAIlFQQ1uv1xvqPAAAAAAAAAAACvKLyF5++WW98sorys3NrbKsrKxMmzdv1ubNm+u83SVLlmjQoEHKysqSYRiaP39+wHLTNHXvvfeqdevWiouLU//+/bVhw4aAdXbv3q3hw4crMTFRLVu21HXXXafCwsI65wIAAAAAAAAA4RDU0Pbqq6/W1VdfrfXr11dZtnz5ch1++OHVflnZoRQVFal79+567rnnql3+yCOP6Omnn9b06dO1bNkytWjRQgMGDFBJSYm1zvDhw/Xjjz9qwYIFeu+997RkyRLdeOONdc4FAAAAAAAAAMIh6Gva1qSsrExS9de8PZSBAwdq4MCB1S4zTVNTp07VuHHjdNFFF0mqOOM3IyND8+fP17Bhw7R27Vp9+OGHWrFihXr27ClJeuaZZ3TeeefpscceU1ZWVpBVAQAAAAAAAEDjqPXQ9rvvvtOaNWsCYh988IE2btxo/ez1evXWW29JklwuV2gy3G/Tpk3KyclR//79rVhSUpJ69+6tpUuXatiwYVq6dKlatmxpDWwlqX///nI4HFq2bJkuvvjikOYEAAAAAAAAAKFW66HtvHnzdN9991k/m6apBx98sNp1DcMI6vIIB5OTkyNJysjICIhnZGRYy3JycpSenh6wPCoqSikpKdY61XG73XK73dbPBQUFkiqG0L4vXTMMQ4ZhyDTNgLOIDxWv/KVtdY07HI4q265rvKYcfbcNw5BhSsb+RaYkGQd+ttYPVdyoWGio4eINlnuluGFKDqPiKiOmadarf4ZxoBKH4QjsSSPWZMWbaJ/8b/s/h6WGfT41x9cIaqImamq6NXm93gPvK37vJz52fy0/aLyR3p987/G+/khi32tmNfnWqXLcJTWrY6OGrMkwDxzDVj4WZt+jJmqiJmqiJmqqPsfKy2pSp8sjVP6lVP7ZP8F//OMfddl0WE2ZMkWTJk2qEt+5c6d1vdy4uDglJSWpoKBAxcXF1jotWrRQQkKC8vLyVFpaasUTExMVHx+v3bt3q7y83IonJyfL5XJp586dAb+/1NRUOZ1O7dixIyCH9PR0eTwe7dq1y4oZhqGMjAyVlpYqLy/PikdFRSktLU3FxcXW4FmSYmJilJKSosLCQhUVFVlxh6Ni2NgmLV1tPdFylDklSQVOrwqcptI8Drm8Bw7V8qK8KjJMZZQ7FeXX+p1RXrkNU1nlzoADwZxojzym1Gb/dn22RnvklJTpFzeNirjLNNSq/MCllsuNiu20MA0l+8XdDlM7o7xK9BpK9ByIFzlM5UV51dLjUAu/3BuqJq8nWsUdj5SRXyyPxxPQv2D6FB8fr6SkJHVtGW/1pLFraup98nqitSYmRoZhKDc3VzExMdb6Dfl8ao6vEdRETdTUdGsqLS1Vdna2Vu7aqmhJWU3stVwK//tT3P73+OzENO3bt09xcXHse82spvj4eElSlw4dA46Fw73vNaXnk9cTrR2t20huad++fcrPz7fWZ9+jJmqiJmqiJmqqvqa9e/eqNgyzpslrJZ999pk+/fRTSdKkSZNkGIauvvpqtWvXzlrH4XAoOTlZZ5xxhrp27VqrBGpMzDA0b948DR48WJL0yy+/6IgjjtA333yjHj16WOudfvrp6tGjh5566im99NJLuv322wOaV15ertjYWM2dO7fGyyNUd6Ztdna28vLylJiYaOUT7kl8sPGacnS73br00ku1cvdWnTRhlJyuiuGW3f+iX5t4Y52l4HGXasWk53RiSpbefPPNKpcFqWuf3G63hg4dqlW7t6nXhJEHetIEz7yoTbwhcve4S7Vs4jPqldpWc+bMUWxsrLWsuf+1jpqoiZqoyRcvKSnRsGHDtDx3i06a+FdFuWIC1rf7a/lB4430/uR7j++Z2kZz5sxRXFwc+14zq8l3LFzluEtqVsdGDVmTx12q5ZOeVc+UNlWOhdn3qImaqImaqImaqs+xoKBAycnJys/Pt+aO1an1mbann366Tj/9dEkVQ1vTNHXdddepb9++td1EvXTo0EGZmZlauHChNbQtKCjQsmXLdPPNN0uS+vTpoz179mjVqlU68cQTJUmLFi2S1+tV7969a9y2y+Wq9hq8DofDOhvVx/fLr6ymeOX7BxOv62PWNu67bZqmTGP/QZifyj+HNG7sP3hsoHiD5u4XNw3Jax64hEYo+idVbLNyTxqrpsAkm16f/G+H4jnc0HE7v0YEG6cmaqKm8NfkOyis2HjDvsY31/cn33u8aZpWb9j3mldNvnWqO+6Sms+x0SHj9cjdNGS91oTqWDgS9r1g4tRETcHEqYmaqMmeNdV0n8rqdHkEn9pee6GuCgsLA77YbNOmTVqzZo1SUlLUrl07jR49WpMnT9ZRRx2lDh06aPz48crKyrLOxu3SpYvOPfdc3XDDDZo+fbrKyso0atQoDRs2TFlZWQ2SMwAAAAAAAACEUlBD27lz5+qDDz5QamqqHn300YBlf//737V7924NHDhQQ4cOrdN2V65cqX79+lk/jxkzRpI0YsQIzZw5U3feeaeKiop04403as+ePTr11FP14YcfBvzz59dee02jRo3SWWedJYfDoSFDhujpp58OpkwAAAAAAAAAaHRBDW2ffPJJLVu2TPfee2+VZcnJyXriiSe0fv36Og9tzzjjjCrXpfBnGIbuu+8+3XfffTWuk5KSotdff71OjwsAAAAAAAAAdlG7iyhU8r///U+Sqr1OrO9asmvXrq1HWgAAAAAAAAAQmYIa2hYXF0uSdu/eXWWZL7Zv3756pAUAAAAAAAAAkSmooW3btm0lSQ8//HDA4Hb37t165JFHAtYBAAAAAAAAANReUEPbAQMGyDRN/fDDDzriiCN07rnn6txzz9WRRx6p7777ToZhaMCAAaHOFQAAAAAAAACavaCGtmPHjlVKSookKT8/XwsWLNCCBQuUn58vSWrZsqXGjh0buiwBAAAAAAAAIEIEfXmETz75RMcee6wkyTRN67+uXbvqk08+4fIIAAAAAAAAABCEqGDv2KNHD3333Xf69ttvtX79eklSp06d1L1795AlBwAAAAAAAACRJuihrU/37t2rDGoXL16s2bNn65///Gd9Nw8AAAAAAAAAEaXeQ1ufr7/+WrNnz9bcuXOVk5MjSQxtAQAAAAAAAKCO6jW0/fbbbzV79mzNmTNHv/32mxU3TVOGYdQ7OQAAAAAAAACINHUe2q5fv16zZ8/W7NmztW7dOitumqZ1u0ePHho0aFBoMgQAAAAAAACACFLroe0jjzyi2bNn69tvv7VivkGt0+mUx+ORYRh6/PHHNXr06JAnCgAAAAAAAACRwFHbFceOHatvv/1WpmnKNE05nU71799f06dP17Zt26z1YmJiGiRRAAAAAAAAAIgEdb48gmEYGjZsmKZOnapWrVo1RE4AAAAAAAAAELFqfaatv9mzZ6tbt266+eabtXDhQnm93lDnBQAAAAAAAAARqdZD2xtvvFEpKSnW5RF27NihF154Qeecc44yMjIaMkcAAAAAAAAAiBi1HtpOnz5df/zxh95//31deeWVSkhIsAa4u3btkmEYkqR//OMfuvTSS/Xaa681WNIAAAAAAAAA0FzV6Zq2UVFRGjhwoAYOHCi326333ntPs2fP1vvvv6+SkhJJ0t69e/Xvf/9bb7/9toYPH94gSQMAIpdpmnK73eFOo9lwuVzWH14BAAAAAPZQ5y8i83G5XBoyZIiGDBmiwsJCzZ8/X2+88YYWLFig8vJymaYZyjwBAJAkud1uDR06NNxpNBtz585VbGxsuNMAAAAAAPgJemjr77DDDtMVV1yhK664Qrt379bcuXM1e/bsUGwaAIBqrdj1e7hTaPJ6pbYNdwoAAAAAgGqEZGjrLyUlRTfddJNuuummUG8aAIAAPcfdLEd0yN/Kmj1vWblWTp4W7jQAAAAAADXgky4AoMlyREfJ6YoJdxoAAAAAAISUI9wJAAAAAAAAAAAOYGgLAAAAAAAAADbC5REAAEC9mKYpt9sd7jSaDZfLJcMwwp0GAAAAgDBiaAsAAOrF7XZr6NCh4U6j2Zg7d65iY2PDnQYAAACAMKr30Hbnzp364IMPJElXXXVVvRMCAABN04pdv4c7hSavV2rbcKcAAAAAwAbqPbRdv369rr76ajkcDoa2AABEuJ7jbpYjmn/IU1fesnKtnDwt3GkAAAAAsImQfaoyTTNUmwIAAE2UIzpKTldMuNMAAAAAgCbNEe4EAAAAAAAAAAAHMLQFAAAAAAAAABup9+URkpKSdNppp8kwjFDkAwAAAAAAAAARrd5D265du+rTTz8NQSoAAAAAAAAAAC6PAAAAAAAAAAA2wtAWAAAAAAAAAGyEoS0AAAAAAAAA2AhDWwAAAAAAAACwEYa2AAAAAAAAAGAjUcHcacmSJZKk448/XgkJCSFNCAAAAAAAAAAiWVBn2p5xxhk688wz9f3331dZ9uWXX8rpdCoqKqh5MAAAAAAAAABEtKAvj2CaZrVxj8cj0zRrXF4fHo9H48ePV4cOHRQXF6cjjjhC999/f8Bjmaape++9V61bt1ZcXJz69++vDRs2hDwXAAAAAAAAAGgItT4ddvPmzfr1118DYt98843Ky8utn71er1599dWKDTfAmbYPP/ywpk2bplmzZunYY4/VypUrdc011ygpKUm33nqrJOmRRx7R008/rVmzZqlDhw4aP368BgwYoJ9++kmxsbEhzwkAAAAAAAAAQqnWk9UZM2bovvvus342TdMalFZmGIbat29f/+wq+eqrr3TRRRfp/PPPlyQdfvjheuONN7R8+XIrp6lTp2rcuHG66KKLJEkvv/yyMjIyNH/+fA0bNizkOQEAAAAAAABAKNXpdNjKlzw42CUQbr755uAyOoi+ffvqhRde0Pr169WpUyd9++23+uKLL/TEE09IkjZt2qScnBz179/fuk9SUpJ69+6tpUuX1ji0dbvdcrvd1s8FBQWSKs4c9nq9kioG0YZhVLn0w6HivvsHG3c4HNVebqIu8Zpy9N02DEOGKRn7F5mSZBz42Vo/VHGjYqGhhos3WO6V4oYpOYyKq4yYplmv/hnGgUochiOwJ41YkxVvon3yv+3/HJYa9vnUHF8j7FqT1+uVYRjW80SSLfa9g8bt9nzS/teZ/b9/3+802D7598T3IHZ9jThoPMx98u+JaZr1ej75euJ7kIastbn2yb8nvtcjXsubV02+daocd0m2fI1okHg9czfMA8ewlY+F2feoiZqoiZqoiZqqz7HysprUemjbo0cPjRgxQpI0a9YsGYahc889V+np6QEJJCcnq1+/ftbZsKE0duxYFRQUqHPnznI6nfJ4PHrggQc0fPhwSVJOTo4kKSMjI+B+GRkZ1rLqTJkyRZMmTaoS37lzp0pKSiRJcXFxSkpKUkFBgYqLi611WrRooYSEBOXl5am0tNSKJyYmKj4+Xrt37w64hERycrJcLpd27twZsBOkpqbK6XRqx44dATmkp6fL4/Fo165dVswwDGVkZKi0tFR5eXlWPCoqSmlpaSouLrYGz5IUExOjlJQUFRYWqqioyIo7HBUfrtukpautJ1qOMqckqcDpVYHTVJrHIZf3wKFaXpRXRYapjHKnovyeHzujvHIbprLKnQEHgjnRHnlMqc3+7fpsjfbIKSnTL24aFXGXaahV+YFLLZcbFdtpYRpK9ou7HaZ2RnmV6DWU6DkQL3KYyovyqqXHoRZ+uTdUTV5PtIo7Hikjv1gejyegf8H0KT4+XklJSeraMt7qSWPX1NT75PVEa01MjAzDUG5urmJiYqz1G/L51BxfI+xaU25urrKzs1WSFKcMb5R2SrbY96Sm83wqkHRk23bKTsuynif16VNpaamys7NVlOiSJFu/Rti2T94ode14pLIT05Sbm6u0tLR6PZ98PVm5a6uiJWXZZN9rSn2K2/8en52Ypn379ikuLo7X8mZWU3x8vCSpS4eOAcfC4d73mtLzyeuJ1o7WbSS3tG/fPuXn51vrs+9REzVREzVREzVVX9PevXtVG4ZZeTxdCw5HxVkHn3/+ufr27VvXuwdt9uzZuuOOO/Too4/q2GOP1Zo1azR69Gg98cQTGjFihL766iudcsop2rZtm1q3bm3d79JLL5VhGJozZ061263uTNvs7Gzl5eUpMTFRkj0m8cHGa8rR7Xbr0ksv1crdW3XShFFyuiqGW3b/i35t4o11loLHXaoVk57TiSlZevPNN+VyuQLWr2uf3G63hg4dqlW7t6nXhJEHetIEz7yoTbwhcve4S7Vs4jPqldpWc+bMCbiWdXP/a12k1FRcXKxhw4Zp5a6t6jVhpByxMbbY9w4at9nzyVNaqpUTn1PP1DaaPXu2YmNj69WnkpISqyc9J46UMybGtq8RB42HsU/ekor3E19P4uLi6vV88vVkee4WnTTxr4pyxQSsb/fX8oPGG6lPvvf4nqltNGfOHMXFxfFa3sxq8h0LVznukmz3GmHX55PHXarlk55Vz5Q2VY6F2feoiZqoiZqoiZqqz7GgoEDJycnKz8+35o7VCerbwjZt2iRJysrKCubuQbvjjjs0duxY6zIH3bp102+//aYpU6ZoxIgRyszMlCRt3749YGi7fft29ejRo8btulyuKsM2qeIX6jsb1cf3y6+spnjl+wcTr+tj1jbuu22apkxj/0GYn8o/hzRuSGY14VDFGzR3v7hpSF7zwCU0QtE/qWKblXvSWDUFJtn0+uR/OxTP4YaO2/k1Ith4Q9dkXSZh//OkYkH4971Dxm32fPKaFf8Ev/LzJJg++fckmNzp04H3E19PfPt/sM8nX0+sXBqw1ubaJ/+e+PrBa3nzqsm3TnXHXZL9XiMaLF6P3E1D1mtNqI6FI2HfCyZOTdQUTJyaqIma7FlTTfepso1arVWJ0+nUzz//rK+++kpSxRv1I488opNPPlnHH3+8Hn300WA2e0j79u2rUpjT6bSm1x06dFBmZqYWLlxoLS8oKNCyZcvUp0+fBskJAAAAAAAAAEIpqDNtH3jgAb3wwgs6/fTTtWjRIr344osaO3asDKPiNOLvvvtOiYmJuummm0Ka7KBBg/TAAw+oXbt2OvbYY/XNN9/oiSee0LXXXiupYmI9evRoTZ48WUcddZQ6dOig8ePHKysrS4MHDw5pLgAAAAAAAADQEIIa2n799deSKoaokvTaa69Jqrho7759++T1ejVjxoyQD22feeYZjR8/Xrfccot27NihrKws3XTTTbr33nutde68804VFRXpxhtv1J49e3Tqqafqww8/DLiuJQAAAAAAAADYVVBD2y1btkiSjjzySEnS6tWrZRiGvvvuO73zzju67bbbtHbt2tBluV9CQoKmTp2qqVOn1riOYRi67777dN9994X88QEAAAAAAACgoQV1TduCggJJFWfW/v7779q7d68yMzN1+OGHq3v37pIqvrUYAAAAAAAAAFA3QZ1pm5ycrNzcXL300kvKzs6WJB1zzDGSpNzcXElSampqiFIEAAAAAAAAgMgR1ND25JNP1n/+8x+98cYbkiouSXDGGWdIkjZs2CBJ6tChQ2gyBAAAAAAAAIAIEtTQ9v7779fSpUuts2qPOuoo/eUvf5EkvfXWW5Kk008/PUQpAkD4mKYpt9sd7jSaDZfLJcMwwp0GAAAAAAC2FtTQ9rjjjtP//vc/LV26VNHR0frTn/6kuLg4SdLTTz8t0zTVqVOnkCYKAOHgdrs1dOjQcKfRbMydO1exsbHhTgMAAAAAAFsLamgrSSkpKTr//POrxPv27VuvhADAjlbs+j3cKTR5vVLbhjsFAAAAAACahKCHtpL09ddfa+XKldqzZ4+8Xm+V5ffee299Ng8AttJz3M1yRNfrZTMiecvKtXLytHCnAQAAAABAkxHU9KG4uFiDBg3S4sWLD7oeQ1sAzYkjOkpOV0y40wAAAAAAAM1cUEPbBx98UIsWLap2mWEYMk2TL5oBAAAAAAAAgCA4grnT22+/LcMwdN5550mqGNTeeeeduummm+R0OnXqqadqxowZIU0UAAAAAAAAACJBUEPbX3/9VZL0l7/8xYpdeOGFmjZtmsaPH68vv/xSJSUlIUkQAAAAAAAAACJJUENb0zQlSUlJSYqOjpYk7dq1S5J08sknyzRNPf744yFKEQAAAAAAAAAiR1DXtE1NTdW2bdu0b98+ZWRkaOvWrXr44YfldDr19NNPS5K2bt0a0kQBAAAAAAAAIBIEdabtkUceKani7NpTTz1Vpmlq6dKlGjRokBYsWCDDMNStW7eQJgoAAAAAAAAAkSCoM20HDBignJwc5ebmaty4cXr//fe1d+9ea3l8fLyeeOKJkCUJAAAANGWmacrtdoc7jWbD5XLJMIxwpwEAANBgghrajh07VmPHjrV+/v777zVr1ixt3bpV7du31xVXXKHs7OyQJQkAAAA0ZW63W0OHDg13Gs3G3LlzFRsbG+40AAAAGkxQQ9vK2rVrp/Hjx4diUwAAAECztWLX7+FOocnrldo23CkAAAA0uKCGtosXL9bnn3+uFi1a6Pbbbw9Y9vjjj6uoqEh/+tOf1K9fv5AkCQAAADQXPcfdLEd0SM6diCjesnKtnDwt3GkAAAA0iqCOFidPnqxPP/1UY8aMqbIsNzdXjzzyiPr168fQFgAAAKjEER0lpysm3GkAAADAxhzB3On777+XJJ1xxhlVlp166qkyTVPfffddvRIDAAAAAAAAgEgU1NC2oKBAklRcXFxlWUlJScA6AAAAAAAAAIDaC2pom5mZKUl67rnnVFZWZsXLy8v17LPPSpIyMjJCkB4AAAAAAAAARJagrml7xhln6OWXX9aSJUvUpUsX9e/fX5L0ySefaNOmTTIMg+vZAgAAAAAAAEAQghrajh07VnPnzlVJSYk2bdqkf/3rX9Yy0zQVGxuru+66K2RJAgAAAAAAAECkCOryCJ07d9bbb7+tVq1ayTTNgP/S09P19ttvq0uXLqHOFQAAAAAAAACavaDOtJWkAQMGaNOmTfr444+1fv16SVKnTp10zjnnKC4uLmQJAgAAAAAAAEAkCXpoK0lxcXG66KKLQpULAAAAAAAAAES8eg1t586dq1dffVVr167Vvn37tHHjRj366KMyTVO33HKL0tLSQpUnAAAAAAAAAESEoIa2pmlq+PDhmjNnjvWzYRiKjY3Vf//7Xy1fvlxpaWm65ZZbQposAAAAAAAAADR3QX0R2TPPPKPZs2dbXz7m77zzzpNpmpo/f34o8gMAAAAAAACAiBLU0Pall16SYRjq06eP/vWvfwUs69SpkyRpw4YN9c8OAAAAAAAAACJMUJdHWL9+vSTpnnvuUVJSUsCyVq1aSZJycnLqmRoAAAAAIFKYpim32x3uNJoNl8slwzDCnQYAIEhBDW2jo6PldrtVWFhYZWjrO8M2Li6u/tkBAAAAACKC2+3W0KFDw51GszF37lzFxsaGOw0AQJCCGtp269ZNS5cu1cSJEzVy5EgrvmTJEj3wwAMyDEM9evQIVY4AAAAAgAixYtfv4U6hyeuV2jbcKQAA6imooe11112nr776SuvWrdOtt95q/ZOLfv36yTRNGYah6667LqSJAgAAAAAiQ89xN8sRHdTH1YjmLSvXysnTwp0GACAEgnoXvOaaa/Tpp5/qlVdekSRraGuapiTpqquu0vDhw0OUIgAAAAAgkjiio+R0xYQ7DQAAwiboP13OmjVLF154oV599VXri8k6deqk4cOH65JLLglZggAAAAAAAAAQSeo8tHW73Vq2bJkkqUePHhoyZEjIkwIAAAAAAACASOWo6x1iYmJ05plnql+/fvr6668bIicAAAAAAAAAiFh1HtoahqE2bdpIklJTU0OeEAAAAAAAAABEsjoPbSXphhtukGmaeuONN0KdzyFt3bpVV1xxhVJTUxUXF6du3bpp5cqV1nLTNHXvvfeqdevWiouLU//+/bVhw4ZGzxMAAAAAAAAAghHUF5G1adNGHTt21KuvvqpNmzbpggsuUEZGhgzDCFjvqquuCkmSPnl5eTrllFPUr18/ffDBB2rVqpU2bNig5ORka51HHnlETz/9tGbNmqUOHTpo/PjxGjBggH766SfFxsaGNB8AAAAAAAAACLWghrbXXXedNaD98ssv9eWXX1ZZxzCMkA9tH374YWVnZ2vGjBlWrEOHDtZt0zQ1depUjRs3ThdddJEk6eWXX1ZGRobmz5+vYcOGhTQfAAAAAAAAAAi1oIa2UsWAtLG9++67GjBggIYOHarPPvtMbdq00S233KIbbrhBkrRp0ybl5OSof//+1n2SkpLUu3dvLV26tMahrdvtltvttn4uKCiQJHm9Xnm9XkkVQ2jDMGSaZkDth4r77h9s3OFwVNl2XeM15ei7bRiGDFMy9i8yJck48LO1fqjiRsXCwPOyQxtvsNwrxQ1TchgVVxkxTbNe/fM/U91hOAJ70og1WfEm2if/2/7PYSn455NhGAE9scO+5/+Ydu+TfM+X/a9xlV9X6/q88Xq9AT3xPUa4972Dxu3WJ+1/nfHrSX3en/x74nsQO+x7Ta1P/j3xvfYEexzh64nvQRqy1ubaJ/+e+F6P6nO853/bqNSTcO97DRJvgJr8eyLV3I/a9sm3TpXjrkasqXK8qfXJMBXQj4D9PIjPT77/Bxx3NXJNtYnbuU81HQsH+3m2KX7OpSZqoiZqsntNlZfVJKih7YQJE4K5W7398ssvmjZtmsaMGaN//OMfWrFihW699VbFxMRoxIgRysnJkSRlZGQE3C8jI8NaVp0pU6Zo0qRJVeI7d+5USUmJJCkuLk5JSUkqKChQcXGxtU6LFi2UkJCgvLw8lZaWWvHExETFx8dr9+7dKi8vt+LJyclyuVzauXNnwE6Qmpoqp9OpHTt2BOSQnp4uj8ejXbt2WTHDMJSRkaHS0lLl5eVZ8aioKKWlpam4uNgaPEtSTEyMUlJSVFhYqKKiIivucFR8uG6Tlq62nmg5ypySpAKnVwVOU2keh1zeA4cAeVFeFRmmMsqdivJ7fuyM8sptmMoqdwYcJOREe+QxpTb7t+uzNdojp6RMv7hpVMRdpqFW5QcutVxuVGynhWko2S/udpjaGeVVotdQoudAvMhhKi/Kq5Yeh1r45d5QNXk90SrueKSM/GJ5PJ6A/gXTp/j4eCUlJalry3irJ41dU1Pvk9cTrTUxMTIMQ7m5uYqJibHWD+b5VFJSouzsbJUkxamtJ1plHoct9r2m1Kft+z9KtGnTJqAnwb7u5ebmWj3J8EZpp2SLfU9qOn0qkHRk23bKTsuyelKf96fS0lJlZ2erKNElSbbZ95pUn7xR6trxSGUnpik3N1dpaWn1Oo7w9WTlrq2KlpRlk32vKfUpbv97fHZimvbt26e4uLh6He+VlpYqOjpaDsMRcNzVmDU19T75jruSHRWXPKvvcXl8fLwkqUuHjgE9Cfe+15T65PVEa0frNpJb2rdvn/Lz8631g/n85HA4lJmZqa77j7scZU5b7HtNqU9ub5T1e/Y/7qrpM2Fz/JxLTdRETdRk95r27t2r2jDMyuNpG4uJiVHPnj311VdfWbFbb71VK1as0NKlS/XVV1/plFNO0bZt29S6dWtrnUsvvVSGYWjOnDnVbre6M22zs7OVl5enxMRESfaYxAcbrylHt9utSy+9VCt3b9VJE0bJ6ap4Q7fTX4qDjTfWX7897lKtmPScTkzJ0ptvvimXyxWwfl375Ha7NXToUK3avU29Jow80BOb/0U/2HhD5O5xl2rZxGfUK7Wt5syZE3At62CeT8XFxbrsssu0ctdWqyd22Pf8H9PufSp3l2r5xGd0Ulq2Zs+ebfUk2Ne94uJiDRs2zOqJIzbGFvveQeM265OntFQrJz6nnqltrJ7U5/2ppKTE6knPiSPljImxxb7XlPrkLal4P/H1JC4url7HEb6eLM/dopMm/lVRrpiA9e30GmHXPvne43umttGcOXMUFxdXr+O9kpISXXbZZVqx63f1nvhX6z2+MWsKiElNrk/+PfEdd9XnuNx3LFzluKsRa6ocb2p98rhLtXzSs+qZ0qbKsXAwn5+szyf+x12NXFNt4nbuU03HwnY+4yzYODVREzVRU1OtqaCgQMnJycrPz7fmjtUJ+vIIPt99953Wr18vSerUqZOOO+64+m6yRq1bt9YxxxwTEOvSpYveeustSVJmZqYkafv27QFD2+3bt6tHjx41btflclUZtkkVv1Df2ag+vl9+ZTXFK98/mHhdH7O2cd9t0zRlGvvf9P1U/jmkcWP/QUkDxRs0d7+4aUhe88A/OQpF/6SKbVbuSWPVFJhk0+uT/+1QPId9L9pVehLmfS8wSZv3yfd8Mc1qe1LX5411mYT9PTlY7vSp5rjX9Fbbk2Den/x7Ekzu9OnA+4mvJ779P9jjCF9PrFwasNbm2if/nvj6UZ/jPf/b1R132e01wo598u+JVP/jct861R13SfZ7jWiweD1yNw0F9CMUx8LVHnfVlHtN8QjuU0McCze1z7nBxqmJmoKNm6YZcCIggudyuQ553NUc9r2a7lNZ0EPbVatW6eqrr9ZPP/0UED/22GM1c+ZMnXDCCcFuukannHKK1q1bFxBbv3692rdvL6niS8kyMzO1cOFCa0hbUFCgZcuW6eabbw55PgAAAAAAAIhcvn8xi/qbO3duwL+WjXRBDW03btyoM888U4WFhVVOSf7hhx905plnatWqVTriiCNCkqTPbbfdpr59++rBBx/UpZdequXLl+uFF17QCy+8IKliYj169GhNnjxZRx11lDp06KDx48crKytLgwcPDmkuAAAAAAAAgCSt2PV7uFNo0nqltg13CrYT1ND2gQcesC6am5mZqeOPP16GYeibb77RH3/8ob179+qBBx7QSy+9FNJke/XqpXnz5unuu+/Wfffdpw4dOmjq1KkaPny4tc6dd96poqIi3XjjjdqzZ49OPfVUffjhh0zqAQAAAAAA0GB6jrtZjuh6X4k0onjLyrVy8rRwp2FLQe1JCxculGEYGjp0qF599VVFRVVspry8XFdccYXefPNNLViwIKSJ+lxwwQW64IILalxuGIbuu+8+3XfffQ3y+AAAAAAAAEBljuiogC8bBeqjdle+rWT79u2SpKuvvtoa2EpSVFSUrr76aknSjh076p8dAAAAAAAAAESYoIa2iYmJkqSvv/66yjJfzLcOAAAAAAAAAKD2gro8Qu/evfXf//5XDzzwgH766Sf17t1bkrR8+XK9/fbbMgzDigEAAAAAAAAAai+ooe2YMWP0wQcfyOv16q233tJbb71lLTNNUw6HQ7fffnvIkgQAAAAAAACASBHU5RHOPPNMPfPMM4qOjpZpmgH/RUdH65lnnlG/fv1CnSsAAAAAAAAANHtBnWkrSbfccosuvPBC/fvf/9b69eslSZ06ddIll1yitm3bhixBAAAAAAAAAIgkQQ9tJalt27YaPXp0iFIBAAAAAAAAANR6aHvCCSfIMAzNmDFDxx13nCTpvvvukyRde+21nF0LAAAAAEAzYpqm3G53uNNoNlwulwzDCHcaAJqIWg9t16xZI8MwVFhYaMUmTpwowzDUv39/hrYAAAAAADQjbrdbQ4cODXcazcbcuXMVGxsb7jQANBH1ujwCAAAAAABo3lbs+j3cKTR5vVI50Q1A3TC0BQAAAAAAB9Vz3M1yRDNCqCtvWblWTp4W7jQANEG84gIAAAAAgINyREfJ6YoJdxoAEDHqPLR96aWX9MknnxwyJkn33ntv8JkBAAAAAAAAQASq89B2xowZ1m3ftx76x/wxtAUAAAAAAACAuqnT0NY0zVqv6xvoAgAAAAAAAABqr9ZD2xEjRjRkHgAAAAAAAAAA1WFoW9MlEAAAAAAAAAAAoeMIdwIAAAAAAAAAgANqNbR944035PF46rxxj8ejN954o873AwAAAAAAAIBIVauh7fDhw9WhQweNGzdOq1evPuT633zzjcaPH68OHTroyiuvrHeSAAAAAAAAABApanVN25iYGP3++++aMmWKpkyZopSUFB1//PE68sgjlZycLNM0lZeXp40bN+qbb75RXl6eJMk0TcXGxjZoAQAAAAAAAADQnNRqaPvzzz/r/vvv18yZM1VaWqpdu3Zp4cKFWrhwYZV1TdOUJLlcLl1zzTW65557QpsxAAAAAAAAADRjtbo8Qps2bTR9+nRt27ZNTz/9tPr166f4+HiZphnwX3x8vPr166dnnnlG27Zt0/PPP682bdo0dA0AAAAAAAAA0GzU6kxbn5SUFI0aNUqjRo2Sx+PR5s2blZubK0lKS0tTu3bt5HQ6GyRRAAAAAAAAAIgEdRra+nM6nerQoYM6dOgQynwAAAAAAAAAIKLV6vIIAAAAAAAAAIDGwdAWAAAAAAAAAGyEoS0AAAAAAAAA2AhDWwAAAAAAAACwEYa2AAAAAAAAAGAjUXW9w759+/TYY49Jkv70pz+pX79+IU8KAAAAAAAAACJVnYe28fHxevDBB1VWVqb58+c3QEoAAAAAAAAAELmCujxC586dJUllZWUhTQYAAAAAAAAAIl1QQ9sJEyZIkh599FHl5+eHNCEAAAAAAAAAiGR1vjyCJL377rs6/PDDtWzZMrVr106nnHKKMjIyZBiGtY5hGHrxxRdDligAAAAAAAAARIKghrazZs2SYRgyDEN79+7VRx99VO16DG0BAAAAAAAAoG6CGtpKkmma1d728T/rFgAAAAAAAABQO0ENbRcvXhzqPAAAAAAAAHAQpmnK7XaHO41mweVyccIhbC2ooe3pp58e6jwAAAAAAABwEG63W0OHDg13Gs3C3LlzFRsbG+40gBoFfXkESdq6daveeustrV+/XpLUqVMnDRkyRG3atAlJcofy0EMP6e6779bf/vY3TZ06VZJUUlKi22+/XbNnz5bb7daAAQP0/PPPKyMjo1FyAgAAAAAAaEgrdv0e7hSatF6pbcOdAnBIQQ9t//nPf2r06NEqLS0NiN9111166qmndOONN9Y7uYNZsWKF/vnPf+q4444LiN922216//33NXfuXCUlJWnUqFH685//rC+//LJB8wEAAAAAAGgsPcfdLEd0vc7FizjesnKtnDwt3GkAtRLUs3vRokW65ZZbJFX9EjK3261bbrlFRx11lPr161f/DKtRWFio4cOH61//+pcmT55sxfPz8/Xiiy/q9ddf15lnnilJmjFjhrp06aKvv/5aJ598coPkAwAAAAAA0Jgc0VFyumLCnQaABuII5k6PP/64TNOUYRgaMmSIHn74YT3yyCMaMmSIHA6HTNPUY489FupcLSNHjtT555+v/v37B8RXrVqlsrKygHjnzp3Vrl07LV26tMHyAQAAAAAAAIBQCepM22XLlskwDI0bN04TJ04MWDZx4kTdd999WrZsWSjyq2L27NlavXq1VqxYUWVZTk6OYmJi1LJly4B4RkaGcnJyatym2+0O+PbFgoICSZLX65XX65UkGYYhwzBkmmbA2cWHivvuH2zcNwSvfEZzXeI15ei7bRiGDFMy9i8yJck48LO1fqjiRsXCyt/RGMp4g+VeKW6YksOo+NuHaZr16p//t1Y6DEdgTxqxJiveRPvkf9v/OSwF/3wyDCOgJ3bY9/wf0+59ku/5sv81rvLral2fN16vN6AnvscI97530Ljd+qT9rzN+PanP+5N/T3wPYod9r6n1yb8nvteeYI8jfD3xPUhD1tpc++TfE9/rUX2O9/xvG5V6Eu59r0HiDVCTf0+kmvtR2z751qly3NWINVWON7U+GaYC+hGwnwfx+cn3/4DjrkauqTZxO/eppmPhYD/PVj4Wltn4NQUbt0uffCofC9fls7t/POC4a/8qdtj3go03dp98atOPmuKV++R/LC3ZZ99rMn1S1c8mDTkLs8N8r/KymgQ1tN27d68kVXu5AV/Mt04obdmyRX/729+0YMGCkH7D35QpUzRp0qQq8Z07d6qkpESSFBcXp6SkJBUUFKi4uNhap0WLFkpISFBeXl7A9X0TExMVHx+v3bt3q7y83IonJyfL5XJp586dATtBamqqnE6nduzYEZBDenq6PB6Pdu3aZcUMw1BGRoZKS0uVl5dnxaOiopSWlqbi4mJr8CxJMTExSklJUWFhoYqKiqy4w1Hx4bpNWrraeqLlKHNKkgqcXhU4TaV5HHJ5Dzxd86K8KjJMZZQ7FeX3/NgZ5ZXbMJVV7gx4AuZEe+QxpTb7t+uzNdojp6RMv7hpVMRdpqFW5QdOAC83KrbTwjSU7Bd3O0ztjPIq0Wso0XMgXuQwlRflVUuPQy38cm+omryeaBV3PFJGfrE8Hk9A/4LpU3x8vJKSktS1ZbzVk8auqan3yeuJ1pqYGBmGodzcXMXEHPjnQsE8n0pKSpSdna2SpDi19USrzOOwxb7XlPq0ff/bfps2bQJ6EuzrXm5urtWTDG+Udkq22PekptOnAklHtm2n7LQsqyf1eX8qLS1Vdna2ihJdkmSbfa9J9ckbpa4dj1R2Yppyc3OVlpZWr+MIX09W7tqqaElZNtn3mlKf4va/x2cnpmnfvn2Ki4ur1/FeaWmpoqOj5TAcAcddjVlTU++T77gr2VHxOaC+x+Xx8fGSpC4dOgb0JNz7XlPqk9cTrR2t20huad++fcrPz7fWD+bzk8PhUGZmprruP+5ylDltse81pT65vVHW79n/uKumz4SH6lN+fn7AsXC+adhi35OaTp82SzosLl7Z2dlWT+r62d2/T/49STIdKpRsse81lT5tNiVXTExAP+o7Y/Edd20zKl7T7LLvNZU+eU0FHAfHxMQ06CzMDvO92s5MgxraZmRkaOvWrZo5c6bOPvtsOZ37B1her2bOnGmtE2qrVq3Sjh07dMIJJ1gxj8ejJUuW6Nlnn9VHH32k0tJS7dmzJ+Bs2+3btyszM7PG7d59990aM2aM9XNBQYGys7PVqlUrJSYmSjrwl9/ExEQlJCRY6/riycnJ1f6lOCUlJeCxfPFWrVpViRuGofT09IC4w+GoNi7J2pEri4uLCxhq+x7zsMMOU4sWLay47+zirbk79LuzTM7oivV8VeQ6vZLfa4Evvj3KE/B4vvi26uL7XygC4oZUblaNS5LbMKuNFxmm9lUTL3CY2uuoGt/j9GpPNbmHuiaPt0w//LJRJ6Zkyel01rtPbrdb+fn5+mH3NsX59aQxa7LiTbRPHm+Z3KWlMk1TaWlpAb/jYJ5PsbGx2rJli37YtbWiJ06j0Wuy4k20T+XuiiVbt24N6Emwr3tpaWkHeuIol0Mxttj3rHgT6dPG3zerZbHH6kl93p9KSkq0ZcsWrd21VT3DWFOT7pOjXD/8slGxqcVKS0tTXFycpOCPI3w98Zpelcle+15T6dMuZ5nVE99wrz7HeyUlJSorK5PX9AYcdzVmTU29T77jrtjUNpLqf1zuOxZeu+kXHVb5WNhurxE27ZPHW6Zf/9iqtJQ2io+Pl8vlstYL5vOT2+1WTk7OgeOuaMMW+15ldu6Tx1sxUCgqKqpy3CVV/Ux4qD4lJSUFHAs7jJhGr8mnyfapVCos3qctW7ZU+XxS28/u/n2Kjo62ehJreOUMR01qwn0qldylpdX2I9gZi++4a+uuHcoKR01NvE+moYDj4NjY2AadhdlhvlfbE1GDGtqeddZZmjVrlubOnavPP//cGqJ+8803+uOPP2QYRpXrzYbCWWedpe+//z4gds0116hz58666667lJ2drejoaC1cuFBDhgyRJK1bt06bN29Wnz59atyuy+UKOMDwcTgc1tmoPv6nvNcmXvn+wcTr+pi1jQf80zJj/6nwfir/HNK4ceBJ2xDxBs3dL24aktc88E+OQtE/qWKblXvSWDUFJtn0+uR/OxTPYeufIVXuSZj3vcAkbd4n3/PFNKvtSV2fN9ZlEvb35GC506ea417TW21Pgnl/8u9JMLnTpwPvJ76e+Pb/YI8jfD2xcmnAWptrn/x74v/PtoM93vO/Xd1xl91eI+zYJ/+eSPU/LvetU91xl2S/14gGi9cjd9NQQD9CcSxc7XFXTbnXFI/gPjX0sbB1XGfD14h65RKqeE05qvpj4WD6EXDcFcp+1BRvjn1S6Prh3xPrckp22veaSJ+q+2zSULOwYOOhnO/VdJ/Kghrajhs3Tm+//bYKCwuVk5Oj//73v9Yy0zSVmJioe+65J5hNH1RCQoK6du0aEGvRooVSU1Ot+HXXXacxY8YoJSVFiYmJ+utf/6o+ffpUeykHAAAAAAAAALCb2o12KzniiCO0YMECde7c2fprgu+/Ll26aMGCBTriiCNCnWutPPnkk7rgggs0ZMgQnXbaacrMzNTbb78dllwAAAAAAAAAoK6COtNWkk466ST9+OOPWrNmjdavXy9J6tSpk3r06BGq3Grl008/Dfg5NjZWzz33nJ577rlGzQMAAAAAAAAAQqHOQ9t9+/bpggsukCRdf/31+n//7/81+qAWAAAAAAAAAJqrOl8eIT4+XitWrNBnn31W7be1AQAAAAAAAACCF9Q1bX1f6rV58+aQJgMAAAAAAAAAkS6ooe2TTz6plJQU3XPPPVq0aFGocwIAAAAAAACAiBXUF5FdeOGF8ng82rVrl84++2zFxsYqPT1dhmFY6xiGoZ9//jlkiQIAAAAAAABAJAhqaPvrr7/KMAxrSFtcXBxwqQTTNAMGuAAAAAAAAACA2glqaCtVDGYP9jMAAAAAAAAAoO6CGtp6vd5Q5wEAAAAAAAAAUBBD23379umxxx6TJP3pT39Sv379Qp4UAAAAAAAAAESqOg9t4+Pj9eCDD6qsrEzz589vgJQAAAAAAAAAIHI5grlT586dJUllZWUhTQYAAAAAAAAAIl1QQ9sJEyZIkh599FHl5+eHNCEAAAAAAAAAiGRBfRHZu+++q8MPP1zLli1Tu3btdMoppygjI0OGYVjrGIahF198MWSJAgAAAAAAAEAkCGpoO2vWLBmGIcMwtHfvXn300UfVrsfQFgAAAAAAAADqJqihrSSZplntbR//s24BAAAAAAAAALUT1NB28eLFoc4DAAAAAAAAAKAgh7ann356qPMAAAAAAAAAAKgel0eoSVlZmf744w9JUrt27UK9eQAAAAAAAABo1hy1XTE5OVmpqalavny5Fbv22mt17bXX6ueff7Ziy5cv1+GHH66OHTuGNlMAAAAAAAAAiAC1Htrm5+drz549Ki8vt2IzZ87UrFmztH379irrV/flZAAAAAAAAACAg6v10BYAAAAAAAAA0PAY2gIAAAAAAACAjTC0BQAAAAAAAAAbiarrHR588EGlp6fXGNuxY0doMgMAAAAAAACACFTnoe0HH3xg3TYMo0oMAAAAAAAAABC8Og1tTdNsqDwAAAAAAAAAAKrD0HbChAkNmQcAAAAAAAAAQAxtAQAAAAAAAMBWHOFOAAAAAAAAAABwAENbAAAAAAAAALARhrYAAAAAAAAAYCMMbQEAAAAAAADARhjaAgAAAAAAAICNMLQFAAAAAAAAABthaAsAAAAAAAAANsLQFgAAAAAAAABshKEtAAAAAAAAANgIQ1sAAAAAAAAAsBGGtgAAAAAAAABgIwxtAQAAAAAAAMBGmtTQdsqUKerVq5cSEhKUnp6uwYMHa926dQHrlJSUaOTIkUpNTdVhhx2mIUOGaPv27WHKGAAAAAAAAADqpkkNbT/77DONHDlSX3/9tRYsWKCysjKdc845Kioqsta57bbb9J///Edz587VZ599pm3btunPf/5zGLMGAAAAAAAAgNqLCncCdfHhhx8G/Dxz5kylp6dr1apVOu2005Sfn68XX3xRr7/+us4880xJ0owZM9SlSxd9/fXXOvnkk8ORNgAAAAAAAADUWpMa2laWn58vSUpJSZEkrVq1SmVlZerfv7+1TufOndWuXTstXbq0xqGt2+2W2+22fi4oKJAkeb1eeb1eSZJhGDIMQ6ZpyjRNa91DxX33DzbucDiqbLuu8Zpy9N02DEOGKRn7F5mSZBz42Vo/VHGjYqGhhos3WO6V4oYpOYyKE9ZN06xX/wzjQCUOwxHYk0asyYo30T753/Z/DkvBP58MwwjoiR32Pf/HtHuf5Hu+7H+Nq/y6WtfnjdfrDeiJ7zHCve8dNG63Pmn/64xfT+rz/uTfE9+D2GHfa2p98u+J77Un2OMIX098D9KQtTbXPvn3xPd6VJ/jPf/bRqWehHvfa5B4A9Tk3xOp5n7Utk++daocdzViTZXjTa1PhqmAfgQAYnyiAAAiUUlEQVTs50F8fvL9P+C4q5Frqk3czn2q6Vg42M+zlY+FZTZ+TcHG7dInn8rHwnX57O4fDzju2r+KHfa9YOON3Sef2vSjpnjlPvkfS0v22feaTJ9U9bNJQ87C7DDfq7ysJk12aOv1ejV69Gidcsop6tq1qyQpJydHMTExatmyZcC6GRkZysnJqXFbU6ZM0aRJk6rEd+7cqZKSEklSXFyckpKSVFBQoOLiYmudFi1aKCEhQXl5eSotLbXiiYmJio+P1+7du1VeXm7Fk5OT5XK5tHPnzoCdIDU1VU6nUzt27AjIIT09XR6PR7t27bJihmEoIyNDpaWlysvLs+JRUVFKS0tTcXGxNXiWpJiYGKWkpKiwsDDgUhIOR8WH6zZp6WrriZajzClJKnB6VeA0leZxyOU98HTNi/KqyDCVUe5UlN/zY2eUV27DVFa5M+AJmBPtkceU2uzfrs/WaI+ckjL94qZREXeZhlqVH7hqR7lRsZ0WpqFkv7jbYWpnlFeJXkOJngPxIoepvCivWnocauGXe0PV5PVEq7jjkTLyi+XxeAL6F0yf4uPjlZSUpK4t462eNHZNTb1PXk+01sTEyDAM5ebmKiYmxlo/mOdTSUmJsrOzVZIUp7aeaJV5HLbY95pSn7bvf9tv06ZNQE+Cfd3Lzc21epLhjdJOyRb7ntR0+lQg6ci27ZSdlmX1pD7vT6WlpcrOzlZRokuSbLPvNak+eaPUteORyk5MU25urtLS0up1HOHrycpdWxUtKcsm+15T6lPc/vf47MQ07du3T3FxcfU63istLVV0dLQchiPguKsxa2rqffIddyU7YitqqOdxeXx8vCSpS4eOAT0J977XlPrk9URrR+s2klvat2+fdVKNFNznJ4fDoczMTHXdf9zlKHPaYt9rSn1ye6Os37P/cVdNnwkP1af8/PyAY+F807DFvic1nT5tlnRYXLyys7OtntT1s7t/n/x7kmQ6VCjZYt9rKn3abEqumJiAftR3xuI77tpmVLym2WXfayp98poKOA6OiYlp0FmYHeZ7e/fuVW002aHtyJEj9cMPP+iLL76o97buvvtujRkzxvq5oKBA2dnZatWqlRITEyUd+MtvYmKiEhISrHV98eTk5Gr/Uuw7C7hyvFWrVlXihmEoPT09IO5wOKqNS7J25Mri4uIUGxtb5TEPO+wwtWjRwor7zi7emrtDvzvL5IyuWM9XRa7TK/m9Fvji26M8AY/ni2+rLr7/hSIgbkjlZtW4JLkNs9p4kWFqXzXxAoepvY6q8T1Or/ZUk3uoa/J4y/TDLxt1YkqWnE5nvfvkdruVn5+vH3ZvU5xfTxqzJiveRPvk8ZbJXVoq0zSVlpYW8DsO5vkUGxurLVu26IddWyt64jQavSYr3kT7VO6uWLJ169aAngT7upeWlnagJ45yORRji33PijeRPm38fbNaFnusntTn/amkpERbtmzR2l1b1TOMNTXpPjnK9cMvGxWbWqy0tDTFxcVJCv44wtcTr+lVmey17zWVPu1yllk98Q336nO8V1JSorKyMnlNb8BxV2PW1NT75Dvuik1tI6n+x+W+Y+G1m37RYZWPhe32GmHTPnm8Zfr1j61KS2mj+Ph4uVwua71gPj+53W7l5OQcOO6KNmyx71Vm5z55vBUDhaKioirHXVLVz4SH6lNSUlLAsbDDiGn0mnyabJ9KpcLifdqyZUuVzye1/ezu36fo6GirJ7GGV85w1KQm3KdSyV1aWm0/gp2x+I67tu7aoaxw1NTE+2QaCjgOjo2NbdBZmB3me/55HkyTHNqOGjVK7733npYsWaK2bdta8czMTJWWlmrPnj0BZ9tu375dmZmZNW7P5XIFHGD4OBwO62xUH/9T3msTr3z/YOJ1fczaxgP+aZmx/1R4P5V/DmncOPCkbYh4g+buFzcNyWse+CdHoeifVLHNyj1prJoCk2x6ffK/HYrnsPXPkCr3JMz7XmCSNu+T7/limtX2pK7PG+syCft7crDc6VPNca/prbYnwbw/+fckmNzp04H3E19PfPt/sMcRvp5YuTRgrc21T/498f9n28Ee7/nfru64y26vEXbsk39PpPofl/vWqe64S7Lfa0SDxeuRu2kooB+hOBau9rirptxrikdwnxr6WNg6rrPha0S9cglVvKYcVf2xcDD9CDjuCmU/aoo3xz4pdP3w74l1OSU77XtNpE/VfTZpqFlYsPFQzvdquk+VbdRqLZswTVOjRo3SvHnztGjRInXo0CFg+Yknnqjo6GgtXLjQiq1bt06bN29Wnz59GjtdAAAAAAAAAKizJnWm7ciRI/X666/rnXfeUUJCgnWd2qSkJOuaFNddd53GjBmjlJQUJSYm6q9//av69OlT45eQAQAAAAAAAICdNKmh7bRp0yRJZ5xxRkB8xowZuvrqqyVJTz75pBwOh4YMGSK3260BAwbo+eefb+RMAQAAAAAAACA4TWpo638h4JrExsbqueee03PPPdcIGQEAAAAAAABAaDWpa9oCAAAAAAAAQHPH0BYAAAAAAAAAbIShLQAAAAAAAADYCENbAAAAAAAAALARhrYAAAAAAAAAYCMMbQEAAAAAAADARhjaAgAAAAAAAICNMLQFAAAAAAAAABthaAsAAAAAAAAANsLQFgAAAAAAAABshKEtAAAAAAAAANgIQ1sAAAAAAAAAsBGGtgAAAAAAAABgIwxtAQAAAAAAAMBGGNoCAAAAAAAAgI0wtAUAAAAAAAAAG2FoCwAAAAAAAAA2wtAWAAAAAAAAAGyEoS0AAAAAAAAA2AhDWwAAAAAAAACwEYa2AAAAAAAAAGAjDG0BAAAAAAAAwEYY2gIAAAAAAACAjTC0BQAAAAAAAAAbYWgLAAAAAAAAADbC0BYAAAAAAAAAbIShLQAAAAAAAADYCENbAAAAAAAAALARhrYAAAAAAAAAYCMMbQEAAAAAAADARhjaAgAAAAAAAICNMLQFAAAAAAAAABthaAsAAAAAAAAANsLQFgAAAAAAAABshKEtAAAAAAAAANgIQ1sAAAAAAAAAsBGGtgAAAAAAAABgIwxtAQAAAAAAAMBGGNoCAAAAAAAAgI0026Htc889p8MPP1yxsbHq3bu3li9fHu6UAAAAAAAAAOCQmuXQds6cORozZowmTJig1atXq3v37howYIB27NgR7tQAAAAAAAAA4KCa5dD2iSee0A033KBrrrlGxxxzjKZPn674+Hi99NJL4U4NAAAAAAAAAA4qKtwJhFppaalWrVqlu+++24o5HA71799fS5cuDWNm9uYtKw93Ck1SQ/7e6Elw6In90BP7oSf2Q0/sh57YDz2xH3piP/TEfuiJvTT074ye1B2/s5o1u6Ftbm6uPB6PMjIyAuIZGRn63//+V+193G633G639XN+fr4k6fPPP1eLFi0kSYZhyDAMmaYp0zStdQ8V93q9AY9V17jD4aiy7brGa8qxrKxMu3btUmlBoZbe+ZgVr1jHlAxDhowqccMIPEHbNL37H6ch4xU1WDGZkmnWHK8h94aqaZd26fPPP1d0dHRAvK598vWkrKDI6km4amrqfdqlXVqyZIliYmKseDDPJ7fbHdATu+17TalPlXsS7OtelZ7YbN8LXbzha/LvSX3en0pLS62efHXHI2Gtqfa/X3v2ydcTl8tVr+MIX09K8/fqqzsesd2+V/tcwt8n33u8y+Wq1/Gef0/8j7vCUVPFNppun3Zpl7744gtFR0fX67i8uuOucNXU1PtU3bFwMJ+fqj0WttG+15T6VNNxV10/z1Y97rLXvteU+lS5J3X57O4f9+/JV3c8GtaamnKfatOPmuKV+2S9xxcUVhwL22zfayp98u9JQ87C7DDfKyoq8vt91cwwD7VGE7Nt2za1adNGX331lfr06WPF77zzTn322WdatmxZlftMnDhRkyZNasw0AQAAAAAAAESoLVu2qG3btjUub3Zn2qalpcnpdGr79u0B8e3btyszM7Pa+9x9990aM2aM9bPX69Xu3buVmpoa8BcGhEdBQYGys7O1ZcsWJSYmhjsdiJ7YDf2wH3piP/TEfuiJ/dAT+6En9kNP7Iee2A89sR96Yi+maWrv3r3Kyso66HrNbmgbExOjE088UQsXLtTgwYMlVQxhFy5cqFGjRlV7H5fLJZfLFRBr2bJlA2eKukpMTOTFxWboib3QD/uhJ/ZDT+yHntgPPbEfemI/9MR+6In90BP7oSf2kZSUdMh1mt3QVpLGjBmjESNGqGfPnjrppJM0depUFRUV6Zprrgl3agAAAAAAAABwUM1yaHvZZZdp586duvfee5WTk6MePXroww8/rPLlZAAAAAAAAABgN81yaCtJo0aNqvFyCGhaXC6XJkyYUOUSFggfemIv9MN+6In90BP7oSf2Q0/sh57YDz2xH3piP/TEfuhJ02SYpmmGOwkAAAAAAAAAQAVHuBMAAAAAAAAAABzA0BYAAAAAAAAAbIShLQAAAAAAAADYCENb2NaSJUs0aNAgZWVlyTAMzZ8/P9wpRbQpU6aoV69eSkhIUHp6ugYPHqx169aFO62INm3aNB133HFKTExUYmKi+vTpow8++CDcacHPQw89JMMwNHr06HCnErEmTpwowzAC/uvcuXO404p4W7du1RVXXKHU1FTFxcWpW7duWrlyZbjTiliHH354leeJYRgaOXJkuFOLWB6PR+PHj1eHDh0UFxenI444Qvfff7/4OpLw2rt3r0aPHq327dsrLi5Offv21YoVK8KdVsQ41OdD0zR17733qnXr1oqLi1P//v21YcOG8CQbIQ7Vk7ffflvnnHOOUlNTZRiG1qxZE5Y8I8nBelJWVqa77rpL3bp1U4sWLZSVlaWrrrpK27ZtC1/COCiGtrCtoqIide/eXc8991y4U4Gkzz77TCNHjtTXX3+tBQsWqKysTOecc46KiorCnVrEatu2rR566CGtWrVKK1eu1JlnnqmLLrpIP/74Y7hTg6QVK1bon//8p4477rhwpxLxjj32WP3xxx/Wf1988UW4U4poeXl5OuWUUxQdHa0PPvhAP/30kx5//HElJyeHO7WItWLFioDnyIIFCyRJQ4cODXNmkevhhx/WtGnT9Oyzz2rt2rV6+OGH9cgjj+iZZ54Jd2oR7frrr9eCBQv0yiuv6Pvvv9c555yj/v37a+vWreFOLSIc6vPhI488oqefflrTp0/XsmXL1KJFCw0YMEAlJSWNnGnkOFRPioqKdOqpp+rhhx9u5Mwi18F6sm/fPq1evVrjx4/X6tWr9fbbb2vdunW68MILw5ApasMw+XMtmgDDMDRv3jwNHjw43Klgv507dyo9PV2fffaZTjvttHCng/1SUlL06KOP6rrrrgt3KhGtsLBQJ5xwgp5//nlNnjxZPXr00NSpU8OdVkSaOHGi5s+fz5kdNjJ27Fh9+eWX+vzzz8OdCmowevRovffee9qwYYMMwwh3OhHpggsuUEZGhl588UUrNmTIEMXFxenVV18NY2aRq7i4WAkJCXrnnXd0/vnnW/ETTzxRAwcO1OTJk8OYXeSp/PnQNE1lZWXp9ttv19///ndJUn5+vjIyMjRz5kwNGzYsjNlGhoN9Zv/111/VoUMHffPNN+rRo0ej5xapajNHWbFihU466ST99ttvateuXeMlh1rhTFsAQcnPz5dUMSRE+Hk8Hs2ePVtFRUXq06dPuNOJeCNHjtT555+v/v37hzsVSNqwYYOysrLUsWNHDR8+XJs3bw53ShHt3XffVc+ePTV06FClp6fr+OOP17/+9a9wp4X9SktL9eqrr+raa69lYBtGffv21cKFC7V+/XpJ0rfffqsvvvhCAwcODHNmkau8vFwej0exsbEB8bi4OP4Fhw1s2rRJOTk5AcdeSUlJ6t27t5YuXRrGzAB7y8/Pl2EYatmyZbhTQTWiwp0AgKbH6/Vq9OjROuWUU9S1a9dwpxPRvv/+e/Xp00clJSU67LDDNG/ePB1zzDHhTiuizZ49W6tXr+YadzbRu3dvzZw5U0cffbT++OMPTZo0SX/605/0ww8/KCEhIdzpRaRffvlF06ZN05gxY/SPf/xDK1as0K233qqYmBiNGDEi3OlFvPnz52vPnj26+uqrw51KRBs7dqwKCgrUuXNnOZ1OeTwePfDAAxo+fHi4U4tYCQkJ6tOnj+6//3516dJFGRkZeuONN7R06VIdeeSR4U4v4uXk5EiSMjIyAuIZGRnWMgCBSkpKdNddd+nyyy9XYmJiuNNBNRjaAqizkSNH6ocffuCsAhs4+uijtWbNGuXn5+vf//63RowYoc8++4zBbZhs2bJFf/vb37RgwYIqZ+IgPPzPSjvuuOPUu3dvtW/fXm+++SaXEQkTr9ernj176sEHH5QkHX/88frhhx80ffp0hrY28OKLL2rgwIHKysoKdyoR7c0339Rrr72m119/Xccee6zWrFmj0aNHKysri+dJGL3yyiu69tpr1aZNGzmdTp1wwgm6/PLLtWrVqnCnBgB1UlZWpksvvVSmaWratGnhTgc14PIIAOpk1KhReu+997R48WK1bds23OlEvJiYGB155JE68cQTNWXKFHXv3l1PPfVUuNOKWKtWrdKOHTt0wgknKCoqSlFRUfrss8/09NNPKyoqSh6PJ9wpRryWLVuqU6dO2rhxY7hTiVitW7eu8oelLl26cNkKG/jtt9/0ySef6Prrrw93KhHvjjvu0NixYzVs2DB169ZNV155pW677TZNmTIl3KlFtCOOOEKfffaZCgsLtWXLFi1fvlxlZWXq2LFjuFOLeJmZmZKk7du3B8S3b99uLQNQwTew/e2337RgwQLOsrUxhrYAasU0TY0aNUrz5s3TokWL1KFDh3CnhGp4vV653e5wpxGxzjrrLH3//fdas2aN9V/Pnj01fPhwrVmzRk6nM9wpRrzCwkL9/PPPat26dbhTiVinnHKK1q1bFxBbv3692rdvH6aM4DNjxgylp6cHfMkSwmPfvn1yOAI/qjmdTnm93jBlBH8tWrRQ69atlZeXp48++kgXXXRRuFOKeB06dFBmZqYWLlxoxQoKCrRs2TK+7wHw4xvYbtiwQZ988olSU1PDnRIOgssjwLYKCwsDzoTatGmT1qxZo5SUFL7VMAxGjhyp119/Xe+8844SEhKsa0MlJSUpLi4uzNlFprvvvlsDBw5Uu3bttHfvXr3++uv69NNP9dFHH4U7tYiVkJBQ5TrPLVq0UGpqKtd/DpO///3vGjRokNq3b69t27ZpwoQJcjqduvzyy8OdWsS67bbb1LdvXz344IO69NJLtXz5cr3wwgt64YUXwp1aRPN6vZoxY4ZGjBihqCg+IoTboEGD9MADD6hdu3Y69thj9c033+iJJ57QtddeG+7UItpHH30k0zR19NFHa+PGjbrjjjvUuXNnXXPNNeFOLSIc6vPh6NGjNXnyZB111FHq0KGDxo8fr6ysLA0ePDh8STdzh+rJ7t27tXnzZm3btk2SrD/aZmZmcgZ0AzlYT1q3bq1LLrlEq1ev1nvvvSePx2N9rk9JSVFMTEy40kZNTMCmFi9ebEqq8t+IESPCnVpEqq4XkswZM2aEO7WIde2115rt27c3Y2JizFatWplnnXWW+fHHH4c7LVRy+umnm3/729/CnUbEuuyyy8zWrVubMTExZps2bczLLrvM3LhxY7jTinj/+c9/zK5du5oul8vs3Lmz+cILL4Q7pYj30UcfmZLMdevWhTsVmKZZUFBg/u1vfzPbtWtnxsbGmh07djTvuece0+12hzu1iDZnzhyzY8eOZkxMjJmZmWmOHDnS3LNnT7jTihiH+nzo9XrN8ePHmxkZGabL5TLPOussXtMa2KF6MmPGjGqXT5gwIax5N2cH68mmTZtq/Fy/ePHicKeOahimaZoNORQGAAAAAAAAANQe17QFAAAAAAAAABthaAsAAAAAAAAANsLQFgAAAAAAAABshKEtAAAAAAAAANgIQ1sAAAAAAAAAsBGGtgAAAAAAAABgIwxtAQAAAAAAAMBGGNoCAAAAAAAAgI0wtAUAAEBE+/XXX2UYhgzD0BlnnNFojztx4kTrcWfOnNloj1sXvvwOP/zwcKcCAAAQURjaAgAAoMH83//9nzX4+8tf/hKwbOrUqdayk08+OWDZJ598Yi274IILGjPleps9e7aVu2EYOvfcc8OdEgAAAJoYhrYAAABoMH369LFuL126NGCZ/8/ffPON3G53tcsqD3Tt7o033gj4eeHChcrNzQ1TNgAAAGiKGNoCAACgwXTp0kWJiYmSpB9++EF79+61ln399dfW7dLSUn3zzTfWz011aLtnzx59+OGHAbHy8nL9+9//DlNGAAAAaIoY2gIAAKDBOBwO9e7dW5Lk9Xq1fPlySdIff/yhzZs3S5KOOeYYSQeGuKZpatmyZdb9TzrpJGt73333nS6//HK1bt1aMTExatOmja6//nr9/vvvVR67sLBQEydOVNeuXRUXF6fExESdccYZ+uCDD2qV+yuvvCKHwyHDMNShQwdt2bLlkPd5++23VVpaKkkaNmyYFZ89e/Yh7/v888/rqKOOksvlUvfu3bVo0aIq62zatEk33HCD2rdvL5fLpfT0dF122WVau3ZtwHpbt27Vtddeq+7duystLU3R0dFKSUnRmWeeqfnz51fZbm5urq666iolJSWpZcuWuuqqqzg7GAAAIIwY2gIAAKBBVXeJBN//jzrqKJ1//vkBsfXr12v37t2SAs/U/eCDD3TSSSdp9uzZysnJUVlZmbZt26YXX3xRvXr10qZNm6zHyc/PV9++fTVp0iT9+OOPKikp0d69e/XZZ5/pvPPO0/PPP3/QnP/73//q2muvlWmaatu2rRYtWqTs7OxD1up/aYS7775bPXr0kCR9/vnn2rZtW433e+SRRzRy5Eht3LhRpaWl+u677zR48GDl5eVZ66xevVonnHCC/u///k+bN29WaWmpdu7cqTfffFMnnXSSNRCXpC1btmjGjBn67rvvtGvXLpWXlysvL0+LFy/WxRdfrJdfftlat7S0VOecc45eeeUVFRQUKD8/X6+88orOOuusQ9YLAACAhsHQFgAAAA3K//IGvsGs76zak08+WX379g2IVXdphH379mnEiBFyu92KiorSAw88oI8//lh33nmnJCknJ0e33HKLdb977rlH33//vSTpvPPO0/vvv6+XX35ZmZmZkqTbbrutxjNnly5dqqFDh6q8vFyZmZlatGiROnTocMg6t2/frsWLF0uqGEYfd9xxuuSSSyRVnGU8Z86cGu+7du1a3XXXXXr33XfVvXt3SdLevXv1+uuvS6o4+3jEiBHas2ePJOn222/Xxx9/rIcfflhOp1OFhYW65pprZJqmJCkzM1MPPfSQ3nrrLX3yySdavHixZs2apVatWkmSJk+ebD32jBkzrEtTpKam6qWXXtLcuXNVWFh4yJoBAADQMBjaAgAAoEGdfPLJMgxDUsVg1jRNa0Dbp08f60zczZs3648//qh2aPvxxx9r586dkqSzzz5bp512muLi4jRo0CAdfvjhkqSPPvpIubm58nq91rAzJiZGY8aMUWJiojp06KA///nPkirOLn3zzTer5LplyxZdcMEF2rdvn9LS0vTJJ5/oqKOOqlWdc+fOlcfjkSRrWOv7v3TwSyRcdNFFeuihhzRo0CDdfffdVnzjxo2SpG+//VY//PCDJKlHjx4aPHiw4uLi1LdvX+vyET/99JNWr14tSTr88MOVmZmpqVOn6pJLLtGZZ56pESNGWL/DDRs2qKCgQJL0zjvvWI9333336ZprrtEll1yif/7zn7WqGwAAAKEXFe4EAAAA0LwlJyerU6dOWrdunXbv3q0ff/xRq1atklQxlM3IyFCHDh20adMmff311wFfUOYb2q5fv96KffDBB9Vel9Y0Tf3vf/9Tp06drMsKlJaWqn///tXmVfk6sJL0yy+/WLdfe+01HXvssbWu0//SCL5h7dFHH61u3brp+++/1/Lly/XLL7+oY8eOVe57+umnW7dTU1Ot274za/3rX7Nmjf70pz9Vm8PatWt14okn6sknn9SYMWMOmu+ePXuUmJgYUHOvXr2s2/7XEgYAAEDj4kxbAAAANDj/69pOnz5d+/btU3x8vI477riA5R9//LF1RmliYqL1JWW1VVRUVK91nU6ndXvcuHG13t7mzZsDzhA+8cQTZRiGDMOwLtMg1Xy2bXJysnU7KurAeRW+yx3Uli/fZ555xordeeedWrhwoT7//HN169bNinu93oNuy3d2NAAAABofQ1sAAAA0OP+h7cyZMyVVnNXpG5L6lr/yyivWMLFXr15yOCoOVzt16mTdf8SIETJNs8p/RUVFGjBggNLS0qwh6GGHHaa9e/dWWdfj8WjGjBlV8jzllFM0ZMgQSdKKFSt02WWXWZc8OJjZs2fXasB6sEskHIx//aeffnqN9d90002SpK1bt0qqOGv34Ycf1plnnqnjjz/eivvzP/N35cqV1u1ly5YFlSsAAADqj8sjAAAAoMH5fxmZ72xQ/5hvaOt/Zqv/8rPPPlutWrXSzp079fLLLyslJUVnn322PB6Pfv31V3355Zf69ttv9dNPP8nhcOjyyy/X888/r8LCQp1zzjm69dZblZaWpt9//10//PCD3n77bb300ks644wzAvI0DEOvvPKKNm/erBUrVuj999/XzTffrBdeeOGg9flfGmHcuHHKyMgIWP7oo49q8+bN+v777/XTTz/V+Qzi7t27q2vXrvrhhx/02Wef6aqrrtLQoUMVHR2tX3/9VcuXL9e8efOsy0K0b99eGzZs0K5du/TQQw/puOOO01NPPaXdu3dX2faFF15oXW7i3nvvVVxcnA477LCAa+sCAACgcTG0BQAAQIPr2rWrEhIStHfvXivmP5Tt3r274uPjtW/fvmqXt2jRQjNnztSf//xnud1uPfnkk3ryyScDHqN9+/bW7QceeECff/65vv/+ey1dujTg0gWHEhcXp3fffVcnnXSStmzZon/9619q27at7r333mrXX7dundasWSNJSk9P16RJk6wzhH1+/vlnTZ06VVLFgPf++++vdT5SxTB51qxZOuuss7Rnzx698soreuWVV2pc/8Ybb9Qdd9whSdbwNS0tTUcffbTWrVsXsO61116r6dOn69tvv1Vubq6uueYaSar1F7ABAAAg9Lg8AgAAABqcw+Go8sVW/kPZqKgo9ezZs8blknTeeedp5cqVuvLKK9W2bVtFR0crLS1NPXr00JgxYzR37lxr3ZYtW2rp0qW6//771b17d8XFxSk+Pl5HHXWULrnkEr3xxhtVtu8vMzNT7733nhISEiRJEyZM0EsvvVTtuv5n2Z5//vlVBraSNGjQIOt2sJdIOOGEE7RmzRr95S9/UceOHRUTE6OWLVuqa9eu+stf/qKFCxda6952222aPHmy2rdvr/j4eJ1xxhlatGiRMjMzq2w3JiZGCxYs0PDhw5WYmKjExERdeuml+vTTT4PKEwAAAPVnmHX9dgMAAAAAAAAAQIPhTFsAAAAAAAAAsBGGtgAAAAAAAABgIwxtAQAAAAAAAMBGGNoCAAAAAAAAgI0wtAUAAAAAAAAAG2FoCwAAAAAAAAA2wtAWAAAAAAAAAGyEoS0AAAAAAAAA2AhDWwAAAAAAAACwEYa2AAAAAAAAAGAjDG0BAAAAAAAAwEYY2gIAAAAAAACAjTC0BQAAAAAAAAAb+f//gRDD0NhnHQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "✅ FORECAST EVALUATION COMPLETE!\n",
            "======================================================================\n",
            "\n",
            "📊 ACCURACY METRICS:\n",
            "  • MAE (Mean Absolute Error):        85.54\n",
            "  • RMSE (Root Mean Squared Error):   90.25\n",
            "  • MAPE (Mean Absolute % Error):     107.8%\n",
            "\n",
            "📈 FORECAST SUMMARY (Next 12 weeks):\n",
            "  • Mean Forecast:     169.21\n",
            "  • Median Forecast:   164.90\n",
            "  • Min Forecast:      126.50\n",
            "  • Max Forecast:      249.65\n",
            "  • Std Deviation:     31.07\n",
            "\n",
            "📉 ACTUAL VALUES (Holdout Period):\n",
            "  • Mean Actual:       83.67\n",
            "  • Min Actual:        56.00\n",
            "  • Max Actual:        113.00\n",
            "\n",
            "📋 WEEK-BY-WEEK COMPARISON:\n",
            "Week   Actual     Forecast   Error      % Error   \n",
            "--------------------------------------------------\n",
            "1      113.00     249.65     136.65     120.9     %\n",
            "2      83.00      206.07     123.07     148.3     %\n",
            "3      80.00      155.45     75.45      94.3      %\n",
            "4      81.00      171.17     90.17      111.3     %\n",
            "5      88.00      175.33     87.33      99.2      %\n",
            "6      56.00      172.50     116.50     208.0     %\n",
            "7      87.00      158.02     71.02      81.6      %\n",
            "8      62.00      170.12     108.12     174.4     %\n",
            "9      86.00      150.19     64.19      74.6      %\n",
            "10     106.00     159.69     53.69      50.6      %\n",
            "11     94.00      135.84     41.84      44.5      %\n",
            "12     68.00      126.50     58.50      86.0      %\n",
            "\n",
            "======================================================================\n"
          ]
        }
      ]
    }
  ]
}